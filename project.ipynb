{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhancing Airline Service Through Automated Sentiment Analysis of Customer Reviews\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Motivation**\n",
    "\n",
    "Developed a a series of data preprocessing tasks, utilizing datasets from [Airlines Review Dataset](https://www.kaggle.com/datasets/juhibhojani/airline-reviews). Performed sentiment analysis and evaluated performance metrics using multiple models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Airline Customer Review Dataset Information\n",
    "\n",
    "The [Airline Customer Review Dataset](https://www.kaggle.com/datasets/juhibhojani/airline-reviews) contains customer review data for airline flights.\n",
    "\n",
    "- **Airline Name**: Name of Airline.\n",
    "- **Overall_Rating:** Rating given by the user.\n",
    "- **Review_Title:** Title of review.\n",
    "- **Review Date:** The date when review was entered (e.g., 1st January 2019).\n",
    "- **Verified:** Whether the reviewer is verified or not.\n",
    "- **Review:** Detailed review given by the user.\n",
    "- **Aircraft:** Type of aircraft.\n",
    "- **Type Of Traveller:** The type of traveller (e.g., Solo Leisure).\n",
    "- **Seat Type:** Categorical seat class type (e.g., Economy Class).\n",
    "- **Route:** Flight source and destination.\n",
    "- **Date Flown:** Month and year of flight (e.g., September 2019).\n",
    "- **Seat Comfort:** Rating out of 5.\n",
    "- **Cabin Staff Service:** Rating out of 5.\n",
    "- **Food & Beverages:** Rating out of 5.\n",
    "- **Ground Service:** Rating out of 5.\n",
    "- **Inflight Entertainment:** Rating out of 5.\n",
    "- **Wifi & Connectivity:** Rating out of 5.\n",
    "- **Value For Money:** Rating out of 5.\n",
    "- **Recommended:** Whether the flight is recommended or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "Uncomment the line below to install the dependencies required for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Statistical functions\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# For concurrency (running functions in parallel)\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# For caching (to speed up repeated function calls)\n",
    "from functools import lru_cache\n",
    "\n",
    "# For progress tracking\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Plotting and Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Language Detection packages\n",
    "# `langdetect` for detecting language\n",
    "from langdetect import detect as langdetect_detect, DetectorFactory\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "# `langid` for an alternative language detection method\n",
    "from langid import classify as langid_classify\n",
    "\n",
    "# Text Preprocessing and NLP\n",
    "# Stopwords (common words to ignore) from NLTK\n",
    "from nltk.corpus import stopwords\n",
    "# Tokenizing sentences/words\n",
    "from nltk.tokenize import word_tokenize\n",
    "# Lemmatization (converting words to their base form)\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "# Regular expressions for text pattern matching\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "import emoji\n",
    "\n",
    "# Word Cloud generation\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation (Loading CSV)\n",
    "\n",
    "Load the Airline Review `data.csv` file into a pandas DataFrame `data_raw`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23171 entries, 0 to 23170\n",
      "Data columns (total 20 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Unnamed: 0              23171 non-null  int64  \n",
      " 1   Airline Name            23171 non-null  object \n",
      " 2   Overall_Rating          23171 non-null  object \n",
      " 3   Review_Title            23171 non-null  object \n",
      " 4   Review Date             23171 non-null  object \n",
      " 5   Verified                23171 non-null  bool   \n",
      " 6   Review                  23171 non-null  object \n",
      " 7   Aircraft                7129 non-null   object \n",
      " 8   Type Of Traveller       19433 non-null  object \n",
      " 9   Seat Type               22075 non-null  object \n",
      " 10  Route                   19343 non-null  object \n",
      " 11  Date Flown              19417 non-null  object \n",
      " 12  Seat Comfort            19016 non-null  float64\n",
      " 13  Cabin Staff Service     18911 non-null  float64\n",
      " 14  Food & Beverages        14500 non-null  float64\n",
      " 15  Ground Service          18378 non-null  float64\n",
      " 16  Inflight Entertainment  10829 non-null  float64\n",
      " 17  Wifi & Connectivity     5920 non-null   float64\n",
      " 18  Value For Money         22105 non-null  float64\n",
      " 19  Recommended             23171 non-null  object \n",
      "dtypes: bool(1), float64(7), int64(1), object(11)\n",
      "memory usage: 3.4+ MB\n",
      "Dataframe Shape:  (23171, 20)\n"
     ]
    }
   ],
   "source": [
    "data_raw.info()\n",
    "print(\"Dataframe Shape: \", data_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Airline Name</th>\n",
       "      <th>Overall_Rating</th>\n",
       "      <th>Review_Title</th>\n",
       "      <th>Review Date</th>\n",
       "      <th>Verified</th>\n",
       "      <th>Review</th>\n",
       "      <th>Aircraft</th>\n",
       "      <th>Type Of Traveller</th>\n",
       "      <th>Seat Type</th>\n",
       "      <th>Route</th>\n",
       "      <th>Date Flown</th>\n",
       "      <th>Seat Comfort</th>\n",
       "      <th>Cabin Staff Service</th>\n",
       "      <th>Food &amp; Beverages</th>\n",
       "      <th>Ground Service</th>\n",
       "      <th>Inflight Entertainment</th>\n",
       "      <th>Wifi &amp; Connectivity</th>\n",
       "      <th>Value For Money</th>\n",
       "      <th>Recommended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AB Aviation</td>\n",
       "      <td>9</td>\n",
       "      <td>\"pretty decent airline\"</td>\n",
       "      <td>11th November 2019</td>\n",
       "      <td>True</td>\n",
       "      <td>Moroni to Moheli. Turned out to be a pretty ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Moroni to Moheli</td>\n",
       "      <td>November 2019</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AB Aviation</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Not a good airline\"</td>\n",
       "      <td>25th June 2019</td>\n",
       "      <td>True</td>\n",
       "      <td>Moroni to Anjouan. It is a very small airline...</td>\n",
       "      <td>E120</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Moroni to Anjouan</td>\n",
       "      <td>June 2019</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AB Aviation</td>\n",
       "      <td>1</td>\n",
       "      <td>\"flight was fortunately short\"</td>\n",
       "      <td>25th June 2019</td>\n",
       "      <td>True</td>\n",
       "      <td>Anjouan to Dzaoudzi. A very small airline an...</td>\n",
       "      <td>Embraer E120</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Anjouan to Dzaoudzi</td>\n",
       "      <td>June 2019</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Adria Airways</td>\n",
       "      <td>1</td>\n",
       "      <td>\"I will never fly again with Adria\"</td>\n",
       "      <td>28th September 2019</td>\n",
       "      <td>False</td>\n",
       "      <td>Please do a favor yourself and do not fly wi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Frankfurt to Pristina</td>\n",
       "      <td>September 2019</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Adria Airways</td>\n",
       "      <td>1</td>\n",
       "      <td>\"it ruined our last days of holidays\"</td>\n",
       "      <td>24th September 2019</td>\n",
       "      <td>True</td>\n",
       "      <td>Do not book a flight with this airline! My fr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Couple Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Sofia to Amsterdam via Ljubljana</td>\n",
       "      <td>September 2019</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   Airline Name Overall_Rating  \\\n",
       "0           0    AB Aviation              9   \n",
       "1           1    AB Aviation              1   \n",
       "2           2    AB Aviation              1   \n",
       "3           3  Adria Airways              1   \n",
       "4           4  Adria Airways              1   \n",
       "\n",
       "                            Review_Title          Review Date  Verified  \\\n",
       "0                \"pretty decent airline\"   11th November 2019      True   \n",
       "1                   \"Not a good airline\"       25th June 2019      True   \n",
       "2         \"flight was fortunately short\"       25th June 2019      True   \n",
       "3    \"I will never fly again with Adria\"  28th September 2019     False   \n",
       "4  \"it ruined our last days of holidays\"  24th September 2019      True   \n",
       "\n",
       "                                              Review       Aircraft  \\\n",
       "0    Moroni to Moheli. Turned out to be a pretty ...            NaN   \n",
       "1   Moroni to Anjouan. It is a very small airline...           E120   \n",
       "2    Anjouan to Dzaoudzi. A very small airline an...  Embraer E120    \n",
       "3    Please do a favor yourself and do not fly wi...            NaN   \n",
       "4   Do not book a flight with this airline! My fr...            NaN   \n",
       "\n",
       "  Type Of Traveller      Seat Type                             Route  \\\n",
       "0      Solo Leisure  Economy Class                  Moroni to Moheli   \n",
       "1      Solo Leisure  Economy Class                 Moroni to Anjouan   \n",
       "2      Solo Leisure  Economy Class               Anjouan to Dzaoudzi   \n",
       "3      Solo Leisure  Economy Class             Frankfurt to Pristina   \n",
       "4    Couple Leisure  Economy Class  Sofia to Amsterdam via Ljubljana   \n",
       "\n",
       "       Date Flown  Seat Comfort  Cabin Staff Service  Food & Beverages  \\\n",
       "0   November 2019           4.0                  5.0               4.0   \n",
       "1       June 2019           2.0                  2.0               1.0   \n",
       "2       June 2019           2.0                  1.0               1.0   \n",
       "3  September 2019           1.0                  1.0               NaN   \n",
       "4  September 2019           1.0                  1.0               1.0   \n",
       "\n",
       "   Ground Service  Inflight Entertainment  Wifi & Connectivity  \\\n",
       "0             4.0                     NaN                  NaN   \n",
       "1             1.0                     NaN                  NaN   \n",
       "2             1.0                     NaN                  NaN   \n",
       "3             1.0                     NaN                  NaN   \n",
       "4             1.0                     1.0                  1.0   \n",
       "\n",
       "   Value For Money Recommended  \n",
       "0              3.0         yes  \n",
       "1              2.0          no  \n",
       "2              2.0          no  \n",
       "3              1.0          no  \n",
       "4              1.0          no  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "Here we select the relevant features for sentiment analysis.\n",
    "- `Review_Title`, `Review`, `Recommended`.\n",
    "- Create a new DataFrame (`data`) by selecting the specifc columns mentioned above from the original DataFrame `data_raw`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "                            Review_Title  \\\n",
      "0                \"pretty decent airline\"   \n",
      "1                   \"Not a good airline\"   \n",
      "2         \"flight was fortunately short\"   \n",
      "3    \"I will never fly again with Adria\"   \n",
      "4  \"it ruined our last days of holidays\"   \n",
      "\n",
      "                                              Review Overall_Rating  \\\n",
      "0    Moroni to Moheli. Turned out to be a pretty ...              9   \n",
      "1   Moroni to Anjouan. It is a very small airline...              1   \n",
      "2    Anjouan to Dzaoudzi. A very small airline an...              1   \n",
      "3    Please do a favor yourself and do not fly wi...              1   \n",
      "4   Do not book a flight with this airline! My fr...              1   \n",
      "\n",
      "  Recommended  Seat Comfort  \n",
      "0         yes           4.0  \n",
      "1          no           2.0  \n",
      "2          no           2.0  \n",
      "3          no           1.0  \n",
      "4          no           1.0  \n",
      "The old shape is:  (23171, 5)\n"
     ]
    }
   ],
   "source": [
    "# Selecting the relevant features for sentiment analysis \n",
    "data = data_raw[[\n",
    "    'Review_Title',\n",
    "    'Review',\n",
    "    \"Overall_Rating\",\n",
    "    \"Recommended\",\n",
    "    \"Seat Comfort\"\n",
    "]]\n",
    "print(type(data))\n",
    "print(data.head())\n",
    "\n",
    "# Shape before dropping duplicates\n",
    "print(\"The old shape is: \", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_Title</th>\n",
       "      <th>Review</th>\n",
       "      <th>Overall_Rating</th>\n",
       "      <th>Recommended</th>\n",
       "      <th>Seat Comfort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"I will never fly again with Adria\"</td>\n",
       "      <td>Please do a favor yourself and do not fly wi...</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"it ruined our last days of holidays\"</td>\n",
       "      <td>Do not book a flight with this airline! My fr...</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"Had very bad experience\"</td>\n",
       "      <td>Had very bad experience with rerouted and ca...</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"worse than the budget airlines\"</td>\n",
       "      <td>Ljubljana to Zürich. Firstly, Ljubljana airp...</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"book another company\"</td>\n",
       "      <td>First of all, I am not complaining about a s...</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23137</th>\n",
       "      <td>ZIPAIR customer review</td>\n",
       "      <td>The seats are abysmal for a long-haul flight...</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23148</th>\n",
       "      <td>\"has the worst customer service\"</td>\n",
       "      <td>Zipair has the worst customer service. The c...</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23149</th>\n",
       "      <td>\"airline is a total rip-off for the extras\"</td>\n",
       "      <td>This airline is a total rip-off for the extra...</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23155</th>\n",
       "      <td>\"Very frustrating experience\"</td>\n",
       "      <td>Very frustrating experience. Does not allow c...</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23156</th>\n",
       "      <td>\"go with a reputable airline\"</td>\n",
       "      <td>Los Angeles to Tokyo. DO NOT BOOK. There is a...</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6337 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Review_Title  \\\n",
       "3              \"I will never fly again with Adria\"   \n",
       "4            \"it ruined our last days of holidays\"   \n",
       "5                        \"Had very bad experience\"   \n",
       "6                 \"worse than the budget airlines\"   \n",
       "7                           \"book another company\"   \n",
       "...                                            ...   \n",
       "23137                       ZIPAIR customer review   \n",
       "23148             \"has the worst customer service\"   \n",
       "23149  \"airline is a total rip-off for the extras\"   \n",
       "23155                \"Very frustrating experience\"   \n",
       "23156                \"go with a reputable airline\"   \n",
       "\n",
       "                                                  Review Overall_Rating  \\\n",
       "3        Please do a favor yourself and do not fly wi...              1   \n",
       "4       Do not book a flight with this airline! My fr...              1   \n",
       "5        Had very bad experience with rerouted and ca...              1   \n",
       "6        Ljubljana to Zürich. Firstly, Ljubljana airp...              1   \n",
       "7        First of all, I am not complaining about a s...              1   \n",
       "...                                                  ...            ...   \n",
       "23137    The seats are abysmal for a long-haul flight...              1   \n",
       "23148    Zipair has the worst customer service. The c...              3   \n",
       "23149   This airline is a total rip-off for the extra...              2   \n",
       "23155   Very frustrating experience. Does not allow c...              1   \n",
       "23156   Los Angeles to Tokyo. DO NOT BOOK. There is a...              1   \n",
       "\n",
       "      Recommended  Seat Comfort  \n",
       "3              no           1.0  \n",
       "4              no           1.0  \n",
       "5              no           1.0  \n",
       "6              no           1.0  \n",
       "7              no           1.0  \n",
       "...           ...           ...  \n",
       "23137          no           1.0  \n",
       "23148          no           1.0  \n",
       "23149          no           1.0  \n",
       "23155          no           1.0  \n",
       "23156          no           1.0  \n",
       "\n",
       "[6337 rows x 5 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[(data[\"Seat Comfort\"] == 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "## Remove Duplicate Rows\n",
    "- Drop duplicate rows from the dataframe (`data`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new shape is:  (23050, 3)\n"
     ]
    }
   ],
   "source": [
    "data = data.drop_duplicates()\n",
    "\n",
    "# Display the new dataframe shape\n",
    "print(\"The new shape is: \", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review_Title      0\n",
       "Review            0\n",
       "Overall_Rating    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Outliers\n",
    "\n",
    "### `Review` \n",
    "\n",
    "The `Review` column of `data`, which is of string type, may contain values with unusually long lengths, indicating the presence of outliers. We will identify the outliers using [Z-score method].\n",
    "\n",
    "1. Create a new column `review_length` in the DataFrame `data` by calculating the length of each review. (Set the value as 0 if the correponding `Review` column has NaN values.)\n",
    "\n",
    "2. Check the statistics of `review_length` using `describe()` method.\n",
    "\n",
    "3. Calculate the mean and standard deviation of the `review_length` column.\n",
    "\n",
    "4. Set the Z-score threshold for identifying outliers to 3.\n",
    "\n",
    "5. Identify outliers of the `review_length` column and set the corresponding `Review` to np.nan.\n",
    "\n",
    "6. Drop the `review_length` column from the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Review_Title  \\\n",
      "0         \"pretty decent airline\"   \n",
      "1            \"Not a good airline\"   \n",
      "2  \"flight was fortunately short\"   \n",
      "\n",
      "                                              Review Overall_Rating  \\\n",
      "0    Moroni to Moheli. Turned out to be a pretty ...              9   \n",
      "1   Moroni to Anjouan. It is a very small airline...              1   \n",
      "2    Anjouan to Dzaoudzi. A very small airline an...              1   \n",
      "\n",
      "   review_length  \n",
      "0            352  \n",
      "1            689  \n",
      "2            405  \n",
      "count    23050.000000\n",
      "mean       721.822299\n",
      "std        537.901606\n",
      "min         14.000000\n",
      "25%        361.000000\n",
      "50%        561.000000\n",
      "75%        904.000000\n",
      "max       5080.000000\n",
      "Name: review_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "data['review_length'] = data['Review'].apply(lambda x: len(x) if pd.notna(x) else 0)\n",
    "print(data.head(3))\n",
    "\n",
    "TL = data[\"review_length\"]\n",
    "stats_TL = TL.describe()\n",
    "print(stats_TL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_Title</th>\n",
       "      <th>Review</th>\n",
       "      <th>Overall_Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"pretty decent airline\"</td>\n",
       "      <td>Moroni to Moheli. Turned out to be a pretty ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Not a good airline\"</td>\n",
       "      <td>Moroni to Anjouan. It is a very small airline...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"flight was fortunately short\"</td>\n",
       "      <td>Anjouan to Dzaoudzi. A very small airline an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"I will never fly again with Adria\"</td>\n",
       "      <td>Please do a favor yourself and do not fly wi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"it ruined our last days of holidays\"</td>\n",
       "      <td>Do not book a flight with this airline! My fr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Review_Title  \\\n",
       "0                \"pretty decent airline\"   \n",
       "1                   \"Not a good airline\"   \n",
       "2         \"flight was fortunately short\"   \n",
       "3    \"I will never fly again with Adria\"   \n",
       "4  \"it ruined our last days of holidays\"   \n",
       "\n",
       "                                              Review Overall_Rating  \n",
       "0    Moroni to Moheli. Turned out to be a pretty ...              9  \n",
       "1   Moroni to Anjouan. It is a very small airline...              1  \n",
       "2    Anjouan to Dzaoudzi. A very small airline an...              1  \n",
       "3    Please do a favor yourself and do not fly wi...              1  \n",
       "4   Do not book a flight with this airline! My fr...              1  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_TL = TL.mean()\n",
    "# print(mean_TL)\n",
    "\n",
    "sd_TL = TL.std()\n",
    "# print(sd_TL)\n",
    "\n",
    "threshold = 3\n",
    "\n",
    "z_score = zscore(TL)\n",
    "# print(z_score)\n",
    "\n",
    "# Remove 'Review' of lengths that are greater than 3 standard deviations above the mean\n",
    "data.loc[abs(z_score) > threshold, 'Review'] = np.nan\n",
    "# print(data.head(3))\n",
    "\n",
    "data = data.drop(\"review_length\", axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Review_Title`\n",
    "\n",
    "Similarly, the `Review_Title` column of `data` (of type `str`) may also contain values with unusually long lengths, indicating the presence of outliers.\n",
    "\n",
    "1. Create a new column `title_length` in the DataFrame `data` by calculating the length of each price value. (Set the value as 0 if the correponding `Review_Title` column has NaN values.)\n",
    "\n",
    "2. Check the statistics of `title_length` using `describe()` method and display its unique values.\n",
    "\n",
    "3. Identify the outlier values by inspecting the content in `Review_Title` corresponding to the abnormal value in `title_length` and set the corresponding value of `Review_Title` to np.nan.\n",
    "\n",
    "4. Drop the `title_length` column from the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Review_Title  \\\n",
      "0         \"pretty decent airline\"   \n",
      "1            \"Not a good airline\"   \n",
      "2  \"flight was fortunately short\"   \n",
      "\n",
      "                                              Review Overall_Rating  \\\n",
      "0    Moroni to Moheli. Turned out to be a pretty ...              9   \n",
      "1   Moroni to Anjouan. It is a very small airline...              1   \n",
      "2    Anjouan to Dzaoudzi. A very small airline an...              1   \n",
      "\n",
      "   title_length  \n",
      "0            23  \n",
      "1            20  \n",
      "2            30  \n",
      "count    23050.000000\n",
      "mean        29.841085\n",
      "std          7.087795\n",
      "min          2.000000\n",
      "25%         25.000000\n",
      "50%         29.000000\n",
      "75%         33.000000\n",
      "max         83.000000\n",
      "Name: title_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "data['title_length'] = data['Review_Title'].apply(lambda x: len(x) if pd.notna(x) else 0)\n",
    "print(data.head(3))\n",
    "\n",
    "TL = data[\"title_length\"]\n",
    "stats_TL = TL.describe()\n",
    "print(stats_TL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['title_length'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m data\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;28mabs\u001b[39m(z_score) \u001b[38;5;241m>\u001b[39m threshold, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReview_Title\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnan\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# print(data.head(3))\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtitle_length\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m data\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5446\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5583\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5587\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5588\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['title_length'] not found in axis\""
     ]
    }
   ],
   "source": [
    "mean_TL = TL.mean()\n",
    "# print(mean_TL)\n",
    "\n",
    "sd_TL = TL.std()\n",
    "# print(sd_TL)\n",
    "\n",
    "threshold = 3\n",
    "\n",
    "z_score = zscore(TL)\n",
    "# print(z_score)\n",
    "\n",
    "# Remove 'Review_Title' of lengths that are greater than 3 standard deviations above the mean\n",
    "data.loc[abs(z_score) > threshold, 'Review_Title'] = np.nan\n",
    "# print(data.head(3))\n",
    "\n",
    "data = data.drop(\"title_length\", axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review_Title      266\n",
       "Review            504\n",
       "Overall_Rating      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "### Create new column `full_review`\n",
    "Since there are some rows with empty `Review_Title` and `Review`, we will concatenate both columns (`Review_Title` and `Review`) to form a new column `Full_Review`.\n",
    "1. Replace `NaN` values in `Review_Title` and `Review` with an empty string.\n",
    "\n",
    "2. Strip starting and ending `\"` double inverted commas from `Review_Title`.\n",
    "\n",
    "3. Combine `Review_Title` and `Review` into `full_review`.\n",
    "\n",
    "4. Strip any leading/trailing whitespaces in `full_review`.\n",
    "\n",
    "5. Drop `Review_Title` and `Review` columns.\n",
    "\n",
    "6. Drop rows where `full_review` are empty strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The old shape is: (23050, 2)\n"
     ]
    }
   ],
   "source": [
    "# 1) Fill NaN values in 'Review_Title' with an empty string\n",
    "data['Review_Title'] = data['Review_Title'].fillna('')\n",
    "data['Review'] = data['Review'].fillna('')\n",
    "\n",
    "# 2) Strip starting and ending `\"` double inverted commas from 'Review_Title'\n",
    "data['Review_Title'] = data['Review_Title'].str.strip('\"')\n",
    "\n",
    "# 3) Combine 'Review_Title' and 'Review' into 'full_review'\n",
    "data['full_review'] = data['Review_Title'] + \" \" + data['Review']\n",
    "\n",
    "# 4) Strip any leading/trailing whitespace\n",
    "data['full_review'] = data['full_review'].str.strip()\n",
    "\n",
    "# 5) Drop `Review_Title` and `Review` columns\n",
    "data = data.drop(columns = ['Review_Title', 'Review'])\n",
    "\n",
    "# Check if the 'full_review' column was added correctly and whether 'Review_Title' and 'Review' columns has been dropped\n",
    "data.head()\n",
    "print(\"The old shape is:\",data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Missing Values\n",
    "1. Drop rows where `Full_Review` are empty strings and reset the index.\n",
    "\n",
    "2. Check if there are no more null values in `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new shape is: (23040, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Overall_Rating    0\n",
       "full_review       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Drop rows where `full_review` are empty strings and reset the index\n",
    "data = data[data['full_review'] != \"\"].reset_index(drop=True)\n",
    "print(\"The new shape is:\",data.shape)\n",
    "\n",
    "# 2) Check if there are no more null values in `data`\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall_Rating</th>\n",
       "      <th>full_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>pretty decent airline   Moroni to Moheli. Turn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Not a good airline  Moroni to Anjouan. It is a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>flight was fortunately short   Anjouan to Dzao...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>I will never fly again with Adria   Please do ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>it ruined our last days of holidays  Do not bo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Overall_Rating                                        full_review\n",
       "0              9  pretty decent airline   Moroni to Moheli. Turn...\n",
       "1              1  Not a good airline  Moroni to Anjouan. It is a...\n",
       "2              1  flight was fortunately short   Anjouan to Dzao...\n",
       "3              1  I will never fly again with Adria   Please do ...\n",
       "4              1  it ruined our last days of holidays  Do not bo..."
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall_Rating</th>\n",
       "      <th>full_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>pretty decent airline   Moroni to Moheli. Turn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>the crew was nice  Ljubljana to Munich. The ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>overall very poor   We were traveling from Par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>Would not fly again   Ljubljana to Munich. Adr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>very unpleasant experience   A very unpleasant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23019</th>\n",
       "      <td>2</td>\n",
       "      <td>I should not have to pay extra just to get a m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23021</th>\n",
       "      <td>9</td>\n",
       "      <td>I highly recommend ZipAir   It was my first ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23022</th>\n",
       "      <td>5</td>\n",
       "      <td>insist I paid for another 23kg of luggage   Tw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23037</th>\n",
       "      <td>3</td>\n",
       "      <td>Will not recommend to anyone   Flight was leav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23038</th>\n",
       "      <td>6</td>\n",
       "      <td>It was immaculately clean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11459 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Overall_Rating                                        full_review\n",
       "0                  9  pretty decent airline   Moroni to Moheli. Turn...\n",
       "9                  8  the crew was nice  Ljubljana to Munich. The ho...\n",
       "12                 2  overall very poor   We were traveling from Par...\n",
       "13                 2  Would not fly again   Ljubljana to Munich. Adr...\n",
       "14                 3  very unpleasant experience   A very unpleasant...\n",
       "...              ...                                                ...\n",
       "23019              2  I should not have to pay extra just to get a m...\n",
       "23021              9  I highly recommend ZipAir   It was my first ti...\n",
       "23022              5  insist I paid for another 23kg of luggage   Tw...\n",
       "23037              3  Will not recommend to anyone   Flight was leav...\n",
       "23038              6                          It was immaculately clean\n",
       "\n",
       "[11459 rows x 2 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"Overall_Rating\"] != \"1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new column `language`\n",
    "We found that there are rows where `full_review` are in different languages (e.g., French, Russian, etc.) other than English. We decided to use 2 different language detector libraries (`langdetect`, `langid`) on the `full_review` column and combined the predictions of all 2 libraries and selecting the most frequent predicted language.\n",
    "\n",
    "**Reason**: `langdetect` might perform well on longer texts while `langid` is more reliable on short texts, using multiple detectors reduces the likelihood of misclassification and mitigates individual detector errors, leading to more accurate overall predictions. Also, even if one detector fails or throws an error, the other can still provide predictions, therefore improving the robustness of the language detection.\n",
    "\n",
    "1. Set a seed for `langdetect` to ensure reproducibility.\n",
    "\n",
    "2. Preprocess the text in `full_review`:\n",
    "    - a\\) Function to remove non-alphabetic characters and normalise whitespaces in `full_review`.\n",
    "    - b\\) Function to determine if the text is non-language (e.g., numbers, symbols only).\n",
    "\n",
    "3. Two functions for language detection:\n",
    "    - a\\) Using `langdetect`.\n",
    "    - b\\) Using `langid`.\n",
    "\n",
    "4. Function for calculating majority vote for each language.\n",
    "\n",
    "5. Function for parallel processing for efficiency.\n",
    "\n",
    "6. Caching function for repeated inputs\n",
    "\n",
    "7. Function for choosing language based on combined majority voting.\n",
    "\n",
    "8. Applying the combined function on `full_review` column.\n",
    "\n",
    "9. Display the resulting `data` DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Language Detection: 100%|██████████| 23039/23039 [03:01<00:00, 127.05it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_review</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pretty decent airline   Moroni to Moheli. Turn...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not a good airline  Moroni to Anjouan. It is a...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flight was fortunately short   Anjouan to Dzao...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I will never fly again with Adria   Please do ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it ruined our last days of holidays  Do not bo...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23034</th>\n",
       "      <td>customer service is terrible  Bangkok to Tokyo...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23035</th>\n",
       "      <td>Avoid at all costs   Avoid at all costs. I boo...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23036</th>\n",
       "      <td>Will not recommend to anyone   Flight was leav...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23037</th>\n",
       "      <td>It was immaculately clean</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23038</th>\n",
       "      <td>lost all of our money with no refund   They li...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23039 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             full_review language\n",
       "0      pretty decent airline   Moroni to Moheli. Turn...       en\n",
       "1      Not a good airline  Moroni to Anjouan. It is a...       en\n",
       "2      flight was fortunately short   Anjouan to Dzao...       en\n",
       "3      I will never fly again with Adria   Please do ...       en\n",
       "4      it ruined our last days of holidays  Do not bo...       en\n",
       "...                                                  ...      ...\n",
       "23034  customer service is terrible  Bangkok to Tokyo...       en\n",
       "23035  Avoid at all costs   Avoid at all costs. I boo...       en\n",
       "23036  Will not recommend to anyone   Flight was leav...       en\n",
       "23037                          It was immaculately clean       en\n",
       "23038  lost all of our money with no refund   They li...       en\n",
       "\n",
       "[23039 rows x 2 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Set a seed for langdetect to ensure reproducibility\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "# 2a) Simplified preprocessing: only remove non-alphabetic characters\n",
    "def preprocess_text_simple(text):\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove non-alphabetic characters\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Normalize whitespace\n",
    "    return text.strip()\n",
    "\n",
    "# 2b) Check if the text is non-language (e.g., numbers, symbols only)\n",
    "def is_non_language_text(text):\n",
    "    if re.match(r'^[^a-zA-Z]*$', text):  # Check if text has no alphabetic characters\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# 3a) Function to get langdetect prediction\n",
    "def get_langdetect_prediction(text):\n",
    "    try:\n",
    "        # Directly use text without preprocessing for efficiency\n",
    "        if len(text) < 10 or is_non_language_text(text):\n",
    "            return \"unknown\"\n",
    "        lang = langdetect_detect(text)\n",
    "        return lang\n",
    "    except LangDetectException:\n",
    "        return \"unknown\"\n",
    "\n",
    "# 3b) Function to get langid prediction\n",
    "def get_langid_prediction(text):\n",
    "    try:\n",
    "        lang, _ = langid_classify(text)\n",
    "        if len(text) < 10 or is_non_language_text(text):\n",
    "            return \"unknown\"\n",
    "        return lang\n",
    "    except Exception:\n",
    "        return \"unknown\"\n",
    "\n",
    "# 4) Function to calculate majority vote for each language\n",
    "def calculate_majority_vote(predictions):\n",
    "    vote_counts = {}\n",
    "    for lang in predictions:\n",
    "        if lang in vote_counts:\n",
    "            vote_counts[lang] += 1\n",
    "        else:\n",
    "            vote_counts[lang] = 1\n",
    "    return vote_counts\n",
    "\n",
    "# 5) Parallel processing for efficiency with limited workers\n",
    "def parallel_detection(text):\n",
    "    with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        results = list(executor.map(lambda func: func(text), \n",
    "                                    [get_langdetect_prediction, get_langid_prediction]))\n",
    "    return results\n",
    "\n",
    "# 6) Caching function for repeated inputs\n",
    "@lru_cache(maxsize=500)\n",
    "def get_cached_language(text):\n",
    "    return combined_language_detection(text)\n",
    "\n",
    "# 7) Combined majority voting language detection function\n",
    "def combined_language_detection(text):\n",
    "    # Check if the text is non-language (e.g., numbers, symbols only)\n",
    "    if is_non_language_text(text):\n",
    "        return \"unknown\"\n",
    "    \n",
    "    # Run the detectors in parallel for efficiency\n",
    "    predictions = parallel_detection(text)\n",
    "    \n",
    "    # Calculate majority vote for each language based on predictions\n",
    "    vote_counts = calculate_majority_vote(predictions)\n",
    "    \n",
    "    # Determine the language with the highest majority vote\n",
    "    final_language = max(vote_counts, key=vote_counts.get)\n",
    "    \n",
    "    # If \"unknown\" is the most common or if all detectors fail, return \"unknown\"\n",
    "    if final_language == \"unknown\" or vote_counts[final_language] <= 1:\n",
    "        return \"unknown\"\n",
    "    \n",
    "    return final_language\n",
    "\n",
    "# 8) Apply the cached function to each text in the DataFrame with a progress bar\n",
    "data['language'] = [get_cached_language(text) for text in tqdm(data['full_review'], desc=\"Language Detection\")]\n",
    "\n",
    "# 9) Display the DataFrame with detected languages\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "language\n",
       "en         22852\n",
       "unknown      145\n",
       "fr            18\n",
       "es             7\n",
       "it             4\n",
       "de             2\n",
       "no             2\n",
       "id             2\n",
       "sv             2\n",
       "et             1\n",
       "nl             1\n",
       "ca             1\n",
       "pt             1\n",
       "th             1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See distribution of languages\n",
    "data[\"language\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_review</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pretty decent airline   Moroni to Moheli. Turn...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not a good airline  Moroni to Anjouan. It is a...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flight was fortunately short   Anjouan to Dzao...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I will never fly again with Adria   Please do ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it ruined our last days of holidays  Do not bo...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22847</th>\n",
       "      <td>customer service is terrible  Bangkok to Tokyo...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22848</th>\n",
       "      <td>Avoid at all costs   Avoid at all costs. I boo...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22849</th>\n",
       "      <td>Will not recommend to anyone   Flight was leav...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22850</th>\n",
       "      <td>It was immaculately clean</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22851</th>\n",
       "      <td>lost all of our money with no refund   They li...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22852 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             full_review language\n",
       "0      pretty decent airline   Moroni to Moheli. Turn...       en\n",
       "1      Not a good airline  Moroni to Anjouan. It is a...       en\n",
       "2      flight was fortunately short   Anjouan to Dzao...       en\n",
       "3      I will never fly again with Adria   Please do ...       en\n",
       "4      it ruined our last days of holidays  Do not bo...       en\n",
       "...                                                  ...      ...\n",
       "22847  customer service is terrible  Bangkok to Tokyo...       en\n",
       "22848  Avoid at all costs   Avoid at all costs. I boo...       en\n",
       "22849  Will not recommend to anyone   Flight was leav...       en\n",
       "22850                          It was immaculately clean       en\n",
       "22851  lost all of our money with no refund   They li...       en\n",
       "\n",
       "[22852 rows x 2 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows where language is NOT in english and reset the index\n",
    "data = data[data['language'] == 'en'].reset_index(drop=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will drop the `language` column since all values of `language` are `en` and all `full_review` are in the English language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22852 entries, 0 to 22851\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   full_review  22852 non-null  object\n",
      " 1   language     22852 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 357.2+ KB\n",
      "The new shape is: (22852, 1)\n"
     ]
    }
   ],
   "source": [
    "data.info()\n",
    "data.drop(columns=[\"language\"], inplace=True)\n",
    "print(\"The new shape is:\", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pretty decent airline   Moroni to Moheli. Turn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not a good airline  Moroni to Anjouan. It is a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flight was fortunately short   Anjouan to Dzao...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I will never fly again with Adria   Please do ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it ruined our last days of holidays  Do not bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22847</th>\n",
       "      <td>customer service is terrible  Bangkok to Tokyo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22848</th>\n",
       "      <td>Avoid at all costs   Avoid at all costs. I boo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22849</th>\n",
       "      <td>Will not recommend to anyone   Flight was leav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22850</th>\n",
       "      <td>It was immaculately clean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22851</th>\n",
       "      <td>lost all of our money with no refund   They li...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22852 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             full_review\n",
       "0      pretty decent airline   Moroni to Moheli. Turn...\n",
       "1      Not a good airline  Moroni to Anjouan. It is a...\n",
       "2      flight was fortunately short   Anjouan to Dzao...\n",
       "3      I will never fly again with Adria   Please do ...\n",
       "4      it ruined our last days of holidays  Do not bo...\n",
       "...                                                  ...\n",
       "22847  customer service is terrible  Bangkok to Tokyo...\n",
       "22848  Avoid at all costs   Avoid at all costs. I boo...\n",
       "22849  Will not recommend to anyone   Flight was leav...\n",
       "22850                          It was immaculately clean\n",
       "22851  lost all of our money with no refund   They li...\n",
       "\n",
       "[22852 rows x 1 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing for NLP\n",
    "\n",
    "Here we will define a function `process_full_review` that takes a textual value as input and applies the following processing steps in sequence:\n",
    "\n",
    "1. Convert the input text to lowercase using the `lower()` function.\n",
    "\n",
    "2. Tokenize the lowercase text using the `word_tokenize` function from the NLTK library.\n",
    "\n",
    "3. Create a list (`alphabetic_tokens`) containing only alphanetic tokens using a list comprehension with a regular expression match.\n",
    "\n",
    "4. Remove stopwords\n",
    "-   Obtain a set of English stopwords using the `stopwords.words('english')` method.\n",
    "-   Define a list of `allowed_words` that should not be removed.\n",
    "-   Remove the stopwords (excluding those that should not be removed).\n",
    "\n",
    "5. Apply lemmatization to each token in the list (`lemmatized_words`) using the `lemmatize` method.\n",
    "\n",
    "6. Join the lemmatized tokens into a single processed text using the `join` method and return the processed text.\n",
    "\n",
    "Create a new column (`processed_full_review`) in `data` by applying the `process_full_review` function to the `Full_Review` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure require NLTK data is downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to process text\n",
    "def process_full_review(text):\n",
    "    processed_text = \"\"\n",
    "\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Tokenize the text into words\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Keep only alphabetic tokens\n",
    "    alphabetic_tokens = [i for i in tokens if re.match('^[a-zA-Z]+$', i)]\n",
    "\n",
    "    if len(alphabetic_tokens) == 0:\n",
    "        # Return empty processed text and zero ratios if no valid token\n",
    "        # return processed_text\n",
    "        return processed_text\n",
    "\n",
    "    # List of stopwords\n",
    "    stop_words = stopwords.words('english')\n",
    "\n",
    "    # List of allowed words (to preserve certain negative words and conjuctions)\n",
    "    allowed_words = [\"no\", \"not\", \"don't\", \"dont\", \"don\", \"but\", \n",
    "                     \"however\", \"never\", \"wasn't\", \"wasnt\", \"shouldn't\",\n",
    "                     \"shouldnt\", \"mustn't\", \"musnt\"]\n",
    "    '''\n",
    "    these words may carry important information, such as negative connotations. in examples such as\n",
    "    \"don't ever get this dish\" -> if don't was removed, it may be interpreted as \"get dish\", which is of the opposite sentiment\n",
    "    of what the original review is supposed to be.\n",
    "    Conjunctions like \"but\" and \"however\" shows a contrast to the sentence said before, meaning that the sentiment can be\n",
    "    negatively affected or at the very least, impacted. Similarly for \"mustn't\" or \"shouldn't\", they typically carry a negative sentiment.\n",
    "    '''\n",
    "\n",
    "    # Filter out stopwords, keeping allowed words\n",
    "    filtered_tokens = [i for i in alphabetic_tokens if i not in stop_words or i in allowed_words]\n",
    "\n",
    "    # Initialise the WordNet Lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # Lemmatize the filtered tokens\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "\n",
    "    # Join the lemmatized words back into a single string\n",
    "    processed_text = ' '.join(lemmatized_words)\n",
    "\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Airlines Reviews: 100%|██████████| 22852/22852 [00:26<00:00, 862.24it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_review</th>\n",
       "      <th>processed_full_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pretty decent airline   Moroni to Moheli. Turn...</td>\n",
       "      <td>pretty decent airline moroni moheli turned pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not a good airline  Moroni to Anjouan. It is a...</td>\n",
       "      <td>not good airline moroni anjouan small airline ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flight was fortunately short   Anjouan to Dzao...</td>\n",
       "      <td>flight fortunately short anjouan dzaoudzi smal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I will never fly again with Adria   Please do ...</td>\n",
       "      <td>never fly adria please favor not fly adria rou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it ruined our last days of holidays  Do not bo...</td>\n",
       "      <td>ruined last day holiday not book flight airlin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22847</th>\n",
       "      <td>customer service is terrible  Bangkok to Tokyo...</td>\n",
       "      <td>customer service terrible bangkok tokyo flown ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22848</th>\n",
       "      <td>Avoid at all costs   Avoid at all costs. I boo...</td>\n",
       "      <td>avoid cost avoid cost booked flight go singapo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22849</th>\n",
       "      <td>Will not recommend to anyone   Flight was leav...</td>\n",
       "      <td>not recommend anyone flight leaving hour half ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22850</th>\n",
       "      <td>It was immaculately clean</td>\n",
       "      <td>immaculately clean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22851</th>\n",
       "      <td>lost all of our money with no refund   They li...</td>\n",
       "      <td>lost money no refund lied connection narita lo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22852 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             full_review  \\\n",
       "0      pretty decent airline   Moroni to Moheli. Turn...   \n",
       "1      Not a good airline  Moroni to Anjouan. It is a...   \n",
       "2      flight was fortunately short   Anjouan to Dzao...   \n",
       "3      I will never fly again with Adria   Please do ...   \n",
       "4      it ruined our last days of holidays  Do not bo...   \n",
       "...                                                  ...   \n",
       "22847  customer service is terrible  Bangkok to Tokyo...   \n",
       "22848  Avoid at all costs   Avoid at all costs. I boo...   \n",
       "22849  Will not recommend to anyone   Flight was leav...   \n",
       "22850                          It was immaculately clean   \n",
       "22851  lost all of our money with no refund   They li...   \n",
       "\n",
       "                                   processed_full_review  \n",
       "0      pretty decent airline moroni moheli turned pre...  \n",
       "1      not good airline moroni anjouan small airline ...  \n",
       "2      flight fortunately short anjouan dzaoudzi smal...  \n",
       "3      never fly adria please favor not fly adria rou...  \n",
       "4      ruined last day holiday not book flight airlin...  \n",
       "...                                                  ...  \n",
       "22847  customer service terrible bangkok tokyo flown ...  \n",
       "22848  avoid cost avoid cost booked flight go singapo...  \n",
       "22849  not recommend anyone flight leaving hour half ...  \n",
       "22850                                 immaculately clean  \n",
       "22851  lost money no refund lied connection narita lo...  \n",
       "\n",
       "[22852 rows x 2 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enable tqdm for pandas (progress bar)\n",
    "tqdm.pandas(desc=\"Processing Airlines Reviews\")\n",
    "\n",
    "# Apply process_full_review function with tqdm progress bar and expand the results into separate columns.\n",
    "data['processed_full_review'] = data['full_review'].progress_apply(process_full_review)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the `data` DataFrame is: (22853, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Recommended\n",
       "no     15096\n",
       "yes     7757\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The shape of the `data` DataFrame is:\",data.shape)\n",
    "\n",
    "data.isnull().sum()\n",
    "\n",
    "data[\"Recommended\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution of the \"Overall Rating\" dependent variable\n",
    "sns.countplot(x='Overall_Rating', data=df_cleaned)\n",
    "plt.title('Class Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get percentage distribution of \"Overall Rating\"\n",
    "class_distribution_percentage = df_cleaned['Overall_Rating'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(class_distribution_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to clean text for \"Review\" column of df_cleaned\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])  # Remove stopwords\n",
    "    return text\n",
    "\n",
    "# Apply cleaning to \"Review\"\n",
    "df_cleaned['Cleaned_Review'] = df_cleaned['Review'].apply(preprocess_text)\n",
    "df_cleaned[\"Cleaned_Review\"].head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Text to Sequences\n",
    "\n",
    "#for an RNN, text data needs to be converted into numerical form\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize the TfidfVectorizer with a limit on vocabulary size\n",
    "max_words = 5000\n",
    "vectorizer = TfidfVectorizer(max_features=max_words)\n",
    "\n",
    "# Fit and transform the text data into numerical sequences\n",
    "sequences = vectorizer.fit_transform(df_cleaned['Cleaned_Review'])\n",
    "\n",
    "# Convert to array (if needed)\n",
    "sequences_array = sequences.toarray()\n",
    "\n",
    "# Check the shape of the output\n",
    "print(sequences_array.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing the Distribution of Text Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['review_length'] = df_cleaned['Cleaned_Review'].apply(lambda x: len(x.split()))\n",
    "df_cleaned['review_length'].hist(bins=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(df_cleaned['review_length'], kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most Common Words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "all_words = ' '.join([text for text in df_cleaned['Cleaned_Review']])\n",
    "word_counts = Counter(all_words.split())\n",
    "common_words = word_counts.most_common(20)\n",
    "\n",
    "print(common_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Cloud Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "# Generating word cloud from cleaned reviews\n",
    "text = ' '.join(df_cleaned['Cleaned_Review'].tolist())\n",
    "wordcloud = WordCloud(width=800, height=400, max_words=100).generate(text)\n",
    "\n",
    "# Plot the word cloud\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bigram Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create a count vectorizer for most common bigrams(Phrases of 2 words)\n",
    "vectorizer = CountVectorizer(ngram_range=(2, 2), max_features=19)\n",
    "\n",
    "# Fit and transform the cleaned review data\n",
    "bigrams = vectorizer.fit_transform(df_cleaned['Cleaned_Review'])\n",
    "\n",
    "# Geting the bigram frequencies\n",
    "bigram_frequencies = pd.DataFrame(bigrams.toarray(), columns=vectorizer.get_feature_names_out()).sum().sort_values(ascending=False)\n",
    "\n",
    "print(bigram_frequencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the Sentiment Polarity Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install textblob\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Calculate polarity\n",
    "# Take note that this current polarity is calculated using the TextBlob library\n",
    "\n",
    "df_cleaned['polarity'] = df_cleaned['Cleaned_Review'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "\n",
    "# Plot the polarity distribution\n",
    "sns.histplot(df_cleaned['polarity'], bins=30)\n",
    "plt.title('Sentiment Polarity Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After additional columns added to df_cleaned, this is how it looks like now\n",
    "df_cleaned.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With only 1 numerical independent variable, the correlation matrix is as follows\n",
    "sns.heatmap(df_cleaned.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pairplot of Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
