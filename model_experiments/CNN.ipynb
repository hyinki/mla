{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation (Loading CSV)\n",
    "\n",
    "Load the three CSV files into a pandas DataFrame `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../final_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>processed_full_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>ok use airlin go singapor london heathrow issu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>Negative</td>\n",
       "      <td>don give money book paid receiv email confirm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>Positive</td>\n",
       "      <td>best airlin world best airlin world seat food ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>Negative</td>\n",
       "      <td>premium economi seat singapor airlin not worth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>Negative</td>\n",
       "      <td>imposs get promis refund book flight full mont...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month sentiment                              processed_full_review\n",
       "0  2024      3   Neutral  ok use airlin go singapor london heathrow issu...\n",
       "1  2024      3  Negative  don give money book paid receiv email confirm ...\n",
       "2  2024      3  Positive  best airlin world best airlin world seat food ...\n",
       "3  2024      3  Negative  premium economi seat singapor airlin not worth...\n",
       "4  2024      3  Negative  imposs get promis refund book flight full mont..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "Positive    7913\n",
       "Negative    2441\n",
       "Neutral     1164\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year\n",
       "2019    5129\n",
       "2018    2596\n",
       "2022    1184\n",
       "2023    1111\n",
       "2020     888\n",
       "2024     514\n",
       "2021      96\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['year'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network\n",
    "\n",
    "A Convolutional Neural Network (CNN) is a type of deep learning model that is particularly effective for pattern recognition tasks, especially in images and, increasingly, in text. Here’s how a CNN works in principle, broken down into its key components.\n",
    "\n",
    "Below is an explanation of how a basic CNN works:\n",
    "\n",
    "1. Convolutional Layer:\n",
    "\t- A CNN’s core layer is the convolutional layer, which applies filters (kernels) to small regions of the input data.\n",
    "\t- For text, a convolutional layer slides filters over sequences of words or tokens. Each filter is designed to detect specific patterns, such as n-grams (e.g., “not good” or “very interesting”) or word sequences relevant to the task.\n",
    "\t- The convolution operation outputs a feature map, where each entry represents the presence or strength of a detected pattern in a specific region of the input.\n",
    "    \n",
    "2.\tActivation Function (e.g., ReLU):\n",
    "\t- After convolution, an activation function (like ReLU) is applied to introduce non-linearity, allowing the network to model complex patterns.\n",
    "\t- This function essentially “activates” certain features, helping the network focus on meaningful patterns while ignoring less relevant details.\n",
    "\n",
    "3.\tPooling Layer:\n",
    "\t- A pooling layer (often Global Max Pooling for text data) is applied after convolution to reduce the dimensionality of the feature map, keeping only the most important features.\n",
    "\t- Pooling helps make the network more robust to minor variations and reduces the number of parameters, which speeds up training and helps prevent overfitting.\n",
    "\n",
    "4.\tFully Connected (Dense) Layer:\n",
    "\t- The pooled features are then passed through one or more fully connected (dense) layers. These layers process the extracted features, combining them to make predictions.\n",
    "\t- In text classification, a final dense layer with a sigmoid or softmax activation is often used to produce a probability score or class label for each input.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Convolutional Neural Network (Embedding Layer)\n",
    "\n",
    "- For our task of fake news classification, we add an embedding layer before the convolution layer. An embedding layer is often included to convert words into dense, continuous vector representations (embeddings) that capture semantic relationships.\n",
    "\n",
    "- An embedding layer provides input that’s suitable for convolution by encoding words as vectors. This way, the CNN can capture patterns in these representations rather than working with raw token IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dariusng2103/projects/mla_project/tf217/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4988 - loss: 2.0944 - val_accuracy: 0.7878 - val_loss: 0.7660\n",
      "Epoch 2/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7879 - loss: 0.8548 - val_accuracy: 0.7847 - val_loss: 0.6446\n",
      "Epoch 3/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8370 - loss: 0.6746 - val_accuracy: 0.8260 - val_loss: 0.5520\n",
      "Epoch 4/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8734 - loss: 0.5717 - val_accuracy: 0.8112 - val_loss: 0.5895\n",
      "Epoch 5/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9066 - loss: 0.4809 - val_accuracy: 0.8112 - val_loss: 0.6004\n",
      "Epoch 6/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9222 - loss: 0.4204 - val_accuracy: 0.7943 - val_loss: 0.6327\n",
      "Epoch 7/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9353 - loss: 0.3838 - val_accuracy: 0.8095 - val_loss: 0.6568\n",
      "Epoch 8/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9448 - loss: 0.3607 - val_accuracy: 0.8255 - val_loss: 0.6101\n",
      "Epoch 9/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9572 - loss: 0.3053 - val_accuracy: 0.8181 - val_loss: 0.6461\n",
      "Epoch 10/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9617 - loss: 0.2777 - val_accuracy: 0.8260 - val_loss: 0.6458\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step\n",
      "Fold Accuracy: 0.8260\n",
      "Fold F1 Score: 0.8440\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dariusng2103/projects/mla_project/tf217/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5433 - loss: 2.1004 - val_accuracy: 0.8138 - val_loss: 0.7483\n",
      "Epoch 2/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7623 - loss: 0.8803 - val_accuracy: 0.8047 - val_loss: 0.6556\n",
      "Epoch 3/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8279 - loss: 0.7011 - val_accuracy: 0.8377 - val_loss: 0.5669\n",
      "Epoch 4/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8683 - loss: 0.5895 - val_accuracy: 0.8277 - val_loss: 0.5789\n",
      "Epoch 5/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8928 - loss: 0.5201 - val_accuracy: 0.8034 - val_loss: 0.6295\n",
      "Epoch 6/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9222 - loss: 0.4494 - val_accuracy: 0.8238 - val_loss: 0.5879\n",
      "Epoch 7/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9358 - loss: 0.3986 - val_accuracy: 0.8194 - val_loss: 0.6197\n",
      "Epoch 8/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9520 - loss: 0.3374 - val_accuracy: 0.8424 - val_loss: 0.5862\n",
      "Epoch 9/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9564 - loss: 0.3090 - val_accuracy: 0.8207 - val_loss: 0.6326\n",
      "Epoch 10/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9657 - loss: 0.2885 - val_accuracy: 0.8403 - val_loss: 0.5978\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step\n",
      "Fold Accuracy: 0.8407\n",
      "Fold F1 Score: 0.8539\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dariusng2103/projects/mla_project/tf217/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4398 - loss: 2.1185 - val_accuracy: 0.8051 - val_loss: 0.7645\n",
      "Epoch 2/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7901 - loss: 0.8478 - val_accuracy: 0.7834 - val_loss: 0.6542\n",
      "Epoch 3/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8304 - loss: 0.6702 - val_accuracy: 0.7886 - val_loss: 0.6497\n",
      "Epoch 4/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8758 - loss: 0.5703 - val_accuracy: 0.8273 - val_loss: 0.5713\n",
      "Epoch 5/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9005 - loss: 0.5023 - val_accuracy: 0.8056 - val_loss: 0.6343\n",
      "Epoch 6/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9172 - loss: 0.4387 - val_accuracy: 0.8142 - val_loss: 0.6268\n",
      "Epoch 7/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9373 - loss: 0.3799 - val_accuracy: 0.8303 - val_loss: 0.6041\n",
      "Epoch 8/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9527 - loss: 0.3363 - val_accuracy: 0.8286 - val_loss: 0.6348\n",
      "Epoch 9/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9649 - loss: 0.2855 - val_accuracy: 0.8429 - val_loss: 0.6135\n",
      "Epoch 10/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9679 - loss: 0.2756 - val_accuracy: 0.8173 - val_loss: 0.6656\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step\n",
      "Fold Accuracy: 0.8173\n",
      "Fold F1 Score: 0.8390\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dariusng2103/projects/mla_project/tf217/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5092 - loss: 2.1264 - val_accuracy: 0.7790 - val_loss: 0.7998\n",
      "Epoch 2/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7906 - loss: 0.8417 - val_accuracy: 0.8224 - val_loss: 0.6153\n",
      "Epoch 3/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8417 - loss: 0.6656 - val_accuracy: 0.8359 - val_loss: 0.5705\n",
      "Epoch 4/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8789 - loss: 0.5758 - val_accuracy: 0.8189 - val_loss: 0.6085\n",
      "Epoch 5/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9002 - loss: 0.5008 - val_accuracy: 0.8281 - val_loss: 0.6221\n",
      "Epoch 6/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9205 - loss: 0.4305 - val_accuracy: 0.8254 - val_loss: 0.6644\n",
      "Epoch 7/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9417 - loss: 0.3706 - val_accuracy: 0.8315 - val_loss: 0.6599\n",
      "Epoch 8/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9499 - loss: 0.3362 - val_accuracy: 0.8246 - val_loss: 0.6594\n",
      "Epoch 9/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9647 - loss: 0.2848 - val_accuracy: 0.8046 - val_loss: 0.7191\n",
      "Epoch 10/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9681 - loss: 0.2636 - val_accuracy: 0.7994 - val_loss: 0.7285\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Fold Accuracy: 0.7994\n",
      "Fold F1 Score: 0.8239\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dariusng2103/projects/mla_project/tf217/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4122 - loss: 2.1396 - val_accuracy: 0.7455 - val_loss: 0.8344\n",
      "Epoch 2/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7635 - loss: 0.8797 - val_accuracy: 0.7838 - val_loss: 0.6928\n",
      "Epoch 3/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8430 - loss: 0.6750 - val_accuracy: 0.8372 - val_loss: 0.5756\n",
      "Epoch 4/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8797 - loss: 0.5740 - val_accuracy: 0.8489 - val_loss: 0.5260\n",
      "Epoch 5/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9080 - loss: 0.5010 - val_accuracy: 0.8081 - val_loss: 0.6503\n",
      "Epoch 6/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9296 - loss: 0.4153 - val_accuracy: 0.8597 - val_loss: 0.5227\n",
      "Epoch 7/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9513 - loss: 0.3515 - val_accuracy: 0.8485 - val_loss: 0.5657\n",
      "Epoch 8/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9612 - loss: 0.3125 - val_accuracy: 0.8597 - val_loss: 0.5378\n",
      "Epoch 9/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9687 - loss: 0.2754 - val_accuracy: 0.8602 - val_loss: 0.5456\n",
      "Epoch 10/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9736 - loss: 0.2508 - val_accuracy: 0.8619 - val_loss: 0.5355\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Fold Accuracy: 0.8619\n",
      "Fold F1 Score: 0.8662\n",
      "\n",
      "Cross-Validation Results:\n",
      "Average Accuracy: 0.8291\n",
      "Average F1 Score: 0.8454\n",
      "\n",
      "Average Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.8391    0.7608    0.7980      2441\n",
      "     Neutral     0.3576    0.6280    0.4557      1164\n",
      "    Positive     0.9587    0.8797    0.9175      7913\n",
      "\n",
      "    accuracy                         0.8291     11518\n",
      "   macro avg     0.7185    0.7562    0.7237     11518\n",
      "weighted avg     0.8726    0.8291    0.8455     11518\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Step 1: Tokenization and Padding\n",
    "max_words = 10000  # Maximum vocabulary size\n",
    "max_sequence_length = 300  # Maximum length of sequences\n",
    "\n",
    "# Assuming 'data' is your DataFrame with 'processed_full_review' and 'sentiment' columns\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(data['processed_full_review'])\n",
    "sequences = tokenizer.texts_to_sequences(data['processed_full_review'])\n",
    "\n",
    "# Pad sequences to ensure uniform length\n",
    "X = pad_sequences(sequences, maxlen=max_sequence_length)\n",
    "\n",
    "# One-hot encode the sentiment labels\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "y = onehot_encoder.fit_transform(data[['sentiment']])\n",
    "\n",
    "# Convert y to single-label format for compute_class_weight\n",
    "y_labels = np.argmax(y, axis=1)\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_labels), y=y_labels)\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# Define the Basic CNN Model with L2 Regularization\n",
    "def create_basic_cnn():\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Embedding layer\n",
    "    model.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_sequence_length))\n",
    "    \n",
    "    # Convolutional layer with L2 regularization\n",
    "    model.add(Conv1D(filters=128, kernel_size=5, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    \n",
    "    # Max pooling layer\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    \n",
    "    # Fully connected layer with L2 regularization\n",
    "    model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(0.5))  # Dropout for regularization\n",
    "    \n",
    "    # Output layer for three-class classification using softmax\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    \n",
    "    # Compile the model with Adam optimizer\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Step 2: Stratified K-Fold Cross-Validation\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "# Initialize lists to store all true and predicted labels across folds\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for train_index, val_index in kfold.split(X, y_labels):\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    \n",
    "    model = create_basic_cnn()\n",
    "    history = model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_val, y_val), verbose=1, class_weight=class_weights_dict)\n",
    "    \n",
    "    # Evaluate the model on the validation set\n",
    "    y_pred = np.argmax(model.predict(X_val), axis=1)\n",
    "    y_true = np.argmax(y_val, axis=1)\n",
    "    \n",
    "    # Store predictions and true labels\n",
    "    all_y_pred.extend(y_pred)\n",
    "    all_y_true.extend(y_true)\n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    accuracy_scores.append(accuracy)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "    print(f\"Fold Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Fold F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Print the average cross-validation results\n",
    "print(\"\\nCross-Validation Results:\")\n",
    "print(f\"Average Accuracy: {np.mean(accuracy_scores):.4f}\")\n",
    "print(f\"Average F1 Score: {np.mean(f1_scores):.4f}\")\n",
    "\n",
    "# Compute and print the classification report across all folds\n",
    "print(\"\\nAverage Classification Report:\")\n",
    "print(classification_report(all_y_true, all_y_pred, target_names=onehot_encoder.categories_[0], digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network + Count Vectorizer\n",
    "\n",
    "CountVec can be used for CNNs, but its not recommended as countvectorizer loses the meaningful sequential information of the reviews, making our model unable to capture semantic meaning and complex language patterns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dariusng2103/projects/mla_project/tf217/lib/python3.12/site-packages/keras/src/layers/reshaping/reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.2536 - loss: 1.7359 - val_accuracy: 0.2630 - val_loss: 1.3195\n",
      "Epoch 2/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.4360 - loss: 1.2230 - val_accuracy: 0.4583 - val_loss: 1.1956\n",
      "Epoch 3/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.4675 - loss: 1.1409 - val_accuracy: 0.5469 - val_loss: 1.1024\n",
      "Epoch 4/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5116 - loss: 1.1078 - val_accuracy: 0.5907 - val_loss: 1.0731\n",
      "Epoch 5/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5767 - loss: 1.0831 - val_accuracy: 0.5885 - val_loss: 1.0788\n",
      "Epoch 6/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5569 - loss: 1.0860 - val_accuracy: 0.5881 - val_loss: 1.0918\n",
      "Epoch 7/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.5508 - loss: 1.0874 - val_accuracy: 0.4136 - val_loss: 1.0904\n",
      "Epoch 8/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5493 - loss: 1.0767 - val_accuracy: 0.5881 - val_loss: 1.0731\n",
      "Epoch 9/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5685 - loss: 1.0679 - val_accuracy: 0.5590 - val_loss: 1.0503\n",
      "Epoch 10/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5571 - loss: 1.0734 - val_accuracy: 0.5881 - val_loss: 1.0908\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Fold Accuracy: 0.5881\n",
      "Fold F1 Score: 0.5745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dariusng2103/projects/mla_project/tf217/lib/python3.12/site-packages/keras/src/layers/reshaping/reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.2848 - loss: 1.7381 - val_accuracy: 0.4349 - val_loss: 1.2859\n",
      "Epoch 2/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.4345 - loss: 1.2360 - val_accuracy: 0.4761 - val_loss: 1.1582\n",
      "Epoch 3/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5164 - loss: 1.1268 - val_accuracy: 0.4210 - val_loss: 1.1153\n",
      "Epoch 4/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5499 - loss: 1.0906 - val_accuracy: 0.6159 - val_loss: 1.0764\n",
      "Epoch 5/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5436 - loss: 1.0872 - val_accuracy: 0.4753 - val_loss: 1.0959\n",
      "Epoch 6/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5549 - loss: 1.0881 - val_accuracy: 0.6159 - val_loss: 1.0772\n",
      "Epoch 7/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5633 - loss: 1.0798 - val_accuracy: 0.4753 - val_loss: 1.0912\n",
      "Epoch 8/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5491 - loss: 1.0757 - val_accuracy: 0.4740 - val_loss: 1.0953\n",
      "Epoch 9/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5265 - loss: 1.1090 - val_accuracy: 0.6159 - val_loss: 1.0368\n",
      "Epoch 10/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5680 - loss: 1.0877 - val_accuracy: 0.6159 - val_loss: 1.0456\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Fold Accuracy: 0.6159\n",
      "Fold F1 Score: 0.5962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dariusng2103/projects/mla_project/tf217/lib/python3.12/site-packages/keras/src/layers/reshaping/reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.2802 - loss: 1.7102 - val_accuracy: 0.1415 - val_loss: 1.2992\n",
      "Epoch 2/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.3339 - loss: 1.2307 - val_accuracy: 0.5894 - val_loss: 1.1426\n",
      "Epoch 3/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.4894 - loss: 1.1384 - val_accuracy: 0.6050 - val_loss: 1.0952\n",
      "Epoch 4/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.4929 - loss: 1.1284 - val_accuracy: 0.6042 - val_loss: 1.0691\n",
      "Epoch 5/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5568 - loss: 1.0941 - val_accuracy: 0.6042 - val_loss: 1.0583\n",
      "Epoch 6/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5451 - loss: 1.0948 - val_accuracy: 0.4089 - val_loss: 1.1079\n",
      "Epoch 7/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5244 - loss: 1.0960 - val_accuracy: 0.4115 - val_loss: 1.0905\n",
      "Epoch 8/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5174 - loss: 1.0978 - val_accuracy: 0.5894 - val_loss: 1.0501\n",
      "Epoch 9/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5613 - loss: 1.0883 - val_accuracy: 0.6042 - val_loss: 1.0554\n",
      "Epoch 10/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5550 - loss: 1.0727 - val_accuracy: 0.4497 - val_loss: 1.0889\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Fold Accuracy: 0.4497\n",
      "Fold F1 Score: 0.5005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dariusng2103/projects/mla_project/tf217/lib/python3.12/site-packages/keras/src/layers/reshaping/reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.2879 - loss: 1.7298 - val_accuracy: 0.4147 - val_loss: 1.2634\n",
      "Epoch 2/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.4167 - loss: 1.2247 - val_accuracy: 0.6756 - val_loss: 1.0851\n",
      "Epoch 3/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5232 - loss: 1.1291 - val_accuracy: 0.4815 - val_loss: 1.1333\n",
      "Epoch 4/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5197 - loss: 1.1101 - val_accuracy: 0.6235 - val_loss: 1.0621\n",
      "Epoch 5/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5559 - loss: 1.0808 - val_accuracy: 0.5758 - val_loss: 1.0685\n",
      "Epoch 6/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5338 - loss: 1.0847 - val_accuracy: 0.6231 - val_loss: 1.0661\n",
      "Epoch 7/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5335 - loss: 1.0838 - val_accuracy: 0.4003 - val_loss: 1.0983\n",
      "Epoch 8/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.4816 - loss: 1.0899 - val_accuracy: 0.5762 - val_loss: 1.0499\n",
      "Epoch 9/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5424 - loss: 1.0710 - val_accuracy: 0.5723 - val_loss: 1.0602\n",
      "Epoch 10/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5303 - loss: 1.0788 - val_accuracy: 0.5953 - val_loss: 1.0760\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Fold Accuracy: 0.5953\n",
      "Fold F1 Score: 0.5978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dariusng2103/projects/mla_project/tf217/lib/python3.12/site-packages/keras/src/layers/reshaping/reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.2774 - loss: 1.7265 - val_accuracy: 0.4842 - val_loss: 1.2564\n",
      "Epoch 2/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.4721 - loss: 1.2412 - val_accuracy: 0.6135 - val_loss: 1.1254\n",
      "Epoch 3/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5222 - loss: 1.1426 - val_accuracy: 0.6131 - val_loss: 1.0909\n",
      "Epoch 4/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5261 - loss: 1.1199 - val_accuracy: 0.6127 - val_loss: 1.0701\n",
      "Epoch 5/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5663 - loss: 1.0903 - val_accuracy: 0.5636 - val_loss: 1.0614\n",
      "Epoch 6/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5442 - loss: 1.0893 - val_accuracy: 0.5636 - val_loss: 1.0455\n",
      "Epoch 7/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5400 - loss: 1.0719 - val_accuracy: 0.4642 - val_loss: 1.0993\n",
      "Epoch 8/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5242 - loss: 1.0948 - val_accuracy: 0.4698 - val_loss: 1.0768\n",
      "Epoch 9/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5538 - loss: 1.0787 - val_accuracy: 0.6127 - val_loss: 1.0396\n",
      "Epoch 10/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5507 - loss: 1.0882 - val_accuracy: 0.4681 - val_loss: 1.0800\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold Accuracy: 0.4681\n",
      "Fold F1 Score: 0.4778\n",
      "\n",
      "Cross-Validation Results:\n",
      "Average Accuracy: 0.5434\n",
      "Average F1 Score: 0.5494\n",
      "\n",
      "Average Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.2822    0.4211    0.3379      2441\n",
      "     Neutral     0.1284    0.1297    0.1291      1164\n",
      "    Positive     0.7583    0.6420    0.6953      7913\n",
      "\n",
      "    accuracy                         0.5434     11518\n",
      "   macro avg     0.3896    0.3976    0.3874     11518\n",
      "weighted avg     0.5938    0.5434    0.5624     11518\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D, Dense, Dropout, Reshape\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "# Assuming 'data' is your DataFrame with 'processed_full_review' and 'sentiment' columns\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Step 1: Vectorization using CountVectorizer\n",
    "max_features = 10000  # Maximum vocabulary size\n",
    "count_vectorizer = CountVectorizer(max_features=max_features)\n",
    "X_counts = count_vectorizer.fit_transform(data['processed_full_review']).toarray()\n",
    "\n",
    "# One-hot encode the sentiment labels\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "y = onehot_encoder.fit_transform(data[['sentiment']])\n",
    "\n",
    "# Convert y to single-label format for compute_class_weight\n",
    "y_labels = np.argmax(y, axis=1)\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_labels), y=y_labels)\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# Define the CNN Model with L2 Regularization for Count Vectorized Input\n",
    "def create_cnn_with_countvec(input_shape):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Reshape input to add a third dimension (needed for Conv1D)\n",
    "    model.add(Reshape((input_shape, 1), input_shape=(input_shape,)))\n",
    "    \n",
    "    # Convolutional layer with L2 regularization\n",
    "    model.add(Conv1D(filters=128, kernel_size=5, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    \n",
    "    # Max pooling layer\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    \n",
    "    # Fully connected layer with L2 regularization\n",
    "    model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(0.5))  # Dropout for regularization\n",
    "    \n",
    "    # Output layer for three-class classification using softmax\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Step 2: Stratified K-Fold Cross-Validation\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "# Initialize lists to store all true and predicted labels across folds\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for train_index, val_index in kfold.split(X_counts, y_labels):\n",
    "    X_train, X_val = X_counts[train_index], X_counts[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    \n",
    "    model = create_cnn_with_countvec(input_shape=X_counts.shape[1])\n",
    "    history = model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_val, y_val), verbose=1, class_weight=class_weights_dict)\n",
    "    \n",
    "    # Evaluate the model on the validation set\n",
    "    y_pred = np.argmax(model.predict(X_val), axis=1)\n",
    "    y_true = np.argmax(y_val, axis=1)\n",
    "    \n",
    "    # Store predictions and true labels\n",
    "    all_y_pred.extend(y_pred)\n",
    "    all_y_true.extend(y_true)\n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    accuracy_scores.append(accuracy)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "    print(f\"Fold Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Fold F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Print the average cross-validation results\n",
    "print(\"\\nCross-Validation Results:\")\n",
    "print(f\"Average Accuracy: {np.mean(accuracy_scores):.4f}\")\n",
    "print(f\"Average F1 Score: {np.mean(f1_scores):.4f}\")\n",
    "\n",
    "# Compute and print the classification report across all folds\n",
    "print(\"\\nAverage Classification Report:\")\n",
    "print(classification_report(all_y_true, all_y_pred, target_names=onehot_encoder.categories_[0], digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network + Custom-trained Word2Vec embeddings\n",
    "\n",
    "In this case, we train the embedding layer on our dataset, which allows it to better capture domain-specific vocabulary, as compared to using pre-trained embeddings that are trained on a very large and general corpus.\n",
    "\n",
    "##### 1. Word embeddings capture the semantic relationships between words in a dense, low-dimensional space.\n",
    "Fake news often uses subtle language, and word embeddings like GloVe can capture the semantic context of words, allowing the model to understand relationships between words that simple vectorizers would miss. This helps in detecting nuanced differences in language use between real and fake news.\n",
    "\n",
    "##### 2. Word embeddings produce dense, low-dimensional vectors (e.g., 100-300 dimensions) that capture rich word information.\n",
    "Pre-trained embeddings are built on large corpora like Wikipedia and news articles, giving our model external knowledge that’s useful for distinguishing between real news and fake news. This boosts the model's ability to generalize on unseen test data from our web scraping.\n",
    "\n",
    "##### 3. Efficient Representation of Semantics\n",
    "Words in fake news can appear in different contexts, but with similar underlying meanings (e.g., \"hoax\" and \"lie\"). GloVe embeddings represent these similar words in close proximity in the vector space, helping the model recognize fake news patterns more effectively than TF-IDF or Count Vectorizer.\n",
    "\n",
    "##### 4. Handling Synonyms and Rare Words:\n",
    "Fake news often uses alternative phrases or rare terminology. Pre-trained embeddings like GloVe can handle these rare words because they’ve seen a broad variety of language during training, making our model more robust against unusual vocabulary choices in fake news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dariusng2103/projects/mla_project/tf217/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5984 - loss: 3.0157 - val_accuracy: 0.7556 - val_loss: 1.7562\n",
      "Epoch 2/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7553 - loss: 1.6927 - val_accuracy: 0.7860 - val_loss: 1.1453\n",
      "Epoch 3/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7855 - loss: 1.2064 - val_accuracy: 0.7969 - val_loss: 0.9125\n",
      "Epoch 4/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7957 - loss: 0.9847 - val_accuracy: 0.7756 - val_loss: 0.8460\n",
      "Epoch 5/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8047 - loss: 0.8770 - val_accuracy: 0.8125 - val_loss: 0.7014\n",
      "Epoch 6/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8078 - loss: 0.8094 - val_accuracy: 0.8199 - val_loss: 0.6655\n",
      "Epoch 7/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8169 - loss: 0.7732 - val_accuracy: 0.8390 - val_loss: 0.6177\n",
      "Epoch 8/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8275 - loss: 0.7411 - val_accuracy: 0.8277 - val_loss: 0.6210\n",
      "Epoch 9/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8247 - loss: 0.7170 - val_accuracy: 0.7934 - val_loss: 0.6629\n",
      "Epoch 10/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8331 - loss: 0.6891 - val_accuracy: 0.8121 - val_loss: 0.6368\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dariusng2103/projects/mla_project/tf217/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6044 - loss: 2.9858 - val_accuracy: 0.7148 - val_loss: 1.7278\n",
      "Epoch 2/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7393 - loss: 1.5952 - val_accuracy: 0.7487 - val_loss: 1.1425\n",
      "Epoch 3/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7689 - loss: 1.1497 - val_accuracy: 0.7982 - val_loss: 0.8741\n",
      "Epoch 4/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7902 - loss: 0.9606 - val_accuracy: 0.7630 - val_loss: 0.8419\n",
      "Epoch 5/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7999 - loss: 0.8571 - val_accuracy: 0.7604 - val_loss: 0.8097\n",
      "Epoch 6/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7939 - loss: 0.8258 - val_accuracy: 0.7700 - val_loss: 0.7686\n",
      "Epoch 7/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8125 - loss: 0.7655 - val_accuracy: 0.8003 - val_loss: 0.6827\n",
      "Epoch 8/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8118 - loss: 0.7542 - val_accuracy: 0.8103 - val_loss: 0.6677\n",
      "Epoch 9/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8156 - loss: 0.7332 - val_accuracy: 0.7530 - val_loss: 0.7873\n",
      "Epoch 10/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8189 - loss: 0.7095 - val_accuracy: 0.8390 - val_loss: 0.6016\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dariusng2103/projects/mla_project/tf217/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6059 - loss: 2.9026 - val_accuracy: 0.7582 - val_loss: 1.5678\n",
      "Epoch 2/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7642 - loss: 1.4759 - val_accuracy: 0.8025 - val_loss: 0.9643\n",
      "Epoch 3/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7812 - loss: 1.0500 - val_accuracy: 0.7613 - val_loss: 0.8924\n",
      "Epoch 4/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7968 - loss: 0.9053 - val_accuracy: 0.8082 - val_loss: 0.7260\n",
      "Epoch 5/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8087 - loss: 0.8298 - val_accuracy: 0.7999 - val_loss: 0.6911\n",
      "Epoch 6/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8178 - loss: 0.7693 - val_accuracy: 0.8190 - val_loss: 0.6435\n",
      "Epoch 7/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8204 - loss: 0.7465 - val_accuracy: 0.8177 - val_loss: 0.6251\n",
      "Epoch 8/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8250 - loss: 0.7142 - val_accuracy: 0.8181 - val_loss: 0.6117\n",
      "Epoch 9/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8254 - loss: 0.7129 - val_accuracy: 0.8151 - val_loss: 0.6302\n",
      "Epoch 10/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8351 - loss: 0.6868 - val_accuracy: 0.8043 - val_loss: 0.6629\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dariusng2103/projects/mla_project/tf217/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6161 - loss: 2.9597 - val_accuracy: 0.7134 - val_loss: 1.6718\n",
      "Epoch 2/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7447 - loss: 1.5338 - val_accuracy: 0.7885 - val_loss: 1.0439\n",
      "Epoch 3/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7790 - loss: 1.0783 - val_accuracy: 0.8094 - val_loss: 0.8372\n",
      "Epoch 4/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7978 - loss: 0.9019 - val_accuracy: 0.8133 - val_loss: 0.7591\n",
      "Epoch 5/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8120 - loss: 0.8301 - val_accuracy: 0.7972 - val_loss: 0.7339\n",
      "Epoch 6/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8003 - loss: 0.7892 - val_accuracy: 0.8254 - val_loss: 0.6577\n",
      "Epoch 7/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8189 - loss: 0.7443 - val_accuracy: 0.8076 - val_loss: 0.6674\n",
      "Epoch 8/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8216 - loss: 0.7304 - val_accuracy: 0.8129 - val_loss: 0.6564\n",
      "Epoch 9/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8307 - loss: 0.6927 - val_accuracy: 0.7655 - val_loss: 0.7404\n",
      "Epoch 10/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8256 - loss: 0.6943 - val_accuracy: 0.7742 - val_loss: 0.7021\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dariusng2103/projects/mla_project/tf217/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6352 - loss: 2.9363 - val_accuracy: 0.7703 - val_loss: 1.6386\n",
      "Epoch 2/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7439 - loss: 1.5933 - val_accuracy: 0.7712 - val_loss: 1.1508\n",
      "Epoch 3/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7706 - loss: 1.1504 - val_accuracy: 0.7955 - val_loss: 0.9230\n",
      "Epoch 4/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7823 - loss: 0.9576 - val_accuracy: 0.7586 - val_loss: 0.9156\n",
      "Epoch 5/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7944 - loss: 0.8659 - val_accuracy: 0.7460 - val_loss: 0.9270\n",
      "Epoch 6/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7929 - loss: 0.8191 - val_accuracy: 0.7742 - val_loss: 0.8077\n",
      "Epoch 7/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8075 - loss: 0.7793 - val_accuracy: 0.7620 - val_loss: 0.8354\n",
      "Epoch 8/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8107 - loss: 0.7607 - val_accuracy: 0.7647 - val_loss: 0.8137\n",
      "Epoch 9/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8143 - loss: 0.7308 - val_accuracy: 0.8033 - val_loss: 0.7265\n",
      "Epoch 10/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8223 - loss: 0.7179 - val_accuracy: 0.7933 - val_loss: 0.7341\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Tokenization parameters\n",
    "max_words = 10000\n",
    "max_sequence_length = 300\n",
    "embedding_dim = 200\n",
    "\n",
    "# Tokenize and create sequences\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(data['processed_full_review'])\n",
    "sequences = tokenizer.texts_to_sequences(data['processed_full_review'])\n",
    "X = pad_sequences(sequences, maxlen=max_sequence_length)\n",
    "\n",
    "# Encode labels and convert to categorical (one-hot encoding)\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(data['sentiment'])\n",
    "y = to_categorical(y)  # Convert labels to one-hot encoded format\n",
    "\n",
    "# Step 2: Train custom Word2Vec embeddings\n",
    "sentences = [text.split() for text in data['processed_full_review']]\n",
    "custom_word2vec = Word2Vec(sentences, vector_size=embedding_dim, window=5, min_count=2, workers=4)\n",
    "\n",
    "# Step 3: Create Embedding Matrix from Custom Word2Vec\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i < max_words and word in custom_word2vec.wv:\n",
    "        embedding_matrix[i] = custom_word2vec.wv[word]\n",
    "    else:\n",
    "        embedding_matrix[i] = np.random.normal(size=(embedding_dim,))\n",
    "\n",
    "# Step 4: Define CNN Model with Custom Word2Vec Embeddings\n",
    "def create_cnn_with_custom_word2vec():\n",
    "    input_layer = Input(shape=(max_sequence_length,))\n",
    "    embedding_layer = Embedding(input_dim=vocab_size,\n",
    "                                output_dim=embedding_dim,\n",
    "                                weights=[embedding_matrix],\n",
    "                                input_length=max_sequence_length,\n",
    "                                trainable=False)(input_layer)\n",
    "    \n",
    "    x = Conv1D(filters=128, kernel_size=5, activation='relu', kernel_regularizer=l2(0.01))(embedding_layer)\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    x = Dense(64, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output_layer = Dense(3, activation='softmax')(x)  # Output layer for multi-class classification\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Step 5: Stratified K-Fold Cross-Validation with Class Weights\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "classification_reports = []\n",
    "\n",
    "# Compute class weights\n",
    "y_labels = np.argmax(y, axis=1)  # Convert from one-hot to single-label format for class weight computation\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_labels), y=y_labels)\n",
    "class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "\n",
    "for train_index, val_index in kfold.split(X, y_labels):\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    \n",
    "    model = create_cnn_with_custom_word2vec()\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_val, y_val), \n",
    "              class_weight=class_weights_dict, verbose=1)\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    y_pred = np.argmax(model.predict(X_val), axis=1)\n",
    "    y_true = np.argmax(y_val, axis=1)\n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    # Append scores to the lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "    # Classification report\n",
    "    report = classification_report(y_true, y_pred, target_names=onehot_encoder.categories_[0], output_dict=True)\n",
    "    classification_reports.append(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Classification Report Across All Folds:\n",
      "--------------------------------------------------------------------------------\n",
      "       Label  Precision  Recall  F1-Score   Support\n",
      "    Negative     0.8054  0.7337    0.7615  488.2000\n",
      "     Neutral     0.3477  0.6752    0.4541  232.8000\n",
      "    Positive     0.9612  0.8454    0.8990 1582.6000\n",
      "   macro avg     0.7048  0.7514    0.7049 2303.6000\n",
      "weighted avg     0.8662  0.8046    0.8249 2303.6000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Average Accuracy: 0.8046\n",
      "Average F1-Score: 0.8249\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def print_average_classification_report(classification_reports):\n",
    "    \"\"\"\n",
    "    Calculate and print the average metrics across all cross-validation folds.\n",
    "    \n",
    "    Parameters:\n",
    "    classification_reports (list): List of classification_report dictionaries from sklearn\n",
    "    \"\"\"\n",
    "    # Initialize a dictionary to store the sum of metrics\n",
    "    metrics_sum = {}\n",
    "    \n",
    "    # Sum up all metrics across folds\n",
    "    for report in classification_reports:\n",
    "        for label, metrics in report.items():\n",
    "            if isinstance(metrics, dict):  # Skip non-dictionary entries\n",
    "                if label not in metrics_sum:\n",
    "                    metrics_sum[label] = {k: 0.0 for k in metrics.keys()}\n",
    "                for metric_name, value in metrics.items():\n",
    "                    metrics_sum[label][metric_name] += value\n",
    "    \n",
    "    # Calculate averages\n",
    "    n_folds = len(classification_reports)\n",
    "    avg_metrics = {\n",
    "        label: {metric: value/n_folds \n",
    "                for metric, value in metrics.items()}\n",
    "        for label, metrics in metrics_sum.items()\n",
    "    }\n",
    "    \n",
    "    # Create a DataFrame for better formatting\n",
    "    rows = []\n",
    "    for label in avg_metrics:\n",
    "        metrics = avg_metrics[label]\n",
    "        row = {\n",
    "            'Label': label,\n",
    "            'Precision': metrics['precision'],\n",
    "            'Recall': metrics['recall'],\n",
    "            'F1-Score': metrics['f1-score'],\n",
    "            'Support': metrics['support']\n",
    "        }\n",
    "        rows.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nAverage Classification Report Across All Folds:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(df.to_string(index=False, float_format=lambda x: '{:.4f}'.format(x) if isinstance(x, float) else str(x)))\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Print average accuracy and F1 scores\n",
    "    print(f\"\\nAverage Accuracy: {np.mean(accuracy_scores):.4f}\")\n",
    "    print(f\"Average F1-Score: {np.mean(f1_scores):.4f}\")\n",
    "\n",
    "# Usage example with your existing code:\n",
    "print_average_classification_report(classification_reports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network + FastText embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dariusng2103/projects/mla_project/tf217/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.5810 - loss: 2.6473 - val_accuracy: 0.8494 - val_loss: 1.0234\n",
      "Epoch 2/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7793 - loss: 1.1274 - val_accuracy: 0.8503 - val_loss: 0.6942\n",
      "Epoch 3/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8122 - loss: 0.8802 - val_accuracy: 0.8529 - val_loss: 0.6161\n",
      "Epoch 4/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8224 - loss: 0.7780 - val_accuracy: 0.8424 - val_loss: 0.5979\n",
      "Epoch 5/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8261 - loss: 0.7332 - val_accuracy: 0.8520 - val_loss: 0.5579\n",
      "Epoch 6/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8315 - loss: 0.7086 - val_accuracy: 0.8550 - val_loss: 0.5481\n",
      "Epoch 7/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8378 - loss: 0.6825 - val_accuracy: 0.8633 - val_loss: 0.5304\n",
      "Epoch 8/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8515 - loss: 0.6622 - val_accuracy: 0.8485 - val_loss: 0.5422\n",
      "Epoch 9/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8456 - loss: 0.6625 - val_accuracy: 0.8542 - val_loss: 0.5324\n",
      "Epoch 10/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8409 - loss: 0.6588 - val_accuracy: 0.8563 - val_loss: 0.5304\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666us/step\n",
      "\n",
      "Fold 1 Results:\n",
      "Accuracy: 0.8563\n",
      "F1 Score: 0.8586\n",
      "\n",
      "Classification Report for this fold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.9191    0.6516    0.7626       488\n",
      "     Neutral     0.4331    0.5837    0.4973       233\n",
      "    Positive     0.9240    0.9596    0.9414      1583\n",
      "\n",
      "    accuracy                         0.8563      2304\n",
      "   macro avg     0.7587    0.7316    0.7338      2304\n",
      "weighted avg     0.8733    0.8563    0.8586      2304\n",
      "\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dariusng2103/projects/mla_project/tf217/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6037 - loss: 2.5758 - val_accuracy: 0.8242 - val_loss: 1.0057\n",
      "Epoch 2/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7898 - loss: 1.0516 - val_accuracy: 0.8281 - val_loss: 0.7378\n",
      "Epoch 3/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8046 - loss: 0.8443 - val_accuracy: 0.8082 - val_loss: 0.7083\n",
      "Epoch 4/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8238 - loss: 0.7671 - val_accuracy: 0.8225 - val_loss: 0.6423\n",
      "Epoch 5/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8307 - loss: 0.7270 - val_accuracy: 0.8008 - val_loss: 0.6669\n",
      "Epoch 6/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8209 - loss: 0.7128 - val_accuracy: 0.8403 - val_loss: 0.5718\n",
      "Epoch 7/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8329 - loss: 0.6866 - val_accuracy: 0.8459 - val_loss: 0.5533\n",
      "Epoch 8/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8447 - loss: 0.6681 - val_accuracy: 0.8485 - val_loss: 0.5588\n",
      "Epoch 9/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8443 - loss: 0.6621 - val_accuracy: 0.8247 - val_loss: 0.5866\n",
      "Epoch 10/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8475 - loss: 0.6434 - val_accuracy: 0.8394 - val_loss: 0.5785\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step\n",
      "\n",
      "Fold 2 Results:\n",
      "Accuracy: 0.8394\n",
      "F1 Score: 0.8545\n",
      "\n",
      "Classification Report for this fold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.8130    0.8197    0.8163       488\n",
      "     Neutral     0.3909    0.6609    0.4912       233\n",
      "    Positive     0.9732    0.8718    0.9197      1583\n",
      "\n",
      "    accuracy                         0.8394      2304\n",
      "   macro avg     0.7257    0.7841    0.7424      2304\n",
      "weighted avg     0.8804    0.8394    0.8545      2304\n",
      "\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dariusng2103/projects/mla_project/tf217/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5878 - loss: 2.5293 - val_accuracy: 0.8147 - val_loss: 0.9824\n",
      "Epoch 2/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7979 - loss: 1.0192 - val_accuracy: 0.8455 - val_loss: 0.6669\n",
      "Epoch 3/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8112 - loss: 0.8224 - val_accuracy: 0.8359 - val_loss: 0.6203\n",
      "Epoch 4/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8258 - loss: 0.7562 - val_accuracy: 0.8529 - val_loss: 0.5680\n",
      "Epoch 5/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8421 - loss: 0.7246 - val_accuracy: 0.8472 - val_loss: 0.5477\n",
      "Epoch 6/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8295 - loss: 0.6968 - val_accuracy: 0.8533 - val_loss: 0.5394\n",
      "Epoch 7/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8441 - loss: 0.6698 - val_accuracy: 0.8472 - val_loss: 0.5426\n",
      "Epoch 8/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8475 - loss: 0.6594 - val_accuracy: 0.8420 - val_loss: 0.5461\n",
      "Epoch 9/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8489 - loss: 0.6465 - val_accuracy: 0.8550 - val_loss: 0.5392\n",
      "Epoch 10/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8347 - loss: 0.6713 - val_accuracy: 0.8442 - val_loss: 0.5639\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step\n",
      "\n",
      "Fold 3 Results:\n",
      "Accuracy: 0.8442\n",
      "F1 Score: 0.8574\n",
      "\n",
      "Classification Report for this fold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.8281    0.7500    0.7871       488\n",
      "     Neutral     0.4046    0.6824    0.5080       233\n",
      "    Positive     0.9666    0.8970    0.9305      1583\n",
      "\n",
      "    accuracy                         0.8442      2304\n",
      "   macro avg     0.7331    0.7765    0.7419      2304\n",
      "weighted avg     0.8804    0.8442    0.8574      2304\n",
      "\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dariusng2103/projects/mla_project/tf217/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6295 - loss: 2.5422 - val_accuracy: 0.7755 - val_loss: 1.0629\n",
      "Epoch 2/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7975 - loss: 1.0385 - val_accuracy: 0.8133 - val_loss: 0.7734\n",
      "Epoch 3/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8252 - loss: 0.8137 - val_accuracy: 0.8211 - val_loss: 0.6914\n",
      "Epoch 4/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8224 - loss: 0.7452 - val_accuracy: 0.8472 - val_loss: 0.6137\n",
      "Epoch 5/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8435 - loss: 0.7047 - val_accuracy: 0.8267 - val_loss: 0.6342\n",
      "Epoch 6/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8457 - loss: 0.6796 - val_accuracy: 0.7924 - val_loss: 0.6757\n",
      "Epoch 7/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8403 - loss: 0.6756 - val_accuracy: 0.8506 - val_loss: 0.5677\n",
      "Epoch 8/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8550 - loss: 0.6501 - val_accuracy: 0.8354 - val_loss: 0.5838\n",
      "Epoch 9/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8612 - loss: 0.6270 - val_accuracy: 0.8246 - val_loss: 0.6141\n",
      "Epoch 10/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8677 - loss: 0.6185 - val_accuracy: 0.8415 - val_loss: 0.5756\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Fold 4 Results:\n",
      "Accuracy: 0.8415\n",
      "F1 Score: 0.8556\n",
      "\n",
      "Classification Report for this fold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.8687    0.7459    0.8026       488\n",
      "     Neutral     0.4015    0.7082    0.5124       233\n",
      "    Positive     0.9566    0.8906    0.9224      1582\n",
      "\n",
      "    accuracy                         0.8415      2303\n",
      "   macro avg     0.7422    0.7816    0.7458      2303\n",
      "weighted avg     0.8818    0.8415    0.8556      2303\n",
      "\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dariusng2103/projects/mla_project/tf217/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6421 - loss: 2.5654 - val_accuracy: 0.8419 - val_loss: 1.0142\n",
      "Epoch 2/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7990 - loss: 1.0818 - val_accuracy: 0.8346 - val_loss: 0.7648\n",
      "Epoch 3/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8148 - loss: 0.8634 - val_accuracy: 0.8563 - val_loss: 0.6311\n",
      "Epoch 4/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8219 - loss: 0.7697 - val_accuracy: 0.8050 - val_loss: 0.7251\n",
      "Epoch 5/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8251 - loss: 0.7297 - val_accuracy: 0.8541 - val_loss: 0.5976\n",
      "Epoch 6/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8364 - loss: 0.7050 - val_accuracy: 0.8446 - val_loss: 0.6029\n",
      "Epoch 7/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8402 - loss: 0.6820 - val_accuracy: 0.8159 - val_loss: 0.6660\n",
      "Epoch 8/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8369 - loss: 0.6716 - val_accuracy: 0.8346 - val_loss: 0.6335\n",
      "Epoch 9/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8461 - loss: 0.6556 - val_accuracy: 0.8311 - val_loss: 0.6432\n",
      "Epoch 10/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8561 - loss: 0.6435 - val_accuracy: 0.8302 - val_loss: 0.6332\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Fold 5 Results:\n",
      "Accuracy: 0.8302\n",
      "F1 Score: 0.8484\n",
      "\n",
      "Classification Report for this fold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.8126    0.8691    0.8399       489\n",
      "     Neutral     0.3839    0.7198    0.5007       232\n",
      "    Positive     0.9814    0.8344    0.9019      1582\n",
      "\n",
      "    accuracy                         0.8302      2303\n",
      "   macro avg     0.7260    0.8078    0.7475      2303\n",
      "weighted avg     0.8854    0.8302    0.8484      2303\n",
      "\n",
      "\n",
      "Overall Cross-Validation Results:\n",
      "Average Accuracy: 0.8423 (±0.0084)\n",
      "Average F1 Score: 0.8549 (±0.0036)\n",
      "\n",
      "Final Classification Report on All Folds:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.8429    0.7673    0.8033      2441\n",
      "     Neutral     0.4011    0.6710    0.5021      1164\n",
      "    Positive     0.9590    0.8907    0.9236      7913\n",
      "\n",
      "    accuracy                         0.8423     11518\n",
      "   macro avg     0.7344    0.7763    0.7430     11518\n",
      "weighted avg     0.8781    0.8423    0.8555     11518\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from gensim.models import FastText\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Tokenization parameters\n",
    "max_words = 10000\n",
    "max_sequence_length = 300\n",
    "embedding_dim = 200\n",
    "\n",
    "# Tokenize and create sequences\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(data['processed_full_review'])\n",
    "sequences = tokenizer.texts_to_sequences(data['processed_full_review'])\n",
    "X = pad_sequences(sequences, maxlen=max_sequence_length)\n",
    "\n",
    "# Encode labels and convert to categorical\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(data['sentiment'])\n",
    "y = to_categorical(y)\n",
    "\n",
    "# Train FastText embeddings\n",
    "sentences = [text.split() for text in data['processed_full_review']]\n",
    "fasttext_model = FastText(sentences,\n",
    "                         vector_size=embedding_dim,\n",
    "                         window=5,\n",
    "                         min_count=2,\n",
    "                         workers=4,\n",
    "                         sg=1)\n",
    "\n",
    "# Create Embedding Matrix from FastText\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i < max_words:\n",
    "        try:\n",
    "            embedding_matrix[i] = fasttext_model.wv[word]\n",
    "        except KeyError:\n",
    "            embedding_matrix[i] = np.random.normal(size=(embedding_dim,))\n",
    "\n",
    "# Define CNN Model with FastText Embeddings\n",
    "def create_cnn_with_fasttext():\n",
    "    input_layer = Input(shape=(max_sequence_length,))\n",
    "    embedding_layer = Embedding(input_dim=vocab_size,\n",
    "                              output_dim=embedding_dim,\n",
    "                              weights=[embedding_matrix],\n",
    "                              input_length=max_sequence_length,\n",
    "                              trainable=False)(input_layer)\n",
    "    \n",
    "    x = Conv1D(filters=128, \n",
    "               kernel_size=5, \n",
    "               activation='relu', \n",
    "               kernel_regularizer=l2(0.01))(embedding_layer)\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    x = Dense(64, \n",
    "              activation='relu', \n",
    "              kernel_regularizer=l2(0.01))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output_layer = Dense(3, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Stratified K-Fold Cross-Validation\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists for storing metrics\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "# Compute class weights\n",
    "y_labels = np.argmax(y, axis=1)\n",
    "class_weights = compute_class_weight(class_weight='balanced',\n",
    "                                   classes=np.unique(y_labels),\n",
    "                                   y=y_labels)\n",
    "class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "\n",
    "# Training and evaluation loop\n",
    "for fold, (train_index, val_index) in enumerate(kfold.split(X, y_labels)):\n",
    "    print(f'\\nFold {fold + 1}')\n",
    "    \n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    \n",
    "    # Create and train model\n",
    "    model = create_cnn_with_fasttext()\n",
    "    history = model.fit(X_train, y_train,\n",
    "                       epochs=10,\n",
    "                       batch_size=64,\n",
    "                       validation_data=(X_val, y_val),\n",
    "                       class_weight=class_weights_dict,\n",
    "                       verbose=1)\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    y_pred = np.argmax(model.predict(X_val), axis=1)\n",
    "    y_true = np.argmax(y_val, axis=1)\n",
    "    \n",
    "    # Store predictions and true labels\n",
    "    all_y_true.extend(y_true)\n",
    "    all_y_pred.extend(y_pred)\n",
    "    \n",
    "    # Calculate fold metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    accuracy_scores.append(accuracy)\n",
    "    f1_scores.append(f1)\n",
    "    \n",
    "    print(f'\\nFold {fold + 1} Results:')\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'F1 Score: {f1:.4f}')\n",
    "    print('\\nClassification Report for this fold:')\n",
    "    print(classification_report(y_true, y_pred, \n",
    "                              target_names=label_encoder.classes_,\n",
    "                              digits=4))\n",
    "\n",
    "# Print overall results\n",
    "print('\\nOverall Cross-Validation Results:')\n",
    "print(f'Average Accuracy: {np.mean(accuracy_scores):.4f} (±{np.std(accuracy_scores):.4f})')\n",
    "print(f'Average F1 Score: {np.mean(f1_scores):.4f} (±{np.std(f1_scores):.4f})')\n",
    "\n",
    "# Print the final classification report on all predictions\n",
    "print('\\nFinal Classification Report on All Folds:')\n",
    "print(classification_report(all_y_true, \n",
    "                          all_y_pred,\n",
    "                          target_names=label_encoder.classes_,\n",
    "                          digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf217",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
