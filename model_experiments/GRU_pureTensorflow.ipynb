{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhancing Singapore Airlines' Service Through Automated Sentiment Analysis of Customer Reviews\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Motivation**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Singapore Airlines Customer Reviews Dataset Information\n",
    "\n",
    "The [Singapore Airlines Customer Reviews Dataset](https://www.kaggle.com/datasets/kanchana1990/singapore-airlines-reviews) aggregates 10,000 anonymized customer reviews, providing a broad perspective on the passenger experience with Singapore Airlines. \n",
    "\n",
    "The dimensions are shown below:\n",
    "- **`published_date`**: Date and time of review publication.\n",
    "- **`published_platform`**: Platform where the review was posted.\n",
    "- **`rating`**: Customer satisfaction rating, from 1 (lowest) to 5 (highest).\n",
    "- **`type`**: Specifies the content as a review.\n",
    "- **`text`**: Detailed customer feedback.\n",
    "- **`title`**: Summary of the review.\n",
    "- **`helpful_votes`**: Number of users finding the review helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gated Recurrent Unit(GRU)\n",
    "\n",
    "GRUs are primarily used neural networks in handling sequential data like text. They help the model to learn long-term dependencies in long texts, like remembering the context of earlier words in a sentence. This makes it especially effective in processing and predicting the sentiment of reviews. \n",
    "\n",
    "#### Common terms + definition:\n",
    "Embeddings - vector of numbers that capture meaning and relationships between words. They also reduce high dimensionality of laguage, into something the computer can easily understand.\n",
    "Embedding layer - Layer in deep learning models that learns these embeddings during training. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports specific to GRU\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import L1L2\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>processed_full_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>ok use airlin go singapor london heathrow issu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>Negative</td>\n",
       "      <td>don give money book paid receiv email confirm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>Positive</td>\n",
       "      <td>best airlin world best airlin world seat food ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>Negative</td>\n",
       "      <td>premium economi seat singapor airlin not worth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>Negative</td>\n",
       "      <td>imposs get promis refund book flight full mont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11513</th>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>Negative</td>\n",
       "      <td>websit buggi paid first busi class ticket webs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11514</th>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>Negative</td>\n",
       "      <td>reduc level qualiti servic fear futur airlin t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11515</th>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>Negative</td>\n",
       "      <td>chang would cost usd book ticket singapor airl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11516</th>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>Negative</td>\n",
       "      <td>disappoint flight check secur check frankfurt ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11517</th>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "      <td>Negative</td>\n",
       "      <td>frustrat experi tri book flight not never frus...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11518 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       year  month sentiment  \\\n",
       "0      2024      3   Neutral   \n",
       "1      2024      3  Negative   \n",
       "2      2024      3  Positive   \n",
       "3      2024      3  Negative   \n",
       "4      2024      3  Negative   \n",
       "...     ...    ...       ...   \n",
       "11513  2021     11  Negative   \n",
       "11514  2021     10  Negative   \n",
       "11515  2021     10  Negative   \n",
       "11516  2021      8  Negative   \n",
       "11517  2021      5  Negative   \n",
       "\n",
       "                                   processed_full_review  \n",
       "0      ok use airlin go singapor london heathrow issu...  \n",
       "1      don give money book paid receiv email confirm ...  \n",
       "2      best airlin world best airlin world seat food ...  \n",
       "3      premium economi seat singapor airlin not worth...  \n",
       "4      imposs get promis refund book flight full mont...  \n",
       "...                                                  ...  \n",
       "11513  websit buggi paid first busi class ticket webs...  \n",
       "11514  reduc level qualiti servic fear futur airlin t...  \n",
       "11515  chang would cost usd book ticket singapor airl...  \n",
       "11516  disappoint flight check secur check frankfurt ...  \n",
       "11517  frustrat experi tri book flight not never frus...  \n",
       "\n",
       "[11518 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"final_df.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Preparing data for GRU**\n",
    "\n",
    "It is important to understand that GRUs are unable to understand words in the traditional sense; instead, the words need to be tokenized into numerical representations that the model can process(Here they are converted into integers). These tokenized words are typically mapped to a vocabulary where each unique word is assigned a specific integer value.\n",
    "\n",
    "#### Tensorflow's Tokenizer or CountVectorization? :\n",
    "\n",
    "Unlike CountVectorization, which uses a bag-of-words model(sparse matrix of word counts) where the order of words is ignored and not compatible with embedding layers, Tensorflow's Tokenizer is more suitable as it preserves the word order in sequences and is directly compatible with embedding layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: {0: 1.5733801717408276, 1: 3.2973415132924337, 2: 0.4851657940663176}\n"
     ]
    }
   ],
   "source": [
    "# Extract features and labels\n",
    "X = data['processed_full_review'].values  # The reviews (features)\n",
    "y = data['sentiment'].values  # The sentiment labels\n",
    "\n",
    "# Directly apply one-hot encoding\n",
    "# Convert the categorical labels (e.g., \"positive\", \"neutral\", \"negative\") to one-hot encoded labels\n",
    "y = pd.get_dummies(y).values  # Automatically converts to one-hot\n",
    "\n",
    "# Tokenize and pad the text data\n",
    "tokenizer = Tokenizer(num_words=5000)  # Limit to top 5000 words\n",
    "tokenizer.fit_on_texts(X)\n",
    "X_tokenized = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "# Set a manageable padding length (e.g., 300 words)\n",
    "max_sequence_len = 300\n",
    "X_padded = pad_sequences(X_tokenized, maxlen=max_sequence_len)\n",
    "\n",
    "# Split the data into training and testing sets (70% training, 30% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y, test_size=0.3, random_state=42, stratify=np.argmax(y, axis=1))\n",
    "\n",
    "# Compute class weights based on the training labels\n",
    "y_train_labels = np.argmax(y_train, axis=1)  # Convert one-hot to single-label encoding for class weights\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train_labels), y=y_train_labels)\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "print(\"Class Weights:\", class_weights_dict)  # Check the weights calculated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Building the GRU Model**\n",
    "These integers are then fed into the GRU model. However, just converting words into integers is not enough to gain an understanding for their meaning. \n",
    "\n",
    "To give the model more context about the relationships between words, word embeddings (created by the Embedding layer in Keras) are used, which transform these integer tokens into dense vectors of real numbers that capture semantic meaning such as the similarity between words(Something the CountVectorizer cannot do).\n",
    "\n",
    "#### Tensorflow's embedding or Word2Vec embedding? :\n",
    "Word2Vec creates word embeddings __outside__ of the deep learning model (in this case we used Gensim), these embeddings are fixed and used directly in any downstream model. After training with Word2Vec, the embeddings are loaded into the model as __pre-trained embeddings__. This may potentially result in missing task-specific nuances(domain specific language).\n",
    "\n",
    "The embedding layer in the tensorflow model is responsible for learning the word embeddings __during model training__. Hence the embeddings learned are __optimized for your dataset__ and the specific task at hand (such as sentiment classification). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "202/202 [==============================] - 8s 29ms/step - loss: 1.3858 - accuracy: 0.7066 - val_loss: 0.6364 - val_accuracy: 0.8035\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 5s 27ms/step - loss: 0.6983 - accuracy: 0.7989 - val_loss: 0.6725 - val_accuracy: 0.7688\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 5s 27ms/step - loss: 0.5319 - accuracy: 0.8513 - val_loss: 0.6497 - val_accuracy: 0.7477\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 6s 28ms/step - loss: 0.3976 - accuracy: 0.8916 - val_loss: 0.6330 - val_accuracy: 0.7905\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 6s 28ms/step - loss: 0.3156 - accuracy: 0.9209 - val_loss: 0.7353 - val_accuracy: 0.7849\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 5s 27ms/step - loss: 0.2378 - accuracy: 0.9442 - val_loss: 0.8965 - val_accuracy: 0.7849\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 6s 28ms/step - loss: 0.1968 - accuracy: 0.9564 - val_loss: 0.7592 - val_accuracy: 0.7874\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 6s 28ms/step - loss: 0.1746 - accuracy: 0.9626 - val_loss: 0.8405 - val_accuracy: 0.7979\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 5s 27ms/step - loss: 0.2090 - accuracy: 0.9552 - val_loss: 0.8514 - val_accuracy: 0.7657\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 6s 28ms/step - loss: 0.1445 - accuracy: 0.9681 - val_loss: 0.9061 - val_accuracy: 0.8060\n",
      "108/108 [==============================] - 1s 11ms/step - loss: 0.8983 - accuracy: 0.8131\n",
      "Test Loss: 0.8983107805252075\n",
      "Test Accuracy: 81.31%\n",
      "108/108 [==============================] - 1s 11ms/step\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.7643    0.7299    0.7467       733\n",
      "     Neutral     0.3388    0.4126    0.3721       349\n",
      "    Positive     0.9142    0.8976    0.9058      2374\n",
      "\n",
      "    accuracy                         0.8131      3456\n",
      "   macro avg     0.6724    0.6800    0.6749      3456\n",
      "weighted avg     0.8243    0.8131    0.8182      3456\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Basic GRU model build\n",
    "model = Sequential()\n",
    "\n",
    "# Adding an Embedding layer to turn words into dense vectors\n",
    "model.add(Embedding(input_dim=5000, output_dim=128))\n",
    "\n",
    "# Add a GRU layer with 128 units(or neurons)\n",
    "# The parameter units specifies the number of GRU neurons in this layer\n",
    "# return_sequences = False tells the GRU to output only the final hidden state, more suitable for sentence classification\n",
    "model.add(GRU(units=64, return_sequences=False,kernel_regularizer=L1L2(l1=0.001, l2=0.001))) #0.01 = 73.81%, loss: 0.8660\n",
    "\n",
    "# Add a dropout layer to prevent overfitting\n",
    "# By dropping neurons randomly while training, it ensures the model is not overly-reliant on a single neuron\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Output layer (for 3 classes: positive, neutral, negative)\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "# Categorical cross entropy is useful for multiclass problems (Calculates how far/close the predicted probability distribution is from the actual distribution of the target class)\n",
    "# 'accuracy' is currently the key performance metric that is being tracked, perhaps can change to recall to make misclassifying negative more costly?\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Fit the model with specified number of epochs\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=10,             # Number of epochs (you can adjust this number)\n",
    "                    batch_size=32,          # Batch size\n",
    "                    validation_split=0.2,   # 20% of the training data will be used for validation\n",
    "                    class_weight=class_weights_dict)  # Optionally include class weights if the dataset is imbalanced\n",
    "\n",
    "\n",
    "# Evaluate the optimized model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Test loss has no inherent meaning unless compared to other models, lower the better\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Print classification report for detailed metrics per class\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=[\"Negative\", \"Neutral\", \"Positive\"], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU model with dynamic models\n",
    "max_sequence_len = max([len(x) for x in X_tokenized])\n",
    "def create_gru_model(input_dimensions=5000, output_dimensions=128, gru_units=128, dropout_rate=0.2, learning_rate=0.001):\n",
    "    # Build the GRU model\n",
    "    model = Sequential()   \n",
    "\n",
    "    # Adding an Embedding layer to turn words into dense vectors\n",
    "    # input_dim - Vocabulary size for the Embedding layer\n",
    "    # output_dim - dimension of dense embedding vectors/number of numbers each word will be represented by \n",
    "    model.add(Embedding(input_dim=input_dimensions, output_dim=output_dimensions))\n",
    "\n",
    "    # Add a GRU layer with 128 units(or neurons)\n",
    "    # The parameter units specifies the number of GRU neurons in this layer\n",
    "    # return_sequences = False tells the GRU to output only the final hidden state, more suitable for sentence classification\n",
    "    model.add(GRU(units=gru_units, return_sequences=False))\n",
    "\n",
    "    # Add a dropout layer to prevent overfitting\n",
    "    # By dropping neurons randomly while training, it ensures the model is not overly-reliant on a single neuron\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Output layer (for 3 classes: positive, neutral, negative)\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    # Categorical cross entropy is useful for multiclass problems(Calculates how far/close the predicted probability distribution is from the actual distribution of the target class)\n",
    "    # 'accuracy' is currently the key performance metric that is being tracked, perhaps can change to recall to make misclassifying negative more costly?\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    " \n",
    "    return model \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Adam(Adaptive Moment Estimation):**\n",
    "A popular optimization algorithm that adjusts the learning rate during training for each parameter. \n",
    "\n",
    "Key features:\n",
    "\n",
    "1. Adaptive Learning Rates: Adam adjusts the learning rates for different parameters individually, allowing the model to converge faster and more effectively.\n",
    "\n",
    "2. Momentum: Adam uses momentum to accelerate gradient descent, especially in the presence of noise or small gradients.\n",
    "\n",
    "Adam is widely used because it combines the advantages of two other optimizers: AdaGrad(Algorithm that works well with spare gradients) and RMSProp(works well in non-stationary gradients)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GRU Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grid to test for cross validation \n",
    "param_grid = {\n",
    "    'model__input_dimensions': [1000, 5000],\n",
    "    'model__output_dimensions': [128],\n",
    "    'model__gru_units': [128, 256],\n",
    "    'model__dropout_rate': [0.1, 0.3],\n",
    "    'model__learning_rate': [0.001, 0.01],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the best parameters for the GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "42/42 [==============================] - 3s 33ms/step - loss: 0.8296 - accuracy: 0.6770\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.5699 - accuracy: 0.7693\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.4361 - accuracy: 0.8297\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.3581 - accuracy: 0.8575\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.3258 - accuracy: 0.8722\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2939 - accuracy: 0.8906\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2612 - accuracy: 0.9032\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.2414 - accuracy: 0.9077\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.2181 - accuracy: 0.9189\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.2014 - accuracy: 0.9282\n",
      "21/21 [==============================] - 1s 14ms/step\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 3s 33ms/step - loss: 0.8176 - accuracy: 0.6776\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 0.5204 - accuracy: 0.7872\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.4036 - accuracy: 0.8433\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.3557 - accuracy: 0.8605\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.3182 - accuracy: 0.8753\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.2847 - accuracy: 0.8954\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.2599 - accuracy: 0.9047\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.2378 - accuracy: 0.9140\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.2136 - accuracy: 0.9213\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.1979 - accuracy: 0.9256\n",
      "21/21 [==============================] - 1s 13ms/step\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 3s 32ms/step - loss: 0.8249 - accuracy: 0.6826\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.5185 - accuracy: 0.7914\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.3797 - accuracy: 0.8499\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.3399 - accuracy: 0.8653\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.2944 - accuracy: 0.8869\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.2606 - accuracy: 0.9055\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.2376 - accuracy: 0.9124\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.2162 - accuracy: 0.9220\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.1925 - accuracy: 0.9271\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.1676 - accuracy: 0.9418\n",
      "21/21 [==============================] - 1s 16ms/step\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 4s 34ms/step - loss: 0.7052 - accuracy: 0.7585\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.3565 - accuracy: 0.8640\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.2581 - accuracy: 0.8995\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.1946 - accuracy: 0.9308\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.1794 - accuracy: 0.9351\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.1199 - accuracy: 0.9561\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.0715 - accuracy: 0.9758\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0646 - accuracy: 0.9784\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0486 - accuracy: 0.9831\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.0676 - accuracy: 0.9753\n",
      "21/21 [==============================] - 1s 18ms/step\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 3s 37ms/step - loss: 0.6450 - accuracy: 0.7505\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3767 - accuracy: 0.8569\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.2629 - accuracy: 0.8993\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.1964 - accuracy: 0.9286\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.1402 - accuracy: 0.9490\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.1113 - accuracy: 0.9602\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0868 - accuracy: 0.9661\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.0665 - accuracy: 0.9767\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.0636 - accuracy: 0.9766\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.0465 - accuracy: 0.9833\n",
      "21/21 [==============================] - 1s 16ms/step\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 3s 38ms/step - loss: 0.6367 - accuracy: 0.7494\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.3333 - accuracy: 0.8683\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.2482 - accuracy: 0.9077\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.1734 - accuracy: 0.9351\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.1163 - accuracy: 0.9600\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.0883 - accuracy: 0.9695\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.0738 - accuracy: 0.9749\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.0718 - accuracy: 0.9745\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.0708 - accuracy: 0.9754\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 0.0521 - accuracy: 0.9825\n",
      "21/21 [==============================] - 1s 15ms/step\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 3s 33ms/step - loss: 0.8247 - accuracy: 0.6758\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.4765 - accuracy: 0.8096\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.3247 - accuracy: 0.8666\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.2526 - accuracy: 0.8941\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.1931 - accuracy: 0.9339\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.1383 - accuracy: 0.9546\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0937 - accuracy: 0.9697\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0684 - accuracy: 0.9775\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.0539 - accuracy: 0.9834\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.0326 - accuracy: 0.9890\n",
      "21/21 [==============================] - 1s 13ms/step\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 3s 32ms/step - loss: 0.8166 - accuracy: 0.6746\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.4725 - accuracy: 0.8087\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.3867 - accuracy: 0.8515\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.2702 - accuracy: 0.8871\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.1890 - accuracy: 0.9371\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.1305 - accuracy: 0.9591\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0915 - accuracy: 0.9704\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.0584 - accuracy: 0.9838\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0374 - accuracy: 0.9888\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.0425 - accuracy: 0.9864\n",
      "21/21 [==============================] - 1s 14ms/step\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 3s 34ms/step - loss: 0.7992 - accuracy: 0.6895\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.4929 - accuracy: 0.8104\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.3365 - accuracy: 0.8647\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2525 - accuracy: 0.8902\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.1851 - accuracy: 0.9289\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.1366 - accuracy: 0.9570\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0969 - accuracy: 0.9704\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0634 - accuracy: 0.9821\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0627 - accuracy: 0.9812\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0482 - accuracy: 0.9831\n",
      "21/21 [==============================] - 1s 13ms/step\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 2s 31ms/step - loss: 0.6981 - accuracy: 0.7579\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.3093 - accuracy: 0.8813\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.1579 - accuracy: 0.9444\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0828 - accuracy: 0.9741\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0421 - accuracy: 0.9872\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0284 - accuracy: 0.9900\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0212 - accuracy: 0.9913\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0167 - accuracy: 0.9940\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0139 - accuracy: 0.9948\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0122 - accuracy: 0.9965\n",
      "21/21 [==============================] - 1s 14ms/step\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 3s 35ms/step - loss: 0.6450 - accuracy: 0.7518\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.2874 - accuracy: 0.8954\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.1481 - accuracy: 0.9481\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.0723 - accuracy: 0.9754\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0390 - accuracy: 0.9859\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0320 - accuracy: 0.9877\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.0203 - accuracy: 0.9929\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0143 - accuracy: 0.9950\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0106 - accuracy: 0.9970\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0240 - accuracy: 0.9927\n",
      "21/21 [==============================] - 1s 13ms/step\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 3s 32ms/step - loss: 0.6410 - accuracy: 0.7589\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.3001 - accuracy: 0.8873\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.1536 - accuracy: 0.9447\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0761 - accuracy: 0.9749\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0470 - accuracy: 0.9849\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0261 - accuracy: 0.9924\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0182 - accuracy: 0.9952\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0141 - accuracy: 0.9952\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0208 - accuracy: 0.9933\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0213 - accuracy: 0.9927\n",
      "21/21 [==============================] - 1s 13ms/step\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 3s 42ms/step - loss: 0.7867 - accuracy: 0.6909\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.4773 - accuracy: 0.8182\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.3964 - accuracy: 0.8465\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.3604 - accuracy: 0.8597\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.3104 - accuracy: 0.8815\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.2801 - accuracy: 0.8934\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.2447 - accuracy: 0.9066\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.2136 - accuracy: 0.9191\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.1986 - accuracy: 0.9265\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.1779 - accuracy: 0.9369\n",
      "21/21 [==============================] - 1s 16ms/step\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 3s 42ms/step - loss: 0.7872 - accuracy: 0.6884\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.5233 - accuracy: 0.7909\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.3971 - accuracy: 0.8461\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.3446 - accuracy: 0.8662\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.2953 - accuracy: 0.8925\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.2622 - accuracy: 0.9059\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.2377 - accuracy: 0.9129\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.2115 - accuracy: 0.9267\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.2017 - accuracy: 0.9293\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.1773 - accuracy: 0.9377\n",
      "21/21 [==============================] - 1s 16ms/step\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 3s 44ms/step - loss: 0.7796 - accuracy: 0.6897\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.5381 - accuracy: 0.7911\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.4137 - accuracy: 0.8372\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.3613 - accuracy: 0.8610\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.3102 - accuracy: 0.8787\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.3043 - accuracy: 0.8876\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.2534 - accuracy: 0.9042\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.2219 - accuracy: 0.9172\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.1905 - accuracy: 0.9312\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.1638 - accuracy: 0.9397\n",
      "21/21 [==============================] - 1s 17ms/step\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 3s 45ms/step - loss: nan - accuracy: 0.5257\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.2134\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.2134\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.2134\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.2134\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.2134\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.2134\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.2134\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.2134\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.2134\n",
      "21/21 [==============================] - 1s 16ms/step\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 3s 42ms/step - loss: nan - accuracy: 0.5901\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.2128\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.2128\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.2128\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.2128\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.2128\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.2128\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.2128\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.2128\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.2128\n",
      "21/21 [==============================] - 1s 16ms/step\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 3s 42ms/step - loss: 0.7381 - accuracy: 0.7379\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.4688\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.2093\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.2093\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.2093\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.2093\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 2s 41ms/step - loss: nan - accuracy: 0.2093\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.2093\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.2093\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.2093\n",
      "21/21 [==============================] - 1s 16ms/step\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 3s 43ms/step - loss: 0.7868 - accuracy: 0.6846\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.4786 - accuracy: 0.8156\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.3271 - accuracy: 0.8666\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.2396 - accuracy: 0.9053\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.1813 - accuracy: 0.9405\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.1300 - accuracy: 0.9542\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.0911 - accuracy: 0.9695\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.0612 - accuracy: 0.9808\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.0420 - accuracy: 0.9870\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.0239 - accuracy: 0.9929\n",
      "21/21 [==============================] - 1s 16ms/step\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 3s 43ms/step - loss: 0.8361 - accuracy: 0.6753\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.5349 - accuracy: 0.7808\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.3468 - accuracy: 0.8597\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.2558 - accuracy: 0.9005\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.1737 - accuracy: 0.9421\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.1165 - accuracy: 0.9609\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.0794 - accuracy: 0.9767\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.0826 - accuracy: 0.9732\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.0556 - accuracy: 0.9834\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.0310 - accuracy: 0.9918\n",
      "21/21 [==============================] - 1s 16ms/step\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 3s 43ms/step - loss: 0.7861 - accuracy: 0.6917\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.4426 - accuracy: 0.8260\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.4937 - accuracy: 0.8283\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.3488 - accuracy: 0.8534\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.2587 - accuracy: 0.8969\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.1746 - accuracy: 0.9425\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.1171 - accuracy: 0.9654\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.0673 - accuracy: 0.9803\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.0483 - accuracy: 0.9870\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.0463 - accuracy: 0.9864\n",
      "21/21 [==============================] - 1s 16ms/step\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 3s 43ms/step - loss: 0.8417 - accuracy: 0.6885\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.7923 - accuracy: 0.6898\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.5795 - accuracy: 0.7739\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.4424 - accuracy: 0.8322\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.3669 - accuracy: 0.8653\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.2928 - accuracy: 0.8919\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.2346 - accuracy: 0.9148\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.1951 - accuracy: 0.9295\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.1567 - accuracy: 0.9457\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.1372 - accuracy: 0.9553\n",
      "21/21 [==============================] - 1s 15ms/step\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 3s 43ms/step - loss: 0.7656 - accuracy: 0.7371\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.7963 - accuracy: 0.6690\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.6222 - accuracy: 0.7691\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.5105 - accuracy: 0.8141\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.4279 - accuracy: 0.8456\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.3669 - accuracy: 0.8677\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.3177 - accuracy: 0.8865\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.2782 - accuracy: 0.9062\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.2303 - accuracy: 0.9232\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.2040 - accuracy: 0.9353\n",
      "21/21 [==============================] - 1s 16ms/step\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 3s 42ms/step - loss: nan - accuracy: 0.6352\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.2093\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.2093\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.2093\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.2093\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.2093\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.2093\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.2093\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.2093\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.2093\n",
      "21/21 [==============================] - 1s 16ms/step\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 3s 32ms/step - loss: 0.8258 - accuracy: 0.6764\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.5153 - accuracy: 0.7940\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.3841 - accuracy: 0.8474\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.3422 - accuracy: 0.8638\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.3121 - accuracy: 0.8800\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.2850 - accuracy: 0.8971\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.2598 - accuracy: 0.9012\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.2242 - accuracy: 0.9207\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.2064 - accuracy: 0.9259\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.1922 - accuracy: 0.9321\n",
      "21/21 [==============================] - 1s 14ms/step\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 3s 33ms/step - loss: 0.8301 - accuracy: 0.6720\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.5286 - accuracy: 0.7870\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.4641 - accuracy: 0.8180\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.3745 - accuracy: 0.8500\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.3301 - accuracy: 0.8716\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.2891 - accuracy: 0.8949\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.2625 - accuracy: 0.9033\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.2391 - accuracy: 0.9144\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.2171 - accuracy: 0.9222\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.2128 - accuracy: 0.9265\n",
      "21/21 [==============================] - 1s 13ms/step\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 3s 32ms/step - loss: 0.8228 - accuracy: 0.6830\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.5372 - accuracy: 0.7862\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.3967 - accuracy: 0.8441\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.3404 - accuracy: 0.8647\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.2953 - accuracy: 0.8839\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.2669 - accuracy: 0.9027\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.2819 - accuracy: 0.8945\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.2312 - accuracy: 0.9144\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.2057 - accuracy: 0.9226\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.1750 - accuracy: 0.9369\n",
      "21/21 [==============================] - 1s 15ms/step\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 2s 32ms/step - loss: 0.6076 - accuracy: 0.7668\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.3514 - accuracy: 0.8623\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.2631 - accuracy: 0.9021\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.2037 - accuracy: 0.9282\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.1549 - accuracy: 0.9438\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.1220 - accuracy: 0.9576\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0750 - accuracy: 0.9749\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0751 - accuracy: 0.9745\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0791 - accuracy: 0.9713\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0980 - accuracy: 0.9643\n",
      "21/21 [==============================] - 1s 14ms/step\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 3s 32ms/step - loss: 0.7641 - accuracy: 0.7375\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.3890 - accuracy: 0.8549\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.2861 - accuracy: 0.8915\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.2088 - accuracy: 0.9206\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.1646 - accuracy: 0.9388\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.1245 - accuracy: 0.9548\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0787 - accuracy: 0.9721\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0642 - accuracy: 0.9758\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0652 - accuracy: 0.9777\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0746 - accuracy: 0.9751\n",
      "21/21 [==============================] - 1s 13ms/step\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 3s 32ms/step - loss: 0.6786 - accuracy: 0.7453\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.3583 - accuracy: 0.8640\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.2527 - accuracy: 0.9057\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.1837 - accuracy: 0.9358\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.1488 - accuracy: 0.9462\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.1011 - accuracy: 0.9656\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0969 - accuracy: 0.9660\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0822 - accuracy: 0.9732\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0656 - accuracy: 0.9758\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0626 - accuracy: 0.9777\n",
      "21/21 [==============================] - 1s 15ms/step\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 3s 33ms/step - loss: 0.8147 - accuracy: 0.6742\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.4747 - accuracy: 0.8162\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.3329 - accuracy: 0.8645\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.2620 - accuracy: 0.8891\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.2066 - accuracy: 0.9220\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.1521 - accuracy: 0.9481\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0988 - accuracy: 0.9669\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0728 - accuracy: 0.9782\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0555 - accuracy: 0.9838\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0485 - accuracy: 0.9842\n",
      "21/21 [==============================] - 1s 14ms/step\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 3s 33ms/step - loss: 0.8199 - accuracy: 0.6752\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.4829 - accuracy: 0.8052\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.3312 - accuracy: 0.8642\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.2767 - accuracy: 0.8847\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.2062 - accuracy: 0.9207\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.1567 - accuracy: 0.9500\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.1052 - accuracy: 0.9673\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0739 - accuracy: 0.9758\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0544 - accuracy: 0.9849\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0580 - accuracy: 0.9816\n",
      "21/21 [==============================] - 1s 15ms/step\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 3s 33ms/step - loss: 0.8038 - accuracy: 0.6884\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.4848 - accuracy: 0.8147\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.3293 - accuracy: 0.8677\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.2543 - accuracy: 0.8893\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.1914 - accuracy: 0.9239\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.1609 - accuracy: 0.9498\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.1131 - accuracy: 0.9656\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0813 - accuracy: 0.9732\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0533 - accuracy: 0.9866\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0390 - accuracy: 0.9901\n",
      "21/21 [==============================] - 1s 14ms/step\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 3s 33ms/step - loss: 0.6759 - accuracy: 0.7387\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.3422 - accuracy: 0.8746\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.1913 - accuracy: 0.9297\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0991 - accuracy: 0.9658\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0543 - accuracy: 0.9823\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0270 - accuracy: 0.9916\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0229 - accuracy: 0.9926\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0185 - accuracy: 0.9935\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0162 - accuracy: 0.9948\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0226 - accuracy: 0.9924\n",
      "21/21 [==============================] - 1s 13ms/step\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 3s 33ms/step - loss: 0.6568 - accuracy: 0.7354\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.3507 - accuracy: 0.8621\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.1871 - accuracy: 0.9304\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0873 - accuracy: 0.9678\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0615 - accuracy: 0.9788\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0341 - accuracy: 0.9892\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0218 - accuracy: 0.9931\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0144 - accuracy: 0.9953\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0210 - accuracy: 0.9909\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0291 - accuracy: 0.9907\n",
      "21/21 [==============================] - 1s 14ms/step\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 3s 33ms/step - loss: 0.7439 - accuracy: 0.7520\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.3081 - accuracy: 0.8867\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.1564 - accuracy: 0.9451\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0989 - accuracy: 0.9676\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0598 - accuracy: 0.9808\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0405 - accuracy: 0.9849\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0328 - accuracy: 0.9894\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0119 - accuracy: 0.9965\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0201 - accuracy: 0.9927\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0172 - accuracy: 0.9952\n",
      "21/21 [==============================] - 1s 14ms/step\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 3s 42ms/step - loss: 0.8060 - accuracy: 0.6814\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.6217 - accuracy: 0.7728\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.4718 - accuracy: 0.8124\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.3793 - accuracy: 0.8483\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.3317 - accuracy: 0.8703\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.2912 - accuracy: 0.8897\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.2620 - accuracy: 0.9047\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.2371 - accuracy: 0.9129\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.2091 - accuracy: 0.9271\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.1797 - accuracy: 0.9399\n",
      "21/21 [==============================] - 1s 16ms/step\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 3s 43ms/step - loss: 0.7878 - accuracy: 0.6835\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.5140 - accuracy: 0.8033\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.5560 - accuracy: 0.7870\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.4156 - accuracy: 0.8314\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.3534 - accuracy: 0.8605\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.2924 - accuracy: 0.8940\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.2546 - accuracy: 0.9103\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.2306 - accuracy: 0.9168\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.2007 - accuracy: 0.9297\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.1807 - accuracy: 0.9379\n",
      "21/21 [==============================] - 1s 16ms/step\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 3s 42ms/step - loss: 0.7865 - accuracy: 0.6954\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.5453 - accuracy: 0.7924\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.4165 - accuracy: 0.8406\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.3534 - accuracy: 0.8644\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.3054 - accuracy: 0.8850\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.2680 - accuracy: 0.8999\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.2328 - accuracy: 0.9148\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.2109 - accuracy: 0.9274\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.1949 - accuracy: 0.9313\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.1630 - accuracy: 0.9433\n",
      "21/21 [==============================] - 1s 17ms/step\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 3s 42ms/step - loss: nan - accuracy: 0.5067\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.2134\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.2134\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.2134\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.2134\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.2134\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.2134\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.2134\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.2134\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.2134\n",
      "21/21 [==============================] - 1s 16ms/step\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 3s 43ms/step - loss: nan - accuracy: 0.4964\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.2128\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.2128\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.2128\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.2128\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.2128\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.2128\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.2128\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.2128\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.2128\n",
      "21/21 [==============================] - 1s 16ms/step\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 3s 42ms/step - loss: nan - accuracy: 0.5010\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.2093\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.2093\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.2093\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.2093\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.2093\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.2093\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.2093\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.2093\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.2093\n",
      "21/21 [==============================] - 1s 16ms/step\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 3s 43ms/step - loss: 0.7782 - accuracy: 0.6868\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.4403 - accuracy: 0.8331\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.3086 - accuracy: 0.8727\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.2343 - accuracy: 0.9038\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.3039 - accuracy: 0.8809\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.1675 - accuracy: 0.9349\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.1008 - accuracy: 0.9676\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.0718 - accuracy: 0.9777\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.0525 - accuracy: 0.9842\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.0476 - accuracy: 0.9847\n",
      "21/21 [==============================] - 1s 16ms/step\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 3s 43ms/step - loss: 0.7974 - accuracy: 0.6796\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.6148 - accuracy: 0.7691\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.3907 - accuracy: 0.8428\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.2985 - accuracy: 0.8755\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.2185 - accuracy: 0.9150\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.1518 - accuracy: 0.9520\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.1046 - accuracy: 0.9673\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.0693 - accuracy: 0.9788\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.0566 - accuracy: 0.9818\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.0404 - accuracy: 0.9877\n",
      "21/21 [==============================] - 1s 16ms/step\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 3s 43ms/step - loss: 0.7933 - accuracy: 0.6925\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.4892 - accuracy: 0.8119\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.3378 - accuracy: 0.8625\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.2494 - accuracy: 0.9023\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.1699 - accuracy: 0.9420\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.1141 - accuracy: 0.9630\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.0932 - accuracy: 0.9691\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.0877 - accuracy: 0.9665\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.0423 - accuracy: 0.9873\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.0217 - accuracy: 0.9953\n",
      "21/21 [==============================] - 1s 16ms/step\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 3s 44ms/step - loss: 0.6860 - accuracy: 0.7748\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.2967 - accuracy: 0.8897\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.1535 - accuracy: 0.9427\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.0794 - accuracy: 0.9753\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.0632 - accuracy: 0.9792\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.0508 - accuracy: 0.9806\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.0664 - accuracy: 0.9773\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.0404 - accuracy: 0.9857\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.0382 - accuracy: 0.9859\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.0373 - accuracy: 0.9873\n",
      "21/21 [==============================] - 1s 16ms/step\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 3s 43ms/step - loss: 0.7541 - accuracy: 0.7390\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.5554 - accuracy: 0.7968\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.3093 - accuracy: 0.8863\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.2022 - accuracy: 0.9278\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.1252 - accuracy: 0.9568\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.0729 - accuracy: 0.9788\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.0497 - accuracy: 0.9851\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.0329 - accuracy: 0.9907\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.0333 - accuracy: 0.9888\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.0234 - accuracy: 0.9937\n",
      "21/21 [==============================] - 1s 16ms/step\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 3s 44ms/step - loss: 0.7833 - accuracy: 0.7254\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.6232 - accuracy: 0.7600\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.6596 - accuracy: 0.7449\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.6496 - accuracy: 0.7436\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.6804 - accuracy: 0.7382\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.6866 - accuracy: 0.7399\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.6845 - accuracy: 0.7367\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.6614 - accuracy: 0.7513\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.6405 - accuracy: 0.7555\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.6343 - accuracy: 0.7596\n",
      "21/21 [==============================] - 1s 16ms/step\n",
      "Epoch 1/10\n",
      "63/63 [==============================] - 4s 43ms/step - loss: 0.6969 - accuracy: 0.7244\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 3s 44ms/step - loss: 0.5140 - accuracy: 0.7961\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 3s 44ms/step - loss: 0.4010 - accuracy: 0.8432\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 3s 44ms/step - loss: 0.3518 - accuracy: 0.8628\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 3s 43ms/step - loss: 0.3144 - accuracy: 0.8824\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 3s 43ms/step - loss: 0.2783 - accuracy: 0.8974\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 3s 44ms/step - loss: 0.2529 - accuracy: 0.9071\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 3s 44ms/step - loss: 0.2320 - accuracy: 0.9137\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 3s 44ms/step - loss: 0.2075 - accuracy: 0.9246\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 3s 44ms/step - loss: 0.1836 - accuracy: 0.9333\n",
      "Best Parameters: {'model__dropout_rate': 0.1, 'model__gru_units': 256, 'model__input_dimensions': 1000, 'model__learning_rate': 0.001, 'model__output_dimensions': 128}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Wrap model function that was built above in a KerasClassifier\n",
    "model = KerasClassifier(\n",
    "    model=create_gru_model,\n",
    "    input_dimensions=1000,  # default value\n",
    "    output_dimensions=128,  # default value\n",
    "    gru_units=128,         # default value\n",
    "    dropout_rate=0.2,      # default value\n",
    "    learning_rate=0.001,   # default value\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    ")\n",
    "\n",
    "# Perform GridSearchCV using the Parameter Grid defined above \n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best results + use those results for training later \n",
    "print(f\"Best Parameters: {grid_result.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the best model using gteh result of the best Parameters from GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "63/63 [==============================] - 5s 54ms/step - loss: 0.7699 - accuracy: 0.6965 - val_loss: 0.5670 - val_accuracy: 0.7772\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 0.5188 - accuracy: 0.8034 - val_loss: 0.4586 - val_accuracy: 0.8313\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 0.3833 - accuracy: 0.8520 - val_loss: 0.4160 - val_accuracy: 0.8403\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.3300 - accuracy: 0.8719 - val_loss: 0.4000 - val_accuracy: 0.8501\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.2944 - accuracy: 0.8928 - val_loss: 0.4302 - val_accuracy: 0.8397\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 0.2650 - accuracy: 0.8999 - val_loss: 0.4288 - val_accuracy: 0.8380\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.2411 - accuracy: 0.9108 - val_loss: 0.4555 - val_accuracy: 0.8197\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 3s 47ms/step - loss: 0.2177 - accuracy: 0.9193 - val_loss: 0.4799 - val_accuracy: 0.8420\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.2043 - accuracy: 0.9257 - val_loss: 0.4886 - val_accuracy: 0.8281\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.1774 - accuracy: 0.9382 - val_loss: 0.5247 - val_accuracy: 0.8383\n"
     ]
    }
   ],
   "source": [
    "best_params = grid_result.best_params_\n",
    "# Unpack best parameters into create_gru_model function arguments\n",
    "best_model = create_gru_model(\n",
    "    input_dimensions=best_params['model__input_dimensions'],\n",
    "    output_dimensions=best_params['model__output_dimensions'],\n",
    "    gru_units=best_params['model__gru_units'],\n",
    "    dropout_rate=best_params['model__dropout_rate'],\n",
    "    learning_rate=best_params['model__learning_rate'],\n",
    ")\n",
    "\n",
    "optimizer = Adam(learning_rate=best_params['model__learning_rate'])\n",
    "best_model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Retrain model on the full training set\n",
    "history = best_model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=10,          # Best epoch count\n",
    "    batch_size=128,   # Best batch size\n",
    "    validation_data=(X_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 2s 15ms/step - loss: 0.5247 - accuracy: 0.8383\n",
      "Test Loss: 0.5247097611427307\n",
      "Test Accuracy: 83.83%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the optimized model\n",
    "test_loss, test_accuracy = best_model.evaluate(X_test, y_test)\n",
    "\n",
    "# Test loss has no inherent meaning unless compared to other models, lower the better\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 2s 13ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.7539    0.7940    0.7734       733\n",
      "     neutral     0.3594    0.2894    0.3206       349\n",
      "    positive     0.9213    0.9326    0.9269      2374\n",
      "\n",
      "    accuracy                         0.8383      3456\n",
      "   macro avg     0.6782    0.6720    0.6737      3456\n",
      "weighted avg     0.8291    0.8383    0.8332      3456\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "class_names = ['negative', 'neutral', 'positive']\n",
    "\n",
    "# Get the predicted classes for X_test\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_true, y_pred_classes, target_names=class_names, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
