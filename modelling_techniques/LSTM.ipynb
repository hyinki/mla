{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhancing Singapore Airlines' Service Through Automated Sentiment Analysis of Customer Reviews\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Motivation**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Singapore Airlines Customer Reviews Dataset Information\n",
    "\n",
    "The [Singapore Airlines Customer Reviews Dataset](https://www.kaggle.com/datasets/kanchana1990/singapore-airlines-reviews) aggregates 10,000 anonymized customer reviews, providing a broad perspective on the passenger experience with Singapore Airlines. \n",
    "\n",
    "The dimensions are shown below:\n",
    "- **`published_date`**: Date and time of review publication.\n",
    "- **`published_platform`**: Platform where the review was posted.\n",
    "- **`rating`**: Customer satisfaction rating, from 1 (lowest) to 5 (highest).\n",
    "- **`type`**: Specifies the content as a review.\n",
    "- **`text`**: Detailed customer feedback.\n",
    "- **`title`**: Summary of the review.\n",
    "- **`helpful_votes`**: Number of users finding the review helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional web scraping of online reviews\n",
    "\n",
    "During our EDA, we noticed two main trends in the distribution of our dataset:\n",
    "1. Less than 10% of our reviews were published from the years 2022 to 2024, making it hard for us to capture recent trends in sentiment.\n",
    "2. Most of the reviews were highly positive, which could mean that SIA had mostly positive reviews, nevertheless we wanted to get more information on negative reviews to improve the robustness of our model.\n",
    "\n",
    "### TripAdvisor\n",
    "\n",
    "We scraped more data for airline reviews from TripAdvisor, specifically for the years 2022 to 2024. \n",
    "(https://www.tripadvisor.com.sg/Airline_Review-d8729151-Reviews-Singapore-Airlines)\n",
    "\n",
    "The dimensions are shown below:\n",
    "- **`Year`**: Year of review publication.\n",
    "- **`Month`**: Month of review publication.\n",
    "- **`Title`**: Title of review publication.\n",
    "- **`Review Text`**: Main text content of review publication.\n",
    "- **`Rating`**: Numerical rating provided by reviewer (Scale: 1 to 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skytrax\n",
    "\n",
    "We also scraped from Skytrax, which is another data source for online reviews. \n",
    "(https://www.airlinequality.com/airline-reviews/singapore-airlines/?sortby=post_date%3ADesc&pagesize=100)\n",
    "\n",
    "The dimensions are shown below:\n",
    "- **`Year`**: Year of review publication.\n",
    "- **`Month`**: Month of review publication.\n",
    "- **`Title`**: Title of review publication.\n",
    "- **`Review Text`**: Main text content of review publication.\n",
    "- **`Rating`**: Numerical rating provided by reviewer (Scale: 1 to 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries\n",
    "\n",
    "Please uncomment the code box below to pip install relevant dependencies for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas>=2.0.0 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (2.0.3)\n",
      "Requirement already satisfied: numpy>=1.24.0 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (1.11.1)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (4.65.0)\n",
      "Requirement already satisfied: matplotlib>=3.7.0 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (3.7.2)\n",
      "Requirement already satisfied: seaborn>=0.12.0 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (0.12.2)\n",
      "Requirement already satisfied: langdetect>=1.0.9 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (1.0.9)\n",
      "Requirement already satisfied: langid>=1.1.6 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 8)) (1.1.6)\n",
      "Requirement already satisfied: nltk>=3.8.1 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (3.8.1)\n",
      "Requirement already satisfied: wordcloud>=1.9.0 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 10)) (1.9.3)\n",
      "Requirement already satisfied: tensorflow>=2.17.1 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 11)) (2.18.0)\n",
      "Requirement already satisfied: scikeras>=0.10.0 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 12)) (0.13.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from pandas>=2.0.0->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from pandas>=2.0.0->-r requirements.txt (line 1)) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from pandas>=2.0.0->-r requirements.txt (line 1)) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 5)) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 5)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 5)) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 5)) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 5)) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 5)) (9.4.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 5)) (3.0.9)\n",
      "Requirement already satisfied: six in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from langdetect>=1.0.9->-r requirements.txt (line 7)) (1.16.0)\n",
      "Requirement already satisfied: click in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from nltk>=3.8.1->-r requirements.txt (line 9)) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from nltk>=3.8.1->-r requirements.txt (line 9)) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from nltk>=3.8.1->-r requirements.txt (line 9)) (2022.7.9)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from tensorflow>=2.17.1->-r requirements.txt (line 11)) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from tensorflow>=2.17.1->-r requirements.txt (line 11)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from tensorflow>=2.17.1->-r requirements.txt (line 11)) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from tensorflow>=2.17.1->-r requirements.txt (line 11)) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from tensorflow>=2.17.1->-r requirements.txt (line 11)) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from tensorflow>=2.17.1->-r requirements.txt (line 11)) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from tensorflow>=2.17.1->-r requirements.txt (line 11)) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from tensorflow>=2.17.1->-r requirements.txt (line 11)) (5.28.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from tensorflow>=2.17.1->-r requirements.txt (line 11)) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from tensorflow>=2.17.1->-r requirements.txt (line 11)) (68.0.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from tensorflow>=2.17.1->-r requirements.txt (line 11)) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from tensorflow>=2.17.1->-r requirements.txt (line 11)) (4.7.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from tensorflow>=2.17.1->-r requirements.txt (line 11)) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from tensorflow>=2.17.1->-r requirements.txt (line 11)) (1.67.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from tensorflow>=2.17.1->-r requirements.txt (line 11)) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from tensorflow>=2.17.1->-r requirements.txt (line 11)) (3.6.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from tensorflow>=2.17.1->-r requirements.txt (line 11)) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from tensorflow>=2.17.1->-r requirements.txt (line 11)) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from tensorflow>=2.17.1->-r requirements.txt (line 11)) (0.37.1)\n",
      "Requirement already satisfied: scikit-learn>=1.4.2 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from scikeras>=0.10.0->-r requirements.txt (line 12)) (1.5.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow>=2.17.1->-r requirements.txt (line 11)) (0.38.4)\n",
      "Requirement already satisfied: rich in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow>=2.17.1->-r requirements.txt (line 11)) (13.9.2)\n",
      "Requirement already satisfied: namex in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow>=2.17.1->-r requirements.txt (line 11)) (0.0.8)\n",
      "Requirement already satisfied: optree in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow>=2.17.1->-r requirements.txt (line 11)) (0.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow>=2.17.1->-r requirements.txt (line 11)) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow>=2.17.1->-r requirements.txt (line 11)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow>=2.17.1->-r requirements.txt (line 11)) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow>=2.17.1->-r requirements.txt (line 11)) (2023.7.22)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from scikit-learn>=1.4.2->scikeras>=0.10.0->-r requirements.txt (line 12)) (3.5.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.17.1->-r requirements.txt (line 11)) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.17.1->-r requirements.txt (line 11)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.17.1->-r requirements.txt (line 11)) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow>=2.17.1->-r requirements.txt (line 11)) (2.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow>=2.17.1->-r requirements.txt (line 11)) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow>=2.17.1->-r requirements.txt (line 11)) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/mayaung/anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow>=2.17.1->-r requirements.txt (line 11)) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime \n",
    "\n",
    "# Statistical functions\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Text Preprocessing and NLP\n",
    "import nltk\n",
    "# Stopwords (common words to ignore) from NLTK\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Tokenizing sentences/words\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Tokenizing sentences/words\n",
    "from nltk.tokenize import word_tokenize\n",
    "# Lemmatization (converting words to their base form)\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "# For generating n-grams\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation (Loading CSV)\n",
    "\n",
    "Load the three CSV files into a pandas DataFrame `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('final_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>processed_full_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>ok use airlin go singapor london heathrow issu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>Negative</td>\n",
       "      <td>don give money book paid receiv email confirm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>Positive</td>\n",
       "      <td>best airlin world best airlin world seat food ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>Negative</td>\n",
       "      <td>premium economi seat singapor airlin not worth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>Negative</td>\n",
       "      <td>imposs get promis refund book flight full mont...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month sentiment                              processed_full_review\n",
       "0  2024      3   Neutral  ok use airlin go singapor london heathrow issu...\n",
       "1  2024      3  Negative  don give money book paid receiv email confirm ...\n",
       "2  2024      3  Positive  best airlin world best airlin world seat food ...\n",
       "3  2024      3  Negative  premium economi seat singapor airlin not worth...\n",
       "4  2024      3  Negative  imposs get promis refund book flight full mont..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "Positive    7913\n",
       "Negative    2441\n",
       "Neutral     1164\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year\n",
       "2019    5129\n",
       "2018    2596\n",
       "2022    1184\n",
       "2023    1111\n",
       "2020     888\n",
       "2024     514\n",
       "2021      96\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['year'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "58/58 [==============================] - 4s 35ms/step - loss: 0.7063 - accuracy: 0.7292 - val_loss: 0.4825 - val_accuracy: 0.8139\n",
      "Epoch 2/10\n",
      "58/58 [==============================] - 1s 24ms/step - loss: 0.3980 - accuracy: 0.8527 - val_loss: 0.4276 - val_accuracy: 0.8296\n",
      "Epoch 3/10\n",
      "58/58 [==============================] - 1s 24ms/step - loss: 0.2902 - accuracy: 0.8847 - val_loss: 0.4885 - val_accuracy: 0.8383\n",
      "Epoch 4/10\n",
      "58/58 [==============================] - 1s 25ms/step - loss: 0.2142 - accuracy: 0.9209 - val_loss: 0.4993 - val_accuracy: 0.8372\n",
      "Epoch 5/10\n",
      "58/58 [==============================] - 1s 25ms/step - loss: 0.1477 - accuracy: 0.9510 - val_loss: 0.5872 - val_accuracy: 0.8340\n",
      "Epoch 6/10\n",
      "58/58 [==============================] - 1s 25ms/step - loss: 0.1117 - accuracy: 0.9654 - val_loss: 0.6367 - val_accuracy: 0.8231\n",
      "Epoch 7/10\n",
      "58/58 [==============================] - 1s 24ms/step - loss: 0.0747 - accuracy: 0.9811 - val_loss: 0.7126 - val_accuracy: 0.8258\n",
      "Epoch 8/10\n",
      "58/58 [==============================] - 2s 26ms/step - loss: 0.0528 - accuracy: 0.9864 - val_loss: 0.7849 - val_accuracy: 0.8220\n",
      "Epoch 9/10\n",
      "58/58 [==============================] - 1s 24ms/step - loss: 0.0459 - accuracy: 0.9882 - val_loss: 0.8462 - val_accuracy: 0.8204\n",
      "Epoch 10/10\n",
      "58/58 [==============================] - 1s 24ms/step - loss: 0.0359 - accuracy: 0.9902 - val_loss: 0.8521 - val_accuracy: 0.8079\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.8129 - accuracy: 0.8199\n",
      "Test Accuracy: 0.8199\n",
      "72/72 [==============================] - 1s 8ms/step\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.7081    0.8000    0.7512       470\n",
      "     Neutral     0.3302    0.3114    0.3205       228\n",
      "    Positive     0.9255    0.8979    0.9115      1606\n",
      "\n",
      "    accuracy                         0.8199      2304\n",
      "   macro avg     0.6546    0.6698    0.6611      2304\n",
      "weighted avg     0.8223    0.8199    0.8203      2304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('final_df.csv')\n",
    "\n",
    "# Preprocess text and labels\n",
    "texts = data['processed_full_review'].astype(str)\n",
    "labels = data['sentiment']\n",
    "\n",
    "# Encode labels (e.g., Positive=2, Negative=0, Neutral=1)\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Tokenize and pad sequences\n",
    "tokenizer = Tokenizer(num_words=10000)  # Adjust the vocabulary size as needed\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "maxlen = 100  # Set maximum sequence length, adjust as needed\n",
    "X = pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=10000, output_dim=128, input_length=maxlen))  # Adjust output_dim as needed\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(64, return_sequences=False))\n",
    "model.add(Dense(32, activation='tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))  # 3 classes for Positive, Negative, Neutral\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=128, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Generate predictions for the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_classes, target_names=label_encoder.classes_, digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM with Hashing Vectorization\n",
    "\n",
    "Hashing Vectorizer is much faster than the Tokenizer and Embedding approach from above code.\n",
    "\n",
    "Hashing Vectorizer directly transforms text into fixed-length numerical vectors by hsahing the terms and mapping them to a specified number of features. This eliminate the need to build a vocabulary or convert tokens into embeddings. Whereas in Tokenizer, it creates a vocabulary, then tokenizes the text into sequences of integers, which are then converted into dense vectors using an `Embedding` layer. This two-step process is more computationally intensive than direct hashing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "116/116 [==============================] - 4s 14ms/step - loss: 0.7579 - accuracy: 0.7087 - val_loss: 0.5006 - val_accuracy: 0.8264\n",
      "Epoch 2/10\n",
      "116/116 [==============================] - 1s 9ms/step - loss: 0.4018 - accuracy: 0.8495 - val_loss: 0.4057 - val_accuracy: 0.8399\n",
      "Epoch 3/10\n",
      "116/116 [==============================] - 1s 8ms/step - loss: 0.3350 - accuracy: 0.8677 - val_loss: 0.3960 - val_accuracy: 0.8410\n",
      "Epoch 4/10\n",
      "116/116 [==============================] - 1s 8ms/step - loss: 0.2889 - accuracy: 0.8832 - val_loss: 0.4136 - val_accuracy: 0.8361\n",
      "Epoch 5/10\n",
      "116/116 [==============================] - 1s 8ms/step - loss: 0.2480 - accuracy: 0.9054 - val_loss: 0.4106 - val_accuracy: 0.8459\n",
      "Epoch 6/10\n",
      "116/116 [==============================] - 1s 8ms/step - loss: 0.2180 - accuracy: 0.9204 - val_loss: 0.4253 - val_accuracy: 0.8562\n",
      "Epoch 7/10\n",
      "116/116 [==============================] - 1s 8ms/step - loss: 0.1841 - accuracy: 0.9350 - val_loss: 0.4719 - val_accuracy: 0.8448\n",
      "Epoch 8/10\n",
      "116/116 [==============================] - 1s 9ms/step - loss: 0.1597 - accuracy: 0.9468 - val_loss: 0.5339 - val_accuracy: 0.8464\n",
      "Epoch 9/10\n",
      "116/116 [==============================] - 1s 9ms/step - loss: 0.1379 - accuracy: 0.9536 - val_loss: 0.5621 - val_accuracy: 0.8470\n",
      "Epoch 10/10\n",
      "116/116 [==============================] - 1s 9ms/step - loss: 0.1249 - accuracy: 0.9601 - val_loss: 0.6027 - val_accuracy: 0.8361\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.5802 - accuracy: 0.8351\n",
      "Test Accuracy: 0.8351\n",
      "72/72 [==============================] - 1s 3ms/step\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.7457    0.8234    0.7826       470\n",
      "     Neutral     0.3673    0.3640    0.3656       228\n",
      "    Positive     0.9326    0.9054    0.9188      1606\n",
      "\n",
      "    accuracy                         0.8351      2304\n",
      "   macro avg     0.6819    0.6976    0.6890      2304\n",
      "weighted avg     0.8386    0.8351    0.8363      2304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Reshape\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('final_df.csv')\n",
    "\n",
    "# Preprocess text and labels\n",
    "texts = data['processed_full_review'].astype(str)\n",
    "labels = data['sentiment']\n",
    "\n",
    "# Encode labels (e.g., Positive=2, Negative=0, Neutral=1)\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Use Hashing Vectorizer\n",
    "vectorizer = HashingVectorizer(n_features=5000, alternate_sign=False)  # Set n_features as needed\n",
    "X = vectorizer.transform(texts).toarray()\n",
    "\n",
    "# Reshape to 3D array as expected by LSTM input (samples, timesteps, features)\n",
    "X = np.reshape(X, (X.shape[0], 1, X.shape[1]))\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(64, return_sequences=False))\n",
    "model.add(Dense(32, activation='tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))  # 3 classes for Positive, Negative, Neutral\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Generate predictions for the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_classes, target_names=label_encoder.classes_, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM + Hashing Vectorizer + GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "48/48 [==============================] - 2s 8ms/step - loss: 0.9675 - accuracy: 0.6768\n",
      "Epoch 2/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.7407 - accuracy: 0.6846\n",
      "Epoch 3/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.5302 - accuracy: 0.7877\n",
      "Epoch 4/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.3914 - accuracy: 0.8549\n",
      "Epoch 5/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.3455 - accuracy: 0.8650\n",
      "24/24 [==============================] - 1s 3ms/step\n",
      "Epoch 1/5\n",
      "48/48 [==============================] - 3s 8ms/step - loss: 0.9732 - accuracy: 0.6777\n",
      "Epoch 2/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.7358 - accuracy: 0.6855\n",
      "Epoch 3/5\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.5318 - accuracy: 0.7980\n",
      "Epoch 4/5\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3959 - accuracy: 0.8528\n",
      "Epoch 5/5\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3489 - accuracy: 0.8647\n",
      "24/24 [==============================] - 1s 4ms/step\n",
      "Epoch 1/5\n",
      "48/48 [==============================] - 2s 7ms/step - loss: 0.9704 - accuracy: 0.6783\n",
      "Epoch 2/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.7375 - accuracy: 0.6855\n",
      "Epoch 3/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.5365 - accuracy: 0.7861\n",
      "Epoch 4/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.4032 - accuracy: 0.8514\n",
      "Epoch 5/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.3596 - accuracy: 0.8615\n",
      "24/24 [==============================] - 1s 3ms/step\n",
      "Epoch 1/5\n",
      "48/48 [==============================] - 2s 7ms/step - loss: 0.9707 - accuracy: 0.6768\n",
      "Epoch 2/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.7574 - accuracy: 0.6845\n",
      "Epoch 3/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.5725 - accuracy: 0.7401\n",
      "Epoch 4/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.4259 - accuracy: 0.8378\n",
      "Epoch 5/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.3606 - accuracy: 0.8605\n",
      "24/24 [==============================] - 1s 3ms/step\n",
      "Epoch 1/5\n",
      "48/48 [==============================] - 2s 7ms/step - loss: 0.9519 - accuracy: 0.6774\n",
      "Epoch 2/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.7363 - accuracy: 0.6852\n",
      "Epoch 3/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.5275 - accuracy: 0.7947\n",
      "Epoch 4/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.3955 - accuracy: 0.8528\n",
      "Epoch 5/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.3486 - accuracy: 0.8634\n",
      "24/24 [==============================] - 1s 3ms/step\n",
      "Epoch 1/5\n",
      "48/48 [==============================] - 2s 7ms/step - loss: 0.9699 - accuracy: 0.6790\n",
      "Epoch 2/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.7643 - accuracy: 0.6845\n",
      "Epoch 3/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.5954 - accuracy: 0.7238\n",
      "Epoch 4/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.4340 - accuracy: 0.8353\n",
      "Epoch 5/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.3636 - accuracy: 0.8597\n",
      "24/24 [==============================] - 1s 3ms/step\n",
      "Epoch 1/5\n",
      "48/48 [==============================] - 2s 8ms/step - loss: 0.8993 - accuracy: 0.6817\n",
      "Epoch 2/5\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.6015 - accuracy: 0.7397\n",
      "Epoch 3/5\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3880 - accuracy: 0.8535\n",
      "Epoch 4/5\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3258 - accuracy: 0.8662\n",
      "Epoch 5/5\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.2833 - accuracy: 0.8769\n",
      "24/24 [==============================] - 1s 4ms/step\n",
      "Epoch 1/5\n",
      "48/48 [==============================] - 2s 8ms/step - loss: 0.9017 - accuracy: 0.6772\n",
      "Epoch 2/5\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.6121 - accuracy: 0.7412\n",
      "Epoch 3/5\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3943 - accuracy: 0.8489\n",
      "Epoch 4/5\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3362 - accuracy: 0.8662\n",
      "Epoch 5/5\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.2984 - accuracy: 0.8747\n",
      "24/24 [==============================] - 1s 4ms/step\n",
      "Epoch 1/5\n",
      "48/48 [==============================] - 2s 7ms/step - loss: 0.9167 - accuracy: 0.6772\n",
      "Epoch 2/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.6480 - accuracy: 0.7171\n",
      "Epoch 3/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.4131 - accuracy: 0.8439\n",
      "Epoch 4/5\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3438 - accuracy: 0.8616\n",
      "Epoch 5/5\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.2973 - accuracy: 0.8745\n",
      "24/24 [==============================] - 1s 4ms/step\n",
      "Epoch 1/5\n",
      "48/48 [==============================] - 3s 8ms/step - loss: 0.9118 - accuracy: 0.6775\n",
      "Epoch 2/5\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.5951 - accuracy: 0.7460\n",
      "Epoch 3/5\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3823 - accuracy: 0.8540\n",
      "Epoch 4/5\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3251 - accuracy: 0.8670\n",
      "Epoch 5/5\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.2851 - accuracy: 0.8776\n",
      "24/24 [==============================] - 1s 4ms/step\n",
      "Epoch 1/5\n",
      "48/48 [==============================] - 2s 8ms/step - loss: 0.8973 - accuracy: 0.6777\n",
      "Epoch 2/5\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.5801 - accuracy: 0.7594\n",
      "Epoch 3/5\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3826 - accuracy: 0.8527\n",
      "Epoch 4/5\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3268 - accuracy: 0.8662\n",
      "Epoch 5/5\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.2908 - accuracy: 0.8755\n",
      "24/24 [==============================] - 1s 4ms/step\n",
      "Epoch 1/5\n",
      "48/48 [==============================] - 3s 8ms/step - loss: 0.9096 - accuracy: 0.6798\n",
      "Epoch 2/5\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.6109 - accuracy: 0.7405\n",
      "Epoch 3/5\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3961 - accuracy: 0.8478\n",
      "Epoch 4/5\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.3358 - accuracy: 0.8646\n",
      "Epoch 5/5\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.2909 - accuracy: 0.8758\n",
      "24/24 [==============================] - 1s 4ms/step\n",
      "Epoch 1/5\n",
      "48/48 [==============================] - 2s 7ms/step - loss: 0.9751 - accuracy: 0.6801\n",
      "Epoch 2/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.7606 - accuracy: 0.6843\n",
      "Epoch 3/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.5615 - accuracy: 0.7796\n",
      "Epoch 4/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.4202 - accuracy: 0.8530\n",
      "Epoch 5/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.3756 - accuracy: 0.8611\n",
      "24/24 [==============================] - 1s 3ms/step\n",
      "Epoch 1/5\n",
      "48/48 [==============================] - 2s 7ms/step - loss: 0.9924 - accuracy: 0.6803\n",
      "Epoch 2/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.7649 - accuracy: 0.6865\n",
      "Epoch 3/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.5579 - accuracy: 0.7918\n",
      "Epoch 4/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.4221 - accuracy: 0.8462\n",
      "Epoch 5/5\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3765 - accuracy: 0.8597\n",
      "24/24 [==============================] - 1s 3ms/step\n",
      "Epoch 1/5\n",
      "48/48 [==============================] - 2s 7ms/step - loss: 0.9832 - accuracy: 0.6777\n",
      "Epoch 2/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.7819 - accuracy: 0.6845\n",
      "Epoch 3/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.6148 - accuracy: 0.7316\n",
      "Epoch 4/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.4574 - accuracy: 0.8286\n",
      "Epoch 5/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.3946 - accuracy: 0.8486\n",
      "24/24 [==============================] - 1s 3ms/step\n",
      "Epoch 1/5\n",
      "48/48 [==============================] - 3s 7ms/step - loss: 0.9829 - accuracy: 0.6757\n",
      "Epoch 2/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.7700 - accuracy: 0.6846\n",
      "Epoch 3/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.5594 - accuracy: 0.7756\n",
      "Epoch 4/5\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4226 - accuracy: 0.8492\n",
      "Epoch 5/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.3779 - accuracy: 0.8592\n",
      "24/24 [==============================] - 1s 3ms/step\n",
      "Epoch 1/5\n",
      "48/48 [==============================] - 2s 7ms/step - loss: 0.9922 - accuracy: 0.6795\n",
      "Epoch 2/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.7797 - accuracy: 0.6845\n",
      "Epoch 3/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.6052 - accuracy: 0.7498\n",
      "Epoch 4/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.4408 - accuracy: 0.8457\n",
      "Epoch 5/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.3816 - accuracy: 0.8569\n",
      "24/24 [==============================] - 1s 3ms/step\n",
      "Epoch 1/5\n",
      "48/48 [==============================] - 2s 7ms/step - loss: 0.9607 - accuracy: 0.6783\n",
      "Epoch 2/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.7666 - accuracy: 0.6845\n",
      "Epoch 3/5\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.5822 - accuracy: 0.7519\n",
      "Epoch 4/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.4363 - accuracy: 0.8384\n",
      "Epoch 5/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.3809 - accuracy: 0.8566\n",
      "24/24 [==============================] - 1s 3ms/step\n",
      "Epoch 1/5\n",
      "48/48 [==============================] - 2s 8ms/step - loss: 0.9248 - accuracy: 0.6744\n",
      "Epoch 2/5\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.6627 - accuracy: 0.7110\n",
      "Epoch 3/5\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4195 - accuracy: 0.8422\n",
      "Epoch 4/5\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3495 - accuracy: 0.8626\n",
      "Epoch 5/5\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.3133 - accuracy: 0.8715\n",
      "24/24 [==============================] - 1s 5ms/step\n",
      "Epoch 1/5\n",
      "48/48 [==============================] - 3s 7ms/step - loss: 0.9106 - accuracy: 0.6787\n",
      "Epoch 2/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.6091 - accuracy: 0.7501\n",
      "Epoch 3/5\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3988 - accuracy: 0.8501\n",
      "Epoch 4/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.3499 - accuracy: 0.8647\n",
      "Epoch 5/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.3119 - accuracy: 0.8717\n",
      "24/24 [==============================] - 1s 4ms/step\n",
      "Epoch 1/5\n",
      "48/48 [==============================] - 2s 8ms/step - loss: 0.9254 - accuracy: 0.6785\n",
      "Epoch 2/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.6705 - accuracy: 0.7089\n",
      "Epoch 3/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.4361 - accuracy: 0.8372\n",
      "Epoch 4/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.3672 - accuracy: 0.8574\n",
      "Epoch 5/5\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3256 - accuracy: 0.8694\n",
      "24/24 [==============================] - 1s 4ms/step\n",
      "Epoch 1/5\n",
      "48/48 [==============================] - 2s 7ms/step - loss: 0.9050 - accuracy: 0.6775\n",
      "Epoch 2/5\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.6132 - accuracy: 0.7384\n",
      "Epoch 3/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.4003 - accuracy: 0.8494\n",
      "Epoch 4/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.3457 - accuracy: 0.8642\n",
      "Epoch 5/5\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3068 - accuracy: 0.8735\n",
      "24/24 [==============================] - 1s 4ms/step\n",
      "Epoch 1/5\n",
      "48/48 [==============================] - 2s 8ms/step - loss: 0.9159 - accuracy: 0.6785\n",
      "Epoch 2/5\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.6357 - accuracy: 0.7355\n",
      "Epoch 3/5\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4119 - accuracy: 0.8473\n",
      "Epoch 4/5\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3521 - accuracy: 0.8607\n",
      "Epoch 5/5\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3165 - accuracy: 0.8711\n",
      "24/24 [==============================] - 1s 4ms/step\n",
      "Epoch 1/5\n",
      "48/48 [==============================] - 2s 7ms/step - loss: 0.9208 - accuracy: 0.6769\n",
      "Epoch 2/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.6432 - accuracy: 0.7290\n",
      "Epoch 3/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.4201 - accuracy: 0.8437\n",
      "Epoch 4/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.3592 - accuracy: 0.8590\n",
      "Epoch 5/5\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.3186 - accuracy: 0.8703\n",
      "24/24 [==============================] - 1s 4ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 2s 7ms/step - loss: 0.9578 - accuracy: 0.6762\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.7378 - accuracy: 0.6845\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.5246 - accuracy: 0.7883\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.3927 - accuracy: 0.8523\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.3483 - accuracy: 0.8642\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.3134 - accuracy: 0.8709\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.2884 - accuracy: 0.8782\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.2634 - accuracy: 0.8864\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.2428 - accuracy: 0.9026\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.2167 - accuracy: 0.9186\n",
      "24/24 [==============================] - 1s 3ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 2s 7ms/step - loss: 0.9615 - accuracy: 0.6765\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.7286 - accuracy: 0.6876\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.5057 - accuracy: 0.8095\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.3850 - accuracy: 0.8540\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.3441 - accuracy: 0.8652\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.3121 - accuracy: 0.8732\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.2875 - accuracy: 0.8773\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.2641 - accuracy: 0.8841\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.2447 - accuracy: 0.8978\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.2260 - accuracy: 0.9110\n",
      "24/24 [==============================] - 1s 3ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 2s 7ms/step - loss: 0.9692 - accuracy: 0.6783\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.7401 - accuracy: 0.6853\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.5344 - accuracy: 0.7859\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.4046 - accuracy: 0.8494\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3588 - accuracy: 0.8611\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3257 - accuracy: 0.8694\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.2987 - accuracy: 0.8774\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.2780 - accuracy: 0.8823\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.2558 - accuracy: 0.8901\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 0.2333 - accuracy: 0.9088\n",
      "24/24 [==============================] - 1s 4ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 3s 8ms/step - loss: 0.9847 - accuracy: 0.6767\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.7315 - accuracy: 0.6879\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4942 - accuracy: 0.8115\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3777 - accuracy: 0.8557\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3400 - accuracy: 0.8660\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3095 - accuracy: 0.8738\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.2862 - accuracy: 0.8803\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.2631 - accuracy: 0.8838\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.2429 - accuracy: 0.8934\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.2205 - accuracy: 0.9093\n",
      "24/24 [==============================] - 1s 3ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 3s 8ms/step - loss: 1.0027 - accuracy: 0.6767\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.7693 - accuracy: 0.6845\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.5741 - accuracy: 0.7671\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.4096 - accuracy: 0.8475\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.3576 - accuracy: 0.8605\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.3215 - accuracy: 0.8691\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.2956 - accuracy: 0.8764\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.2691 - accuracy: 0.8913\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.2369 - accuracy: 0.9067\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.2090 - accuracy: 0.9256\n",
      "24/24 [==============================] - 1s 3ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 2s 7ms/step - loss: 0.9671 - accuracy: 0.6783\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.7510 - accuracy: 0.6845\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.5537 - accuracy: 0.7701\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.4057 - accuracy: 0.8478\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.3528 - accuracy: 0.8603\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.3249 - accuracy: 0.8701\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.2975 - accuracy: 0.8761\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.2763 - accuracy: 0.8820\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.2542 - accuracy: 0.8901\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.2295 - accuracy: 0.9088\n",
      "24/24 [==============================] - 1s 3ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 2s 8ms/step - loss: 0.9079 - accuracy: 0.6793\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.5985 - accuracy: 0.7436\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.3823 - accuracy: 0.8541\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3243 - accuracy: 0.8676\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.2844 - accuracy: 0.8766\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.2517 - accuracy: 0.8886\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.2168 - accuracy: 0.9191\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.1735 - accuracy: 0.9398\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.1447 - accuracy: 0.9544\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.1176 - accuracy: 0.9634\n",
      "24/24 [==============================] - 1s 4ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 2s 8ms/step - loss: 0.8965 - accuracy: 0.6832\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.6062 - accuracy: 0.7438\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.3952 - accuracy: 0.8506\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3323 - accuracy: 0.8652\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.2965 - accuracy: 0.8743\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.2658 - accuracy: 0.8833\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.2389 - accuracy: 0.8971\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.2113 - accuracy: 0.9171\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.1753 - accuracy: 0.9375\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.1510 - accuracy: 0.9484\n",
      "24/24 [==============================] - 1s 4ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 4s 8ms/step - loss: 0.9164 - accuracy: 0.6778\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.6109 - accuracy: 0.7395\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3966 - accuracy: 0.8484\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3378 - accuracy: 0.8637\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.2965 - accuracy: 0.8747\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.2680 - accuracy: 0.8815\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.2371 - accuracy: 0.9062\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.2017 - accuracy: 0.9294\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.1672 - accuracy: 0.9434\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.1394 - accuracy: 0.9575\n",
      "24/24 [==============================] - 1s 4ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 2s 7ms/step - loss: 0.9158 - accuracy: 0.6762\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.6124 - accuracy: 0.7358\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3853 - accuracy: 0.8514\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3288 - accuracy: 0.8681\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.2883 - accuracy: 0.8764\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.2613 - accuracy: 0.8872\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.2302 - accuracy: 0.9064\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.1991 - accuracy: 0.9302\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.1696 - accuracy: 0.9415\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.1400 - accuracy: 0.9539\n",
      "24/24 [==============================] - 1s 4ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 3s 7ms/step - loss: 0.9196 - accuracy: 0.6778\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.6003 - accuracy: 0.7500\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3897 - accuracy: 0.8517\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3345 - accuracy: 0.8660\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.2978 - accuracy: 0.8745\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.2689 - accuracy: 0.8830\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.2410 - accuracy: 0.8971\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.2105 - accuracy: 0.9186\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.1782 - accuracy: 0.9346\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.1493 - accuracy: 0.9492\n",
      "24/24 [==============================] - 1s 4ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 2s 8ms/step - loss: 0.9197 - accuracy: 0.6806\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.6526 - accuracy: 0.7119\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4220 - accuracy: 0.8421\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3470 - accuracy: 0.8613\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3029 - accuracy: 0.8712\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.2733 - accuracy: 0.8795\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.2392 - accuracy: 0.9064\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 0.1998 - accuracy: 0.9313\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.1673 - accuracy: 0.9404\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.1411 - accuracy: 0.9536\n",
      "24/24 [==============================] - 1s 5ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 3s 7ms/step - loss: 0.9804 - accuracy: 0.6754\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.7770 - accuracy: 0.6845\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.5794 - accuracy: 0.7634\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.4332 - accuracy: 0.8426\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.3823 - accuracy: 0.8588\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.3463 - accuracy: 0.8676\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.3265 - accuracy: 0.8737\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.2962 - accuracy: 0.8772\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.2826 - accuracy: 0.8834\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.2587 - accuracy: 0.8930\n",
      "24/24 [==============================] - 1s 4ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 2s 7ms/step - loss: 0.9587 - accuracy: 0.6775\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.7526 - accuracy: 0.6853\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.5515 - accuracy: 0.7846\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4205 - accuracy: 0.8458\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.3713 - accuracy: 0.8597\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.3396 - accuracy: 0.8693\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.3219 - accuracy: 0.8717\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.2982 - accuracy: 0.8786\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.2778 - accuracy: 0.8805\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.2676 - accuracy: 0.8865\n",
      "24/24 [==============================] - 1s 3ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 2s 7ms/step - loss: 1.0007 - accuracy: 0.6756\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.7876 - accuracy: 0.6845\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.6304 - accuracy: 0.7299\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.4584 - accuracy: 0.8366\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3967 - accuracy: 0.8533\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.3636 - accuracy: 0.8620\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3374 - accuracy: 0.8699\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.3106 - accuracy: 0.8732\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.2920 - accuracy: 0.8836\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.2728 - accuracy: 0.8981\n",
      "24/24 [==============================] - 1s 4ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 2s 7ms/step - loss: 0.9873 - accuracy: 0.6767\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.7825 - accuracy: 0.6843\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.6043 - accuracy: 0.7392\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4447 - accuracy: 0.8347\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3846 - accuracy: 0.8548\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.3466 - accuracy: 0.8670\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3274 - accuracy: 0.8724\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.2953 - accuracy: 0.8766\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.2792 - accuracy: 0.8831\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.2548 - accuracy: 0.8989\n",
      "24/24 [==============================] - 1s 3ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 2s 8ms/step - loss: 0.9804 - accuracy: 0.6790\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.7710 - accuracy: 0.6845\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.5913 - accuracy: 0.7573\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4408 - accuracy: 0.8364\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3805 - accuracy: 0.8592\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3491 - accuracy: 0.8667\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.3286 - accuracy: 0.8714\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.3037 - accuracy: 0.8768\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.2893 - accuracy: 0.8790\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.2784 - accuracy: 0.8841\n",
      "24/24 [==============================] - 1s 3ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 2s 7ms/step - loss: 0.9784 - accuracy: 0.6767\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.7877 - accuracy: 0.6845\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.6493 - accuracy: 0.7029\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.4822 - accuracy: 0.8069\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.4066 - accuracy: 0.8439\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.3680 - accuracy: 0.8571\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3411 - accuracy: 0.8662\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3187 - accuracy: 0.8717\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.2941 - accuracy: 0.8828\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.2756 - accuracy: 0.8921\n",
      "24/24 [==============================] - 1s 4ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 3s 8ms/step - loss: 0.9245 - accuracy: 0.6763\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.6309 - accuracy: 0.7330\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.4078 - accuracy: 0.8481\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3515 - accuracy: 0.8645\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3080 - accuracy: 0.8717\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.2811 - accuracy: 0.8836\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.2500 - accuracy: 0.9018\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.2142 - accuracy: 0.9254\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.1866 - accuracy: 0.9359\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.1599 - accuracy: 0.9456\n",
      "24/24 [==============================] - 1s 5ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 2s 8ms/step - loss: 0.9108 - accuracy: 0.6790\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.6347 - accuracy: 0.7351\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4116 - accuracy: 0.8473\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3505 - accuracy: 0.8621\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3198 - accuracy: 0.8707\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.2907 - accuracy: 0.8790\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.2674 - accuracy: 0.8898\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.2445 - accuracy: 0.9043\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.2151 - accuracy: 0.9178\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.1936 - accuracy: 0.9298\n",
      "24/24 [==============================] - 1s 4ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 2s 8ms/step - loss: 0.9198 - accuracy: 0.6770\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.6330 - accuracy: 0.7338\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4151 - accuracy: 0.8467\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3593 - accuracy: 0.8600\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3199 - accuracy: 0.8711\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.2922 - accuracy: 0.8758\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.2670 - accuracy: 0.8916\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.2423 - accuracy: 0.9043\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.2144 - accuracy: 0.9235\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 0.1878 - accuracy: 0.9357\n",
      "24/24 [==============================] - 1s 5ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 3s 9ms/step - loss: 0.9266 - accuracy: 0.6763\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.6502 - accuracy: 0.7167\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.4194 - accuracy: 0.8408\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3554 - accuracy: 0.8624\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3141 - accuracy: 0.8720\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.2853 - accuracy: 0.8772\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.2631 - accuracy: 0.8885\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.2352 - accuracy: 0.9033\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.2158 - accuracy: 0.9162\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 0.1922 - accuracy: 0.9321\n",
      "24/24 [==============================] - 1s 5ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 3s 9ms/step - loss: 0.9123 - accuracy: 0.6774\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.6531 - accuracy: 0.7198\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.4171 - accuracy: 0.8457\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.3567 - accuracy: 0.8623\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 0.3200 - accuracy: 0.8706\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.2905 - accuracy: 0.8782\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.2629 - accuracy: 0.8932\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.2358 - accuracy: 0.9093\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.2038 - accuracy: 0.9220\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 0.1810 - accuracy: 0.9289\n",
      "24/24 [==============================] - 1s 4ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 2s 8ms/step - loss: 0.9302 - accuracy: 0.6780\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.6769 - accuracy: 0.7062\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4415 - accuracy: 0.8369\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.3654 - accuracy: 0.8584\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3280 - accuracy: 0.8698\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.2990 - accuracy: 0.8745\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.2730 - accuracy: 0.8913\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.2399 - accuracy: 0.9064\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.2110 - accuracy: 0.9230\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.1849 - accuracy: 0.9344\n",
      "24/24 [==============================] - 1s 5ms/step\n",
      "Epoch 1/10\n",
      "72/72 [==============================] - 2s 7ms/step - loss: 0.8951 - accuracy: 0.6764\n",
      "Epoch 2/10\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.6014 - accuracy: 0.7408\n",
      "Epoch 3/10\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.4111 - accuracy: 0.8500\n",
      "Epoch 4/10\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.3524 - accuracy: 0.8611\n",
      "Epoch 5/10\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.3254 - accuracy: 0.8687\n",
      "Epoch 6/10\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.3008 - accuracy: 0.8748\n",
      "Epoch 7/10\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.2807 - accuracy: 0.8789\n",
      "Epoch 8/10\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.2611 - accuracy: 0.8886\n",
      "Epoch 9/10\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.2428 - accuracy: 0.9007\n",
      "Epoch 10/10\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.2248 - accuracy: 0.9147\n",
      "Best Parameters: {'epochs': 10, 'model__dropout_rate': 0.3, 'model__units': 32, 'optimizer': 'rmsprop'}\n",
      "Best Score: 0.8518564333346901\n",
      "18/18 [==============================] - 1s 3ms/step\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.7590    0.8043    0.7810       470\n",
      "     Neutral     0.3037    0.1798    0.2259       228\n",
      "    Positive     0.9120    0.9489    0.9301      1606\n",
      "\n",
      "    accuracy                         0.8433      2304\n",
      "   macro avg     0.6583    0.6443    0.6457      2304\n",
      "weighted avg     0.8206    0.8433    0.8300      2304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Embedding\n",
    "from scikeras.wrappers import KerasClassifier  # Updated import\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('final_df.csv')\n",
    "\n",
    "# Preprocess text and labels\n",
    "texts = data['processed_full_review'].astype(str)\n",
    "labels = data['sentiment']\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Use Hashing Vectorizer\n",
    "vectorizer = HashingVectorizer(n_features=5000, alternate_sign=False)  # Set n_features as needed\n",
    "X = vectorizer.transform(texts).toarray()\n",
    "X = np.reshape(X, (X.shape[0], 1, X.shape[1]))  # Reshape for LSTM\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a function to create the model (for use in KerasClassifier)\n",
    "def create_model(units=64, dropout_rate=0.5, optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(units, return_sequences=False))\n",
    "    model.add(Dense(units // 2, activation='tanh'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(3, activation='softmax'))  # 3 classes for Positive, Negative, Neutral\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Wrap the model using KerasClassifier from scikeras\n",
    "model = KerasClassifier(model=create_model, verbose=1, batch_size=128)  # scikeras syntax\n",
    "\n",
    "# Define the grid of hyperparameters\n",
    "param_grid = {\n",
    "    'model__units': [32, 64],\n",
    "    'model__dropout_rate': [0.3, 0.5],\n",
    "    'optimizer': ['adam', 'rmsprop'],\n",
    "    'epochs': [5, 10],  # Reduced for demo; increase as needed\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
    "\n",
    "# Perform grid search\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Display the best parameters and accuracy\n",
    "print(\"Best Parameters:\", grid_result.best_params_)\n",
    "print(\"Best Score:\", grid_result.best_score_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = grid_result.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
