{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhancing Singapore Airlines' Service Through Automated Sentiment Analysis of Customer Reviews\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Motivation**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Singapore Airlines Customer Reviews Dataset Information\n",
    "\n",
    "The [Singapore Airlines Customer Reviews Dataset](https://www.kaggle.com/datasets/kanchana1990/singapore-airlines-reviews) aggregates 10,000 anonymized customer reviews, providing a broad perspective on the passenger experience with Singapore Airlines. \n",
    "\n",
    "The dimensions are shown below:\n",
    "- **`published_date`**: Date and time of review publication.\n",
    "- **`published_platform`**: Platform where the review was posted.\n",
    "- **`rating`**: Customer satisfaction rating, from 1 (lowest) to 5 (highest).\n",
    "- **`type`**: Specifies the content as a review.\n",
    "- **`text`**: Detailed customer feedback.\n",
    "- **`title`**: Summary of the review.\n",
    "- **`helpful_votes`**: Number of users finding the review helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries\n",
    "\n",
    "Please uncomment the code box below to pip install relevant dependencies for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Statistical functions\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# For concurrency (running functions in parallel)\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# For caching (to speed up repeated function calls)\n",
    "from functools import lru_cache\n",
    "\n",
    "# For progress tracking\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Plotting and Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Language Detection packages\n",
    "# `langdetect` for detecting language\n",
    "from langdetect import detect as langdetect_detect, DetectorFactory\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "# `langid` for an alternative language detection method\n",
    "from langid import classify as langid_classify\n",
    "\n",
    "# Text Preprocessing and NLP\n",
    "# Stopwords (common words to ignore) from NLTK\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Tokenizing sentences/words\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Tokenizing sentences/words\n",
    "from nltk.tokenize import word_tokenize\n",
    "# Lemmatization (converting words to their base form)\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "# Regular expressions for text pattern matching\n",
    "import re\n",
    "\n",
    "# Word Cloud generation\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# For generating n-grams\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "\n",
    "# Libraries for Word2Vec and Logistic Regression\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation (Loading CSV)\n",
    "\n",
    "Load the `singapore_airline_reviews.csv` file into a pandas DataFrame `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   published_date      10000 non-null  object\n",
      " 1   published_platform  10000 non-null  object\n",
      " 2   rating              10000 non-null  int64 \n",
      " 3   type                10000 non-null  object\n",
      " 4   text                10000 non-null  object\n",
      " 5   title               9999 non-null   object\n",
      " 6   helpful_votes       10000 non-null  int64 \n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 547.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"singapore_airlines_reviews.csv\")\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>published_date</th>\n",
       "      <th>published_platform</th>\n",
       "      <th>rating</th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>helpful_votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03-12T14:41:14-04:00</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>3</td>\n",
       "      <td>review</td>\n",
       "      <td>We used this airline to go from Singapore to L...</td>\n",
       "      <td>Ok</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-03-11T19:39:13-04:00</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>5</td>\n",
       "      <td>review</td>\n",
       "      <td>The service on Singapore Airlines Suites Class...</td>\n",
       "      <td>The service in Suites Class makes one feel lik...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-03-11T12:20:23-04:00</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>1</td>\n",
       "      <td>review</td>\n",
       "      <td>Booked, paid and received email confirmation f...</td>\n",
       "      <td>Don’t give them your money</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-03-11T07:12:27-04:00</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>5</td>\n",
       "      <td>review</td>\n",
       "      <td>Best airline in the world, seats, food, servic...</td>\n",
       "      <td>Best Airline in the World</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-03-10T05:34:18-04:00</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>2</td>\n",
       "      <td>review</td>\n",
       "      <td>Premium Economy Seating on Singapore Airlines ...</td>\n",
       "      <td>Premium Economy Seating on Singapore Airlines ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              published_date published_platform  rating    type  \\\n",
       "0  2024-03-12T14:41:14-04:00            Desktop       3  review   \n",
       "1  2024-03-11T19:39:13-04:00            Desktop       5  review   \n",
       "2  2024-03-11T12:20:23-04:00            Desktop       1  review   \n",
       "3  2024-03-11T07:12:27-04:00            Desktop       5  review   \n",
       "4  2024-03-10T05:34:18-04:00            Desktop       2  review   \n",
       "\n",
       "                                                text  \\\n",
       "0  We used this airline to go from Singapore to L...   \n",
       "1  The service on Singapore Airlines Suites Class...   \n",
       "2  Booked, paid and received email confirmation f...   \n",
       "3  Best airline in the world, seats, food, servic...   \n",
       "4  Premium Economy Seating on Singapore Airlines ...   \n",
       "\n",
       "                                               title  helpful_votes  \n",
       "0                                                 Ok              0  \n",
       "1  The service in Suites Class makes one feel lik...              0  \n",
       "2                         Don’t give them your money              0  \n",
       "3                          Best Airline in the World              0  \n",
       "4  Premium Economy Seating on Singapore Airlines ...              0  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "## Remove Duplicate Rows\n",
    "\n",
    "- Drop duplicate rows from the dataframe (`data`) and reset the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new shape is:  (10000, 7)\n",
      "Remaining duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "data = data.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Display the new dataframe shape\n",
    "print(\"The new shape is: \", data.shape)\n",
    "\n",
    "# Make sure no more duplicates are present\n",
    "print(\"Remaining duplicate rows:\", data.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for Null Values\n",
    "\n",
    "- Here we check which features have null values using the `isnull()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "published_date        0\n",
       "published_platform    0\n",
       "rating                0\n",
       "type                  0\n",
       "text                  0\n",
       "title                 1\n",
       "helpful_votes         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In this case only `title` feature has one null value, will fill it with empty string \" \"\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with empty string\n",
    "data = data.fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "published_date        0\n",
       "published_platform    0\n",
       "rating                0\n",
       "type                  0\n",
       "text                  0\n",
       "title                 0\n",
       "helpful_votes         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify that there are no missing values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert data types\n",
    "\n",
    "Since the column `published_date` is in data type (`str`), we will\n",
    "- Convert `published_date` to a standard timezone (UTC) format as a new column `date`.\n",
    "- Drop the original `published_date` column after conversion and reset the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime64[ns, UTC]\n"
     ]
    }
   ],
   "source": [
    "# Set `utc=True` to convert the date to common timezone (UTC)\n",
    "data[\"date\"] = pd.to_datetime(data[\"published_date\"], utc=True)\n",
    "print(data[\"date\"].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>published_platform</th>\n",
       "      <th>rating</th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Desktop</td>\n",
       "      <td>3</td>\n",
       "      <td>review</td>\n",
       "      <td>We used this airline to go from Singapore to L...</td>\n",
       "      <td>Ok</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-12 18:41:14+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Desktop</td>\n",
       "      <td>5</td>\n",
       "      <td>review</td>\n",
       "      <td>The service on Singapore Airlines Suites Class...</td>\n",
       "      <td>The service in Suites Class makes one feel lik...</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-11 23:39:13+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Desktop</td>\n",
       "      <td>1</td>\n",
       "      <td>review</td>\n",
       "      <td>Booked, paid and received email confirmation f...</td>\n",
       "      <td>Don’t give them your money</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-11 16:20:23+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Desktop</td>\n",
       "      <td>5</td>\n",
       "      <td>review</td>\n",
       "      <td>Best airline in the world, seats, food, servic...</td>\n",
       "      <td>Best Airline in the World</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-11 11:12:27+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Desktop</td>\n",
       "      <td>2</td>\n",
       "      <td>review</td>\n",
       "      <td>Premium Economy Seating on Singapore Airlines ...</td>\n",
       "      <td>Premium Economy Seating on Singapore Airlines ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-10 09:34:18+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  published_platform  rating    type  \\\n",
       "0            Desktop       3  review   \n",
       "1            Desktop       5  review   \n",
       "2            Desktop       1  review   \n",
       "3            Desktop       5  review   \n",
       "4            Desktop       2  review   \n",
       "\n",
       "                                                text  \\\n",
       "0  We used this airline to go from Singapore to L...   \n",
       "1  The service on Singapore Airlines Suites Class...   \n",
       "2  Booked, paid and received email confirmation f...   \n",
       "3  Best airline in the world, seats, food, servic...   \n",
       "4  Premium Economy Seating on Singapore Airlines ...   \n",
       "\n",
       "                                               title  helpful_votes  \\\n",
       "0                                                 Ok              0   \n",
       "1  The service in Suites Class makes one feel lik...              0   \n",
       "2                         Don’t give them your money              0   \n",
       "3                          Best Airline in the World              0   \n",
       "4  Premium Economy Seating on Singapore Airlines ...              0   \n",
       "\n",
       "                       date  \n",
       "0 2024-03-12 18:41:14+00:00  \n",
       "1 2024-03-11 23:39:13+00:00  \n",
       "2 2024-03-11 16:20:23+00:00  \n",
       "3 2024-03-11 11:12:27+00:00  \n",
       "4 2024-03-10 09:34:18+00:00  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop `published_date` column and reset the index\n",
    "data = data.drop(columns=[\"published_date\"]).reset_index(drop=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Outliers\n",
    "\n",
    "### `text`\n",
    "\n",
    "The `text` column of `data`, which is of string (`str`) type, may contain values with unusually long lengths, indicating the presence of outliers. We will identify the outliers using [Z-score method].\n",
    "\n",
    "1. Create a new column `text_length` in the DataFrame `data` by calculating the length of each review. (Set the value as 0 if the correponding `text` column has NaN values.)\n",
    "\n",
    "2. Check the statistics of `text_length` using `describe()` method.\n",
    "\n",
    "3. Calculate the mean and standard deviation of the `text_length` column.\n",
    "\n",
    "4. Set the Z-score threshold for identifying outliers to 3.\n",
    "\n",
    "5. Identify outliers of the `text_length` column and set the corresponding `text` to np.nan.\n",
    "\n",
    "6. Drop the `text_length` column from the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  published_platform  rating    type  \\\n",
      "0            Desktop       3  review   \n",
      "1            Desktop       5  review   \n",
      "2            Desktop       1  review   \n",
      "\n",
      "                                                text  \\\n",
      "0  We used this airline to go from Singapore to L...   \n",
      "1  The service on Singapore Airlines Suites Class...   \n",
      "2  Booked, paid and received email confirmation f...   \n",
      "\n",
      "                                               title  helpful_votes  \\\n",
      "0                                                 Ok              0   \n",
      "1  The service in Suites Class makes one feel lik...              0   \n",
      "2                         Don’t give them your money              0   \n",
      "\n",
      "                       date  text_length  \n",
      "0 2024-03-12 18:41:14+00:00         1352  \n",
      "1 2024-03-11 23:39:13+00:00         4666  \n",
      "2 2024-03-11 16:20:23+00:00          420  \n",
      "count    10000.000000\n",
      "mean       556.526800\n",
      "std        640.290638\n",
      "min        100.000000\n",
      "25%        228.000000\n",
      "50%        380.000000\n",
      "75%        665.000000\n",
      "max      18717.000000\n",
      "Name: text_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "data['text_length'] = data['text'].apply(lambda x: len(x) if pd.notna(x) else 0)\n",
    "print(data.head(3))\n",
    "\n",
    "TL = data[\"text_length\"]\n",
    "stats_TL = TL.describe()\n",
    "print(stats_TL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 7)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_TL = TL.mean()\n",
    "# print(mean_TL)\n",
    "\n",
    "sd_TL = TL.std()\n",
    "# print(sd_TL)\n",
    "\n",
    "threshold = 3\n",
    "\n",
    "z_score = zscore(TL)\n",
    "# print(z_score)\n",
    "\n",
    "# Remove 'text' of lengths that are greater than 3 standard deviations above the mean\n",
    "data.loc[abs(z_score) > threshold, 'text'] = np.nan\n",
    "# print(data.head(3))\n",
    "\n",
    "data = data.drop(\"text_length\", axis=1)\n",
    "\n",
    "data.head()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `title`\n",
    "\n",
    "Similarly, the `title` column of `data` (of type `str`) may also contain values with unusually long lengths, indicating the presence of outliers.\n",
    "\n",
    "1. Create a new column `title_length` in the DataFrame `data` by calculating the length of each price value. (Set the value as 0 if the correponding `title` column has NaN values.)\n",
    "\n",
    "2. Check the statistics of `title_length` using `describe()` method and display its unique values.\n",
    "\n",
    "3. Identify the outlier values by inspecting the content in `title` corresponding to the abnormal value in `title_length` and set the corresponding value of `title` to np.nan.\n",
    "\n",
    "4. Drop the `title_length` column from the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  published_platform  rating    type  \\\n",
      "0            Desktop       3  review   \n",
      "1            Desktop       5  review   \n",
      "2            Desktop       1  review   \n",
      "\n",
      "                                                text  \\\n",
      "0  We used this airline to go from Singapore to L...   \n",
      "1                                                NaN   \n",
      "2  Booked, paid and received email confirmation f...   \n",
      "\n",
      "                                               title  helpful_votes  \\\n",
      "0                                                 Ok              0   \n",
      "1  The service in Suites Class makes one feel lik...              0   \n",
      "2                         Don’t give them your money              0   \n",
      "\n",
      "                       date  title_length  \n",
      "0 2024-03-12 18:41:14+00:00             2  \n",
      "1 2024-03-11 23:39:13+00:00            51  \n",
      "2 2024-03-11 16:20:23+00:00            26  \n",
      "count    10000.000000\n",
      "mean        28.409500\n",
      "std         17.279742\n",
      "min          0.000000\n",
      "25%         16.000000\n",
      "50%         24.000000\n",
      "75%         36.000000\n",
      "max        120.000000\n",
      "Name: title_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "data['title_length'] = data['title'].apply(lambda x: len(x) if pd.notna(x) else 0)\n",
    "print(data.head(3))\n",
    "\n",
    "TL = data[\"title_length\"]\n",
    "stats_TL = TL.describe()\n",
    "print(stats_TL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>published_platform</th>\n",
       "      <th>rating</th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Desktop</td>\n",
       "      <td>3</td>\n",
       "      <td>review</td>\n",
       "      <td>We used this airline to go from Singapore to L...</td>\n",
       "      <td>Ok</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-12 18:41:14+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Desktop</td>\n",
       "      <td>5</td>\n",
       "      <td>review</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The service in Suites Class makes one feel lik...</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-11 23:39:13+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Desktop</td>\n",
       "      <td>1</td>\n",
       "      <td>review</td>\n",
       "      <td>Booked, paid and received email confirmation f...</td>\n",
       "      <td>Don’t give them your money</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-11 16:20:23+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Desktop</td>\n",
       "      <td>5</td>\n",
       "      <td>review</td>\n",
       "      <td>Best airline in the world, seats, food, servic...</td>\n",
       "      <td>Best Airline in the World</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-11 11:12:27+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Desktop</td>\n",
       "      <td>2</td>\n",
       "      <td>review</td>\n",
       "      <td>Premium Economy Seating on Singapore Airlines ...</td>\n",
       "      <td>Premium Economy Seating on Singapore Airlines ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-10 09:34:18+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  published_platform  rating    type  \\\n",
       "0            Desktop       3  review   \n",
       "1            Desktop       5  review   \n",
       "2            Desktop       1  review   \n",
       "3            Desktop       5  review   \n",
       "4            Desktop       2  review   \n",
       "\n",
       "                                                text  \\\n",
       "0  We used this airline to go from Singapore to L...   \n",
       "1                                                NaN   \n",
       "2  Booked, paid and received email confirmation f...   \n",
       "3  Best airline in the world, seats, food, servic...   \n",
       "4  Premium Economy Seating on Singapore Airlines ...   \n",
       "\n",
       "                                               title  helpful_votes  \\\n",
       "0                                                 Ok              0   \n",
       "1  The service in Suites Class makes one feel lik...              0   \n",
       "2                         Don’t give them your money              0   \n",
       "3                          Best Airline in the World              0   \n",
       "4  Premium Economy Seating on Singapore Airlines ...              0   \n",
       "\n",
       "                       date  \n",
       "0 2024-03-12 18:41:14+00:00  \n",
       "1 2024-03-11 23:39:13+00:00  \n",
       "2 2024-03-11 16:20:23+00:00  \n",
       "3 2024-03-11 11:12:27+00:00  \n",
       "4 2024-03-10 09:34:18+00:00  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_TL = TL.mean()\n",
    "# print(mean_TL)\n",
    "\n",
    "sd_TL = TL.std()\n",
    "# print(sd_TL)\n",
    "\n",
    "threshold = 3\n",
    "\n",
    "z_score = zscore(TL)\n",
    "# print(z_score)\n",
    "\n",
    "# Remove 'title' of lengths that are greater than 3 standard deviations above the mean\n",
    "data.loc[abs(z_score) > threshold, 'title'] = np.nan\n",
    "# print(data.head(3))\n",
    "\n",
    "data = data.drop(\"title_length\", axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype              \n",
      "---  ------              --------------  -----              \n",
      " 0   published_platform  10000 non-null  object             \n",
      " 1   rating              10000 non-null  int64              \n",
      " 2   type                10000 non-null  object             \n",
      " 3   text                9846 non-null   object             \n",
      " 4   title               9834 non-null   object             \n",
      " 5   helpful_votes       10000 non-null  int64              \n",
      " 6   date                10000 non-null  datetime64[ns, UTC]\n",
      "dtypes: datetime64[ns, UTC](1), int64(2), object(4)\n",
      "memory usage: 547.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "published_platform                 object\n",
      "rating                              int64\n",
      "type                               object\n",
      "text                               object\n",
      "title                              object\n",
      "helpful_votes                       int64\n",
      "date                  datetime64[ns, UTC]\n",
      "dtype: object\n",
      "Remaining duplicate rows: 0\n",
      "Unique ratings: [3 5 1 2 4]\n"
     ]
    }
   ],
   "source": [
    "#check data types of each column, make sure they are correct\n",
    "print(data.dtypes)\n",
    "\n",
    "# Make sure no more duplicates are present\n",
    "print(\"Remaining duplicate rows:\", data.duplicated().sum())\n",
    "\n",
    "# Check for outliers in ratings\n",
    "print(\"Unique ratings:\", data['rating'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "published_platform      0\n",
       "rating                  0\n",
       "type                    0\n",
       "text                  154\n",
       "title                 166\n",
       "helpful_votes           0\n",
       "date                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new column `full_review`\n",
    "Since there are some rows with empty `text` and `title`, we will concatenate both columns (`text` and `title`) to form a new column `full_review`.\n",
    "1. Replace `NaN` values in `text` and `title` with an empty string.\n",
    "\n",
    "2. Combine `text` and `title` into `full_review`.\n",
    "\n",
    "3. Strip any leading/trailing whitespaces in `full_review`.\n",
    "\n",
    "4. Drop `text` and `title` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  published_platform  rating    type  helpful_votes                      date  \\\n",
      "0            Desktop       3  review              0 2024-03-12 18:41:14+00:00   \n",
      "1            Desktop       5  review              0 2024-03-11 23:39:13+00:00   \n",
      "2            Desktop       1  review              0 2024-03-11 16:20:23+00:00   \n",
      "3            Desktop       5  review              0 2024-03-11 11:12:27+00:00   \n",
      "4            Desktop       2  review              0 2024-03-10 09:34:18+00:00   \n",
      "\n",
      "                                         full_review  \n",
      "0  We used this airline to go from Singapore to L...  \n",
      "1  The service in Suites Class makes one feel lik...  \n",
      "2  Booked, paid and received email confirmation f...  \n",
      "3  Best airline in the world, seats, food, servic...  \n",
      "4  Premium Economy Seating on Singapore Airlines ...  \n",
      "\n",
      "The old shape is: (10000, 6)\n"
     ]
    }
   ],
   "source": [
    "# 1) Fill NaN values in 'text' and 'title' with an empty string\n",
    "data['title'] = data['title'].fillna('')\n",
    "data['text'] = data['text'].fillna('')\n",
    "\n",
    "# 2) Combine 'text' and 'title' into 'full_review'\n",
    "data['full_review'] = data['text'] + \" \" + data['title']\n",
    "\n",
    "# 3) Strip any leading/trailing whitespace\n",
    "data['full_review'] = data['full_review'].str.strip()\n",
    "\n",
    "# 4) Drop `text` and `title` columns\n",
    "data = data.drop(columns = ['text', 'title'])\n",
    "\n",
    "# Check if the 'full_review' column was added and if 'text' and 'title' columns has been dropped\n",
    "print(data.head())\n",
    "print(\"\\nThe old shape is:\",data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove empty strings\n",
    "1. Drop rows where `full_review` are empty strings and reset the index.\n",
    "\n",
    "2. Check if there are no more null values in `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new shape is: (9989, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "published_platform    0\n",
       "rating                0\n",
       "type                  0\n",
       "helpful_votes         0\n",
       "date                  0\n",
       "full_review           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Drop rows where `full_review` are empty strings and reset the index\n",
    "data = data[data['full_review'] != \"\"].reset_index(drop=True)\n",
    "print(\"The new shape is:\",data.shape)\n",
    "\n",
    "# 2) Check if there are no more null values in `data`\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new column `language`\n",
    "In the case where there are rows where `full_review` are in different languages (e.g., French, Russian, etc.) other than English. We decided to use 2 different language detector libraries (`langdetect`, `langid`) on the `full_review` column and combined the predictions of all 2 libraries and selecting the most frequent predicted language.\n",
    "\n",
    "**Reason**: `langdetect` might perform well on longer texts while `langid` is more reliable on short texts, using multiple detectors reduces the likelihood of misclassification and mitigates individual detector errors, leading to more accurate overall predictions. Also, even if one detector fails or throws an error, the other can still provide predictions, therefore improving the robustness of the language detection.\n",
    "\n",
    "1. Set a seed for `langdetect` to ensure reproducibility.\n",
    "\n",
    "2. Preprocess the text in `full_review`:\n",
    "    - a\\) Function to remove non-alphabetic characters and normalise whitespaces in  `full_review`.\n",
    "    - b\\) Function to determine if the text is non-language (e.g., numbers, symbols only).\n",
    "\n",
    "3. Two functions for language detection:\n",
    "    - a\\) Using `langdetect`.\n",
    "    - b\\) Using `langid`.\n",
    "\n",
    "4. Function for calculating majority vote for each language.\n",
    "\n",
    "5. Function for parallel processing for efficiency.\n",
    "\n",
    "6. Caching function for repeated inputs\n",
    "\n",
    "7. Function for choosing language based on combined majority voting.\n",
    "\n",
    "8. Applying the combined function on `full_review` column.\n",
    "\n",
    "9. Display the resulting `data` DataFrame.\n",
    "\n",
    "### <span style=\"color:red\">The code below will take approximately 1 minute to run!</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Language Detection: 100%|██████████| 9989/9989 [01:16<00:00, 130.47it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>published_platform</th>\n",
       "      <th>rating</th>\n",
       "      <th>type</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>date</th>\n",
       "      <th>full_review</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Desktop</td>\n",
       "      <td>3</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-12 18:41:14+00:00</td>\n",
       "      <td>We used this airline to go from Singapore to L...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Desktop</td>\n",
       "      <td>5</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-11 23:39:13+00:00</td>\n",
       "      <td>The service in Suites Class makes one feel lik...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Desktop</td>\n",
       "      <td>1</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-11 16:20:23+00:00</td>\n",
       "      <td>Booked, paid and received email confirmation f...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Desktop</td>\n",
       "      <td>5</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-11 11:12:27+00:00</td>\n",
       "      <td>Best airline in the world, seats, food, servic...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Desktop</td>\n",
       "      <td>2</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-10 09:34:18+00:00</td>\n",
       "      <td>Premium Economy Seating on Singapore Airlines ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>Desktop</td>\n",
       "      <td>5</td>\n",
       "      <td>review</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-08-06 07:48:21+00:00</td>\n",
       "      <td>First part done with Singapore Airlines - acce...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>Mobile</td>\n",
       "      <td>5</td>\n",
       "      <td>review</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-08-06 02:50:29+00:00</td>\n",
       "      <td>And again a great Flight with Singapore Air. G...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>Desktop</td>\n",
       "      <td>5</td>\n",
       "      <td>review</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-08-06 02:47:06+00:00</td>\n",
       "      <td>We flew business class from Frankfurt, via Sin...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>Desktop</td>\n",
       "      <td>4</td>\n",
       "      <td>review</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-08-06 00:32:03+00:00</td>\n",
       "      <td>As always, the A380 aircraft was spotlessly pr...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>Desktop</td>\n",
       "      <td>4</td>\n",
       "      <td>review</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-08-06 00:19:51+00:00</td>\n",
       "      <td>As always, Singapore Airlines has done it agai...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9989 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     published_platform  rating    type  helpful_votes  \\\n",
       "0               Desktop       3  review              0   \n",
       "1               Desktop       5  review              0   \n",
       "2               Desktop       1  review              0   \n",
       "3               Desktop       5  review              0   \n",
       "4               Desktop       2  review              0   \n",
       "...                 ...     ...     ...            ...   \n",
       "9984            Desktop       5  review              1   \n",
       "9985             Mobile       5  review              1   \n",
       "9986            Desktop       5  review              1   \n",
       "9987            Desktop       4  review              2   \n",
       "9988            Desktop       4  review              3   \n",
       "\n",
       "                          date  \\\n",
       "0    2024-03-12 18:41:14+00:00   \n",
       "1    2024-03-11 23:39:13+00:00   \n",
       "2    2024-03-11 16:20:23+00:00   \n",
       "3    2024-03-11 11:12:27+00:00   \n",
       "4    2024-03-10 09:34:18+00:00   \n",
       "...                        ...   \n",
       "9984 2018-08-06 07:48:21+00:00   \n",
       "9985 2018-08-06 02:50:29+00:00   \n",
       "9986 2018-08-06 02:47:06+00:00   \n",
       "9987 2018-08-06 00:32:03+00:00   \n",
       "9988 2018-08-06 00:19:51+00:00   \n",
       "\n",
       "                                            full_review language  \n",
       "0     We used this airline to go from Singapore to L...       en  \n",
       "1     The service in Suites Class makes one feel lik...       en  \n",
       "2     Booked, paid and received email confirmation f...       en  \n",
       "3     Best airline in the world, seats, food, servic...       en  \n",
       "4     Premium Economy Seating on Singapore Airlines ...       en  \n",
       "...                                                 ...      ...  \n",
       "9984  First part done with Singapore Airlines - acce...       en  \n",
       "9985  And again a great Flight with Singapore Air. G...       en  \n",
       "9986  We flew business class from Frankfurt, via Sin...       en  \n",
       "9987  As always, the A380 aircraft was spotlessly pr...       en  \n",
       "9988  As always, Singapore Airlines has done it agai...       en  \n",
       "\n",
       "[9989 rows x 7 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Set a seed for langdetect to ensure reproducibility\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "# 2a) Simplified preprocessing: only remove non-alphabetic characters\n",
    "def preprocess_text_simple(text):\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove non-alphabetic characters\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Normalize whitespace\n",
    "    return text.strip()\n",
    "\n",
    "# 2b) Check if the text is non-language (e.g., numbers, symbols only)\n",
    "def is_non_language_text(text):\n",
    "    if re.match(r'^[^a-zA-Z]*$', text):  # Check if text has no alphabetic characters\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# 3a) Function to get langdetect prediction\n",
    "def get_langdetect_prediction(text):\n",
    "    try:\n",
    "        # Directly use text without preprocessing for efficiency\n",
    "        if len(text) < 10 or is_non_language_text(text):\n",
    "            return \"unknown\"\n",
    "        lang = langdetect_detect(text)\n",
    "        return lang\n",
    "    except LangDetectException:\n",
    "        return \"unknown\"\n",
    "\n",
    "# 3b) Function to get langid prediction\n",
    "def get_langid_prediction(text):\n",
    "    try:\n",
    "        lang, _ = langid_classify(text)\n",
    "        if len(text) < 10 or is_non_language_text(text):\n",
    "            return \"unknown\"\n",
    "        return lang\n",
    "    except Exception:\n",
    "        return \"unknown\"\n",
    "\n",
    "# 4) Function to calculate majority vote for each language\n",
    "def calculate_majority_vote(predictions):\n",
    "    vote_counts = {}\n",
    "    for lang in predictions:\n",
    "        if lang in vote_counts:\n",
    "            vote_counts[lang] += 1\n",
    "        else:\n",
    "            vote_counts[lang] = 1\n",
    "    return vote_counts\n",
    "\n",
    "# 5) Parallel processing for efficiency with limited workers\n",
    "def parallel_detection(text):\n",
    "    with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        results = list(executor.map(lambda func: func(text), \n",
    "                                    [get_langdetect_prediction, get_langid_prediction]))\n",
    "    return results\n",
    "\n",
    "# 6) Caching function for repeated inputs\n",
    "@lru_cache(maxsize=500)\n",
    "def get_cached_language(text):\n",
    "    return combined_language_detection(text)\n",
    "\n",
    "# 7) Combined majority voting language detection function\n",
    "def combined_language_detection(text):\n",
    "    # Check if the text is non-language (e.g., numbers, symbols only)\n",
    "    if is_non_language_text(text):\n",
    "        return \"unknown\"\n",
    "    \n",
    "    # Run the detectors in parallel for efficiency\n",
    "    predictions = parallel_detection(text)\n",
    "    \n",
    "    # Calculate majority vote for each language based on predictions\n",
    "    vote_counts = calculate_majority_vote(predictions)\n",
    "    \n",
    "    # Determine the language with the highest majority vote\n",
    "    final_language = max(vote_counts, key=vote_counts.get)\n",
    "    \n",
    "    # If \"unknown\" is the most common or if all detectors fail, return \"unknown\"\n",
    "    if final_language == \"unknown\" or vote_counts[final_language] <= 1:\n",
    "        return \"unknown\"\n",
    "    \n",
    "    return final_language\n",
    "\n",
    "# 8) Apply the cached function to each text in the DataFrame with a progress bar\n",
    "data['language'] = [get_cached_language(text) for text in tqdm(data['full_review'], desc=\"Language Detection\")]\n",
    "\n",
    "# 9) Display the DataFrame with detected languages\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "language\n",
       "en         9952\n",
       "unknown      32\n",
       "es            1\n",
       "de            1\n",
       "th            1\n",
       "fr            1\n",
       "sv            1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See distribution of languages\n",
    "data[\"language\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9952, 7)\n"
     ]
    }
   ],
   "source": [
    "# Drop rows where language is NOT in english and reset the index\n",
    "data = data[data['language'] == 'en'].reset_index(drop=True)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will drop the `language` column since all values of `language` are `en` and all `full_review` are in the English language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9952 entries, 0 to 9951\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype              \n",
      "---  ------              --------------  -----              \n",
      " 0   published_platform  9952 non-null   object             \n",
      " 1   rating              9952 non-null   int64              \n",
      " 2   type                9952 non-null   object             \n",
      " 3   helpful_votes       9952 non-null   int64              \n",
      " 4   date                9952 non-null   datetime64[ns, UTC]\n",
      " 5   full_review         9952 non-null   object             \n",
      " 6   language            9952 non-null   object             \n",
      "dtypes: datetime64[ns, UTC](1), int64(2), object(4)\n",
      "memory usage: 544.4+ KB\n",
      "The new shape is: (9952, 6)\n"
     ]
    }
   ],
   "source": [
    "data.info()\n",
    "data.drop(columns=[\"language\"], inplace=True)\n",
    "print(\"The new shape is:\", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>published_platform</th>\n",
       "      <th>rating</th>\n",
       "      <th>type</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>date</th>\n",
       "      <th>full_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Desktop</td>\n",
       "      <td>3</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-12 18:41:14+00:00</td>\n",
       "      <td>We used this airline to go from Singapore to L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Desktop</td>\n",
       "      <td>5</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-11 23:39:13+00:00</td>\n",
       "      <td>The service in Suites Class makes one feel lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Desktop</td>\n",
       "      <td>1</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-11 16:20:23+00:00</td>\n",
       "      <td>Booked, paid and received email confirmation f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Desktop</td>\n",
       "      <td>5</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-11 11:12:27+00:00</td>\n",
       "      <td>Best airline in the world, seats, food, servic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Desktop</td>\n",
       "      <td>2</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-10 09:34:18+00:00</td>\n",
       "      <td>Premium Economy Seating on Singapore Airlines ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  published_platform  rating    type  helpful_votes                      date  \\\n",
       "0            Desktop       3  review              0 2024-03-12 18:41:14+00:00   \n",
       "1            Desktop       5  review              0 2024-03-11 23:39:13+00:00   \n",
       "2            Desktop       1  review              0 2024-03-11 16:20:23+00:00   \n",
       "3            Desktop       5  review              0 2024-03-11 11:12:27+00:00   \n",
       "4            Desktop       2  review              0 2024-03-10 09:34:18+00:00   \n",
       "\n",
       "                                         full_review  \n",
       "0  We used this airline to go from Singapore to L...  \n",
       "1  The service in Suites Class makes one feel lik...  \n",
       "2  Booked, paid and received email confirmation f...  \n",
       "3  Best airline in the world, seats, food, servic...  \n",
       "4  Premium Economy Seating on Singapore Airlines ...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing for NLP\n",
    "\n",
    "Word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression (Part1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/mayaung/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "X = data['full_review'] \n",
    "y = (data['rating'] > 3).astype(int)  \n",
    "\n",
    "nltk.download('punkt')\n",
    "tokenized_sentences = [word_tokenize(sentence.lower()) for sentence in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing: vectorizing the text data\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X_vectorized = vectorizer.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 90.05%\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting and evaluating\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Output the accuracy\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression (Part 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 82.82%\n",
      "Predicted Sentiments: [2 2 2 ... 2 2 1]\n",
      "True Sentiments: [2 2 0 ... 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "# Define X (features) and y (target) based on multiclass sentiment\n",
    "X = data['full_review']  # Review text\n",
    "\n",
    "# Multiclass sentiment: 0 for negative, 1 for neutral, 2 for positive\n",
    "def sentiment_label(rating):\n",
    "    if rating < 2:\n",
    "        return 0  # Negative\n",
    "    elif rating == 3:\n",
    "        return 1  # Neutral\n",
    "    else:\n",
    "        return 2  # Positive\n",
    "\n",
    "y = data['rating'].apply(sentiment_label)\n",
    "\n",
    "# Text preprocessing: vectorizing the text data\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X_vectorized = vectorizer.fit_transform(X)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Logistic regression model (for multiclass classification)\n",
    "model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting and evaluating\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Output the accuracy\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Optional: Output predictions and true values for comparison\n",
    "print(\"Predicted Sentiments:\", y_pred)\n",
    "print(\"True Sentiments:\", y_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FastText Embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/mayaung/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 83.89%\n",
      "Cross-Validation Scores: [0.83776996 0.82621798 0.8361809  0.8361809  0.84020101]\n",
      "Average Cross-Validation Accuracy: 83.53%\n"
     ]
    }
   ],
   "source": [
    "# Ensure you have the required NLTK package\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "# Define X (features) and y (target) based on multiclass sentiment\n",
    "X = data['full_review']  # Review text\n",
    "\n",
    "# Multiclass sentiment: 0 for negative, 1 for neutral, 2 for positive\n",
    "def sentiment_label(rating):\n",
    "    if rating < 2:\n",
    "        return 0  # Negative\n",
    "    elif rating == 3:\n",
    "        return 1  # Neutral\n",
    "    else:\n",
    "        return 2  # Positive\n",
    "\n",
    "y = data['rating'].apply(sentiment_label)\n",
    "\n",
    "# Step 1: Tokenize the sentences\n",
    "tokenized_sentences = [nltk.word_tokenize(sentence.lower()) for sentence in X]\n",
    "\n",
    "# Step 2: Train the FastText model\n",
    "fasttext_model = FastText(sentences=tokenized_sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Step 3: Function to average word vectors for each sentence\n",
    "def get_sentence_vector(sentence, model, vector_size):\n",
    "    words = nltk.word_tokenize(sentence.lower())\n",
    "    word_vectors = [model.wv[word] for word in words if word in model.wv]\n",
    "    if len(word_vectors) == 0:\n",
    "        return np.zeros(vector_size)  # Return a zero vector if no words are found\n",
    "    return np.mean(word_vectors, axis=0)\n",
    "\n",
    "# Step 4: Convert each sentence to its FastText vector representation\n",
    "X_vectors = np.array([get_sentence_vector(sentence, fasttext_model, 100) for sentence in X])\n",
    "\n",
    "# Step 5: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vectors, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Step 6: Logistic regression model (for multiclass classification)\n",
    "model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 7: Predicting and evaluating\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Output the accuracy\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Step 8 (Optional): Implement Cross-Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(model, X_vectors, y, cv=kf, scoring=make_scorer(accuracy_score))\n",
    "\n",
    "# Output cross-validation results\n",
    "print(f\"Cross-Validation Scores: {cv_scores}\")\n",
    "print(f\"Average Cross-Validation Accuracy: {np.mean(cv_scores) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/mayaung/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mayaung/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/mayaung/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/mayaung/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure require NLTK data is downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "# Define function to process text\n",
    "def process_full_review(text):\n",
    "    processed_text = \"\"\n",
    "\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Tokenize the text into words\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Keep only alphabetic tokens\n",
    "    alphabetic_tokens = [i for i in tokens if re.match('^[a-zA-Z]+$', i)]\n",
    "\n",
    "    if len(alphabetic_tokens) == 0:\n",
    "        # Return empty processed text if there are no alphabetic tokens\n",
    "        return processed_text\n",
    "\n",
    "    # List of stopwords\n",
    "    stop_words = stopwords.words('english')\n",
    "\n",
    "    # List of allowed words (to preserve certain negative words and conjuctions)\n",
    "    allowed_words = [\"no\", \"not\", \"don't\", \"dont\", \"don\", \"but\", \n",
    "                     \"however\", \"never\", \"wasn't\", \"wasnt\", \"shouldn't\",\n",
    "                     \"shouldnt\", \"mustn't\", \"musnt\"]\n",
    "    '''\n",
    "    these words may carry important information, such as negative connotations. in examples such as\n",
    "    \"don't ever get this dish\" -> if don't was removed, it may be interpreted as \"get dish\", which is of the opposite sentiment\n",
    "    of what the original review is supposed to be.\n",
    "    Conjunctions like \"but\" and \"however\" shows a contrast to the sentence said before, meaning that the sentiment can be\n",
    "    negatively affected or at the very least, impacted. Similarly for \"mustn't\" or \"shouldn't\", they typically carry a negative sentiment.\n",
    "    '''\n",
    "\n",
    "    # Filter out stopwords, keeping allowed words\n",
    "    filtered_tokens = [i for i in alphabetic_tokens if i not in stop_words or i in allowed_words]\n",
    "\n",
    "    # Initialise the WordNet Lemmatizer\n",
    "    stemmer = PorterStemmer()\n",
    "\n",
    "    # Stem the filtered tokens\n",
    "    stemmed_words = [stemmer.stem(word) for word in filtered_tokens]\n",
    "\n",
    "    # Join the stemmed words back into a single string\n",
    "    processed_text = ' '.join(stemmed_words)\n",
    "\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Reviews: 100%|██████████| 9952/9952 [00:12<00:00, 803.23it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>published_platform</th>\n",
       "      <th>rating</th>\n",
       "      <th>type</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>date</th>\n",
       "      <th>full_review</th>\n",
       "      <th>processed_full_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Desktop</td>\n",
       "      <td>3</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-12 18:41:14+00:00</td>\n",
       "      <td>We used this airline to go from Singapore to L...</td>\n",
       "      <td>use airlin go singapor london heathrow issu ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Desktop</td>\n",
       "      <td>5</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-11 23:39:13+00:00</td>\n",
       "      <td>The service in Suites Class makes one feel lik...</td>\n",
       "      <td>servic suit class make one feel like vip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Desktop</td>\n",
       "      <td>1</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-11 16:20:23+00:00</td>\n",
       "      <td>Booked, paid and received email confirmation f...</td>\n",
       "      <td>book paid receiv email confirm extra legroom s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Desktop</td>\n",
       "      <td>5</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-11 11:12:27+00:00</td>\n",
       "      <td>Best airline in the world, seats, food, servic...</td>\n",
       "      <td>best airlin world seat food servic brilliant c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Desktop</td>\n",
       "      <td>2</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-10 09:34:18+00:00</td>\n",
       "      <td>Premium Economy Seating on Singapore Airlines ...</td>\n",
       "      <td>premium economi seat singapor airlin narrow se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9947</th>\n",
       "      <td>Desktop</td>\n",
       "      <td>5</td>\n",
       "      <td>review</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-08-06 07:48:21+00:00</td>\n",
       "      <td>First part done with Singapore Airlines - acce...</td>\n",
       "      <td>first part done singapor airlin accept comfort...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9948</th>\n",
       "      <td>Mobile</td>\n",
       "      <td>5</td>\n",
       "      <td>review</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-08-06 02:50:29+00:00</td>\n",
       "      <td>And again a great Flight with Singapore Air. G...</td>\n",
       "      <td>great flight singapor air great uniqu servic o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9949</th>\n",
       "      <td>Desktop</td>\n",
       "      <td>5</td>\n",
       "      <td>review</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-08-06 02:47:06+00:00</td>\n",
       "      <td>We flew business class from Frankfurt, via Sin...</td>\n",
       "      <td>flew busi class frankfurt via singapor brisban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9950</th>\n",
       "      <td>Desktop</td>\n",
       "      <td>4</td>\n",
       "      <td>review</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-08-06 00:32:03+00:00</td>\n",
       "      <td>As always, the A380 aircraft was spotlessly pr...</td>\n",
       "      <td>alway aircraft spotlessli present board carpet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9951</th>\n",
       "      <td>Desktop</td>\n",
       "      <td>4</td>\n",
       "      <td>review</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-08-06 00:19:51+00:00</td>\n",
       "      <td>As always, Singapore Airlines has done it agai...</td>\n",
       "      <td>alway singapor airlin done flight sector trip ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9952 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     published_platform  rating    type  helpful_votes  \\\n",
       "0               Desktop       3  review              0   \n",
       "1               Desktop       5  review              0   \n",
       "2               Desktop       1  review              0   \n",
       "3               Desktop       5  review              0   \n",
       "4               Desktop       2  review              0   \n",
       "...                 ...     ...     ...            ...   \n",
       "9947            Desktop       5  review              1   \n",
       "9948             Mobile       5  review              1   \n",
       "9949            Desktop       5  review              1   \n",
       "9950            Desktop       4  review              2   \n",
       "9951            Desktop       4  review              3   \n",
       "\n",
       "                          date  \\\n",
       "0    2024-03-12 18:41:14+00:00   \n",
       "1    2024-03-11 23:39:13+00:00   \n",
       "2    2024-03-11 16:20:23+00:00   \n",
       "3    2024-03-11 11:12:27+00:00   \n",
       "4    2024-03-10 09:34:18+00:00   \n",
       "...                        ...   \n",
       "9947 2018-08-06 07:48:21+00:00   \n",
       "9948 2018-08-06 02:50:29+00:00   \n",
       "9949 2018-08-06 02:47:06+00:00   \n",
       "9950 2018-08-06 00:32:03+00:00   \n",
       "9951 2018-08-06 00:19:51+00:00   \n",
       "\n",
       "                                            full_review  \\\n",
       "0     We used this airline to go from Singapore to L...   \n",
       "1     The service in Suites Class makes one feel lik...   \n",
       "2     Booked, paid and received email confirmation f...   \n",
       "3     Best airline in the world, seats, food, servic...   \n",
       "4     Premium Economy Seating on Singapore Airlines ...   \n",
       "...                                                 ...   \n",
       "9947  First part done with Singapore Airlines - acce...   \n",
       "9948  And again a great Flight with Singapore Air. G...   \n",
       "9949  We flew business class from Frankfurt, via Sin...   \n",
       "9950  As always, the A380 aircraft was spotlessly pr...   \n",
       "9951  As always, Singapore Airlines has done it agai...   \n",
       "\n",
       "                                  processed_full_review  \n",
       "0     use airlin go singapor london heathrow issu ti...  \n",
       "1              servic suit class make one feel like vip  \n",
       "2     book paid receiv email confirm extra legroom s...  \n",
       "3     best airlin world seat food servic brilliant c...  \n",
       "4     premium economi seat singapor airlin narrow se...  \n",
       "...                                                 ...  \n",
       "9947  first part done singapor airlin accept comfort...  \n",
       "9948  great flight singapor air great uniqu servic o...  \n",
       "9949  flew busi class frankfurt via singapor brisban...  \n",
       "9950  alway aircraft spotlessli present board carpet...  \n",
       "9951  alway singapor airlin done flight sector trip ...  \n",
       "\n",
       "[9952 rows x 7 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enable tqdm for pandas (progress bar)\n",
    "tqdm.pandas(desc=\"Processing Reviews\")\n",
    "\n",
    "# Apply process_full_review function with tqdm progress bar and expand the results into a\n",
    "data['processed_full_review'] = data['full_review'].progress_apply(process_full_review)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping ratings to sentiment labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "Positive    7375\n",
      "Negative    1577\n",
      "Neutral     1000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Function to map ratings to sentiment\n",
    "def rating_to_sentiment(rating):\n",
    "    if rating <= 2:\n",
    "        return 'Negative'\n",
    "    elif rating == 3:\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Positive'\n",
    "\n",
    "# Apply the function to the 'rating' column\n",
    "data['sentiment'] = data['rating'].apply(rating_to_sentiment)\n",
    "\n",
    "# Check the sentiment distribution\n",
    "print(data['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "Now, we select the final features to use for our sentiment analysis of airline reviews. \n",
    "- `processed_full_review`,`processed_review_length`, `sentiment`,`year`,`month`\n",
    "\n",
    "- Columns excluded: [`published_platform`,`type`,`helpful_votes`,`language`,`review_length`,`day`,`day_of_week`,`year_month`]\n",
    "\n",
    "- Create a new DataFrame (`data_final`) by selecting the specifc columns mentioned above from the original DataFrame `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>processed_full_review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>use airlin go singapor london heathrow issu ti...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>servic suit class make one feel like vip</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>book paid receiv email confirm extra legroom s...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>best airlin world seat food servic brilliant c...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>premium economi seat singapor airlin narrow se...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               processed_full_review sentiment\n",
       "0  use airlin go singapor london heathrow issu ti...   Neutral\n",
       "1           servic suit class make one feel like vip  Positive\n",
       "2  book paid receiv email confirm extra legroom s...  Negative\n",
       "3  best airlin world seat food servic brilliant c...  Positive\n",
       "4  premium economi seat singapor airlin narrow se...  Negative"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final = data[['processed_full_review','sentiment']]\n",
    "data_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial NB with Count Vectorizer\n",
    "\n",
    "Count vectoriser converts a collection of text documents into a matrix of token counts. It simply counts the number of occurrences of each word in the document without considering the importance of frequency of words across the entire corpus.\n",
    "\n",
    "Count vectoriser counts the raw frequency where each word is weighted equally while tf-idf is weighted by term frequency and rarity across documents.\n",
    "\n",
    "Count vectoriser is simple and fast as it's just raw counts, while tf-idf requires more computation as it is slightly more complex due to the use of inverse document frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8422638981915607\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.76      0.69      0.72       485\n",
      "     Neutral       0.42      0.63      0.50       307\n",
      "    Positive       0.95      0.91      0.93      2194\n",
      "\n",
      "    accuracy                           0.84      2986\n",
      "   macro avg       0.71      0.74      0.72      2986\n",
      "weighted avg       0.87      0.84      0.85      2986\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=1000)\n",
    "X = vectorizer.fit_transform(data['processed_full_review'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, data['sentiment'],test_size=0.3, random_state=42)\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train,y_train)\n",
    "\n",
    "nb_predictions = nb_model.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test,nb_predictions))\n",
    "print(classification_report(y_test, nb_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF with Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.8419290020093771\n",
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.80      0.70      0.75       485\n",
      "     Neutral       0.47      0.02      0.04       307\n",
      "    Positive       0.85      0.99      0.91      2194\n",
      "\n",
      "    accuracy                           0.84      2986\n",
      "   macro avg       0.71      0.57      0.57      2986\n",
      "weighted avg       0.80      0.84      0.80      2986\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, rf_predictions))\n",
    "print(\"Random Forest Classification Report:\\n\", classification_report(y_test, rf_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log Regression with Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8479571332886805\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.73      0.75      0.74       485\n",
      "     Neutral       0.42      0.36      0.39       307\n",
      "    Positive       0.93      0.94      0.93      2194\n",
      "\n",
      "    accuracy                           0.85      2986\n",
      "   macro avg       0.69      0.68      0.69      2986\n",
      "weighted avg       0.84      0.85      0.84      2986\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mayaung/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=42, max_iter=100).fit(X_train, y_train)\n",
    "clf_predictions = clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, clf_predictions))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, clf_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using count vectoriser, log regression does not converge since count vectoriser produces raw counts for each word, which can result in large values in the feature matrix, especially if a word appears very frequently in a document while TF-IDF normalises these counts by down-weighting common words and dividing by the document length, leading to smaller values in the feature matrix.\n",
    "\n",
    "Log regression is sensitive to the scale of features. Since Count Vectoriser can produce features of widely varying scales (some words may appear 1000 times, others only once), this can affect convergence. TF-IDF normalises the data, results in features that are more evenly scaled, leading to easier optimisation and quicker convergence.\n",
    "\n",
    "Fixed by increasing max_iter from 100 to 200 OR scaling data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8479571332886805\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.73      0.74      0.74       485\n",
      "     Neutral       0.42      0.36      0.39       307\n",
      "    Positive       0.93      0.94      0.93      2194\n",
      "\n",
      "    accuracy                           0.85      2986\n",
      "   macro avg       0.69      0.68      0.69      2986\n",
      "weighted avg       0.84      0.85      0.84      2986\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=42, max_iter=200).fit(X_train, y_train)\n",
    "clf_predictions = clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, clf_predictions))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, clf_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8114534494306765\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.67      0.69      0.68       485\n",
      "     Neutral       0.33      0.36      0.34       307\n",
      "    Positive       0.92      0.90      0.91      2194\n",
      "\n",
      "    accuracy                           0.81      2986\n",
      "   macro avg       0.64      0.65      0.64      2986\n",
      "weighted avg       0.82      0.81      0.81      2986\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler(with_mean=False)  # with_mean=False because sparse matrices don't support centering\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression(random_state=42).fit(X_train_scaled, y_train)\n",
    "clf_predictions = clf.predict(X_test_scaled)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, clf_predictions))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, clf_predictions))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
