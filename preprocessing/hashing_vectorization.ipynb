{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhancing Singapore Airlines' Service Through Automated Sentiment Analysis of Customer Reviews\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Motivation**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Singapore Airlines Customer Reviews Dataset Information\n",
    "\n",
    "The [Singapore Airlines Customer Reviews Dataset](https://www.kaggle.com/datasets/kanchana1990/singapore-airlines-reviews) aggregates 10,000 anonymized customer reviews, providing a broad perspective on the passenger experience with Singapore Airlines. \n",
    "\n",
    "The dimensions are shown below:\n",
    "- **`published_date`**: Date and time of review publication.\n",
    "- **`published_platform`**: Platform where the review was posted.\n",
    "- **`rating`**: Customer satisfaction rating, from 1 (lowest) to 5 (highest).\n",
    "- **`type`**: Specifies the content as a review.\n",
    "- **`text`**: Detailed customer feedback.\n",
    "- **`title`**: Summary of the review.\n",
    "- **`helpful_votes`**: Number of users finding the review helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional web scraping of online reviews\n",
    "\n",
    "During our EDA, we noticed two main trends in the distribution of our dataset:\n",
    "1. Less than 10% of our reviews were published from the years 2022 to 2024, making it hard for us to capture recent trends in sentiment.\n",
    "2. Most of the reviews were highly positive, which could mean that SIA had mostly positive reviews, nevertheless we wanted to get more information on negative reviews to improve the robustness of our model.\n",
    "\n",
    "### TripAdvisor\n",
    "\n",
    "We scraped more data for airline reviews from TripAdvisor, specifically for the years 2022 to 2024. \n",
    "(https://www.tripadvisor.com.sg/Airline_Review-d8729151-Reviews-Singapore-Airlines)\n",
    "\n",
    "The dimensions are shown below:\n",
    "- **`Year`**: Year of review publication.\n",
    "- **`Month`**: Month of review publication.\n",
    "- **`Title`**: Title of review publication.\n",
    "- **`Review Text`**: Main text content of review publication.\n",
    "- **`Rating`**: Numerical rating provided by reviewer (Scale: 1 to 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skytrax\n",
    "\n",
    "We also scraped from Skytrax, which is another data source for online reviews. \n",
    "(https://www.airlinequality.com/airline-reviews/singapore-airlines/?sortby=post_date%3ADesc&pagesize=100)\n",
    "\n",
    "The dimensions are shown below:\n",
    "- **`Year`**: Year of review publication.\n",
    "- **`Month`**: Month of review publication.\n",
    "- **`Title`**: Title of review publication.\n",
    "- **`Review Text`**: Main text content of review publication.\n",
    "- **`Rating`**: Numerical rating provided by reviewer (Scale: 1 to 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries\n",
    "\n",
    "Please uncomment the code box below to pip install relevant dependencies for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritikabajpai/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime \n",
    "\n",
    "# Statistical functions\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# For concurrency (running functions in parallel)\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# For caching (to speed up repeated function calls)\n",
    "from functools import lru_cache\n",
    "\n",
    "# For progress tracking\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Plotting and Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Language Detection packages\n",
    "# `langdetect` for detecting language\n",
    "from langdetect import detect as langdetect_detect, DetectorFactory\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "# `langid` for an alternative language detection method\n",
    "from langid import classify as langid_classify\n",
    "\n",
    "# Text Preprocessing and NLP\n",
    "# Stopwords (common words to ignore) from NLTK\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import nltk\n",
    "\n",
    "# Tokenizing sentences/words\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Tokenizing sentences/words\n",
    "from nltk.tokenize import word_tokenize\n",
    "# Lemmatization (converting words to their base form)\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# Regular expressions for text pattern matching\n",
    "import re\n",
    "\n",
    "# Word Cloud generation\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# For generating n-grams\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/ritikabajpai/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/ritikabajpai/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ritikabajpai/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ritikabajpai/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/ritikabajpai/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /Users/ritikabajpai/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## for Mac users, might have to install this manually\n",
    "\n",
    "# Ensure require NLTK data is downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation (Loading CSV)\n",
    "\n",
    "Load the three CSV files into a pandas DataFrame `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"singapore_airlines_reviews.csv\")\n",
    "tripadvisor_scraped_df = pd.read_csv('../web_scraping/singapore_airlines_reviews_tripadvisor.csv')\n",
    "skytrax_scraped_df = pd.read_csv('../web_scraping/singapore_airlines_reviews_skytrax.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>published_date</th>\n",
       "      <th>published_platform</th>\n",
       "      <th>rating</th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>helpful_votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03-12T14:41:14-04:00</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>3</td>\n",
       "      <td>review</td>\n",
       "      <td>We used this airline to go from Singapore to L...</td>\n",
       "      <td>Ok</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-03-11T19:39:13-04:00</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>5</td>\n",
       "      <td>review</td>\n",
       "      <td>The service on Singapore Airlines Suites Class...</td>\n",
       "      <td>The service in Suites Class makes one feel lik...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-03-11T12:20:23-04:00</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>1</td>\n",
       "      <td>review</td>\n",
       "      <td>Booked, paid and received email confirmation f...</td>\n",
       "      <td>Don’t give them your money</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-03-11T07:12:27-04:00</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>5</td>\n",
       "      <td>review</td>\n",
       "      <td>Best airline in the world, seats, food, servic...</td>\n",
       "      <td>Best Airline in the World</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-03-10T05:34:18-04:00</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>2</td>\n",
       "      <td>review</td>\n",
       "      <td>Premium Economy Seating on Singapore Airlines ...</td>\n",
       "      <td>Premium Economy Seating on Singapore Airlines ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              published_date published_platform  rating    type  \\\n",
       "0  2024-03-12T14:41:14-04:00            Desktop       3  review   \n",
       "1  2024-03-11T19:39:13-04:00            Desktop       5  review   \n",
       "2  2024-03-11T12:20:23-04:00            Desktop       1  review   \n",
       "3  2024-03-11T07:12:27-04:00            Desktop       5  review   \n",
       "4  2024-03-10T05:34:18-04:00            Desktop       2  review   \n",
       "\n",
       "                                                text  \\\n",
       "0  We used this airline to go from Singapore to L...   \n",
       "1  The service on Singapore Airlines Suites Class...   \n",
       "2  Booked, paid and received email confirmation f...   \n",
       "3  Best airline in the world, seats, food, servic...   \n",
       "4  Premium Economy Seating on Singapore Airlines ...   \n",
       "\n",
       "                                               title  helpful_votes  \n",
       "0                                                 Ok              0  \n",
       "1  The service in Suites Class makes one feel lik...              0  \n",
       "2                         Don’t give them your money              0  \n",
       "3                          Best Airline in the World              0  \n",
       "4  Premium Economy Seating on Singapore Airlines ...              0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024</td>\n",
       "      <td>May</td>\n",
       "      <td>I would give them zero stars!</td>\n",
       "      <td>I’d give zero stars if I could. I always see o...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024</td>\n",
       "      <td>September</td>\n",
       "      <td>Very Poor service/responce</td>\n",
       "      <td>Zero stars. Very disappointed with Singapore a...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024</td>\n",
       "      <td>October</td>\n",
       "      <td>Business Class of Singpore Airlines 2024</td>\n",
       "      <td>Amazing, best service ever. Food is amazing, e...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024</td>\n",
       "      <td>October</td>\n",
       "      <td>10/10 for how they handled our delayed flight</td>\n",
       "      <td>We had a 4.5 hour delay on our flight from Lon...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024</td>\n",
       "      <td>October</td>\n",
       "      <td>Premium Economy</td>\n",
       "      <td>The leg room was great but the food was terrib...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year      Month                                          Title  \\\n",
       "0  2024        May                  I would give them zero stars!   \n",
       "1  2024  September                     Very Poor service/responce   \n",
       "2  2024    October       Business Class of Singpore Airlines 2024   \n",
       "3  2024    October  10/10 for how they handled our delayed flight   \n",
       "4  2024    October                                Premium Economy   \n",
       "\n",
       "                                         Review Text  Rating  \n",
       "0  I’d give zero stars if I could. I always see o...     1.0  \n",
       "1  Zero stars. Very disappointed with Singapore a...     1.0  \n",
       "2  Amazing, best service ever. Food is amazing, e...     5.0  \n",
       "3  We had a 4.5 hour delay on our flight from Lon...     5.0  \n",
       "4  The leg room was great but the food was terrib...     3.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tripadvisor_scraped_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024</td>\n",
       "      <td>10</td>\n",
       "      <td>\"one of our most enjoyable flights\"</td>\n",
       "      <td>✅Trip Verified| We flew Singapore Air;ine (SIA...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024</td>\n",
       "      <td>10</td>\n",
       "      <td>\"Excellent for economy\"</td>\n",
       "      <td>✅Trip Verified|   Excellent for economy. Five ...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024</td>\n",
       "      <td>10</td>\n",
       "      <td>\"dismissive and unapologetic tone\"</td>\n",
       "      <td>✅Trip Verified|   My sister made an error in t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024</td>\n",
       "      <td>9</td>\n",
       "      <td>“Moon Festival Treats were a nice touch”</td>\n",
       "      <td>✅Trip Verified| SQ22 Solo Seat. Boards on Chan...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024</td>\n",
       "      <td>9</td>\n",
       "      <td>“Little touches are always nice”</td>\n",
       "      <td>✅Trip Verified| SQ191 HAN-SIN in Economy. Staf...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Month                                     Title  \\\n",
       "0  2024     10       \"one of our most enjoyable flights\"   \n",
       "1  2024     10                   \"Excellent for economy\"   \n",
       "2  2024     10        \"dismissive and unapologetic tone\"   \n",
       "3  2024      9  “Moon Festival Treats were a nice touch”   \n",
       "4  2024      9          “Little touches are always nice”   \n",
       "\n",
       "                                         Review Text  Rating  \n",
       "0  ✅Trip Verified| We flew Singapore Air;ine (SIA...      10  \n",
       "1  ✅Trip Verified|   Excellent for economy. Five ...      10  \n",
       "2  ✅Trip Verified|   My sister made an error in t...       1  \n",
       "3  ✅Trip Verified| SQ22 Solo Seat. Boards on Chan...      10  \n",
       "4  ✅Trip Verified| SQ191 HAN-SIN in Economy. Staf...      10  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skytrax_scraped_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TripAdvisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Clean TripAdvisor scraped dataframe\n",
    "def clean_tripadvisor_df(df):\n",
    "    cleaned_df = df.copy()\n",
    "    \n",
    "    # Convert rating to integer\n",
    "    cleaned_df['Rating'] = cleaned_df['Rating'].astype(int)  \n",
    "      \n",
    "    # Dictionary to map month names to numbers\n",
    "    month_map = {\n",
    "        'January': 1, 'February': 2, 'March': 3, 'April': 4,\n",
    "        'May': 5, 'June': 6, 'July': 7, 'August': 8,\n",
    "        'September': 9, 'October': 10, 'November': 11, 'December': 12}\n",
    "\n",
    "    # Applying the mapping to the 'Month' column\n",
    "    cleaned_df['Month'] = cleaned_df['Month'].map(month_map)\n",
    "    \n",
    "    ## Convert Year and Month to lowercase\n",
    "    cleaned_df = cleaned_df.rename(columns={'Year': 'year', 'Month': 'month'})\n",
    "\n",
    "    # Clean text fields\n",
    "    cleaned_df['Review Text'] = cleaned_df['Review Text'].apply(lambda x: str(x).strip())\n",
    "    cleaned_df['Title'] = cleaned_df['Title'].apply(lambda x: str(x).strip())\n",
    "        \n",
    "    # Remove any empty reviews\n",
    "    cleaned_df = cleaned_df.dropna(subset=['Review Text', 'Rating'])\n",
    "    \n",
    "    # Remove any duplicate reviews\n",
    "    cleaned_df.drop_duplicates(subset=['Review Text']).reset_index(drop=True)\n",
    "        \n",
    "    return cleaned_df\n",
    "\n",
    "\n",
    "\n",
    "# Apply cleaning functions\n",
    "clean_tripadvisor = clean_tripadvisor_df(tripadvisor_scraped_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "      <td>I would give them zero stars!</td>\n",
       "      <td>I’d give zero stars if I could. I always see o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024</td>\n",
       "      <td>9</td>\n",
       "      <td>Very Poor service/responce</td>\n",
       "      <td>Zero stars. Very disappointed with Singapore a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024</td>\n",
       "      <td>10</td>\n",
       "      <td>Business Class of Singpore Airlines 2024</td>\n",
       "      <td>Amazing, best service ever. Food is amazing, e...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024</td>\n",
       "      <td>10</td>\n",
       "      <td>10/10 for how they handled our delayed flight</td>\n",
       "      <td>We had a 4.5 hour delay on our flight from Lon...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024</td>\n",
       "      <td>10</td>\n",
       "      <td>Premium Economy</td>\n",
       "      <td>The leg room was great but the food was terrib...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month                                          Title  \\\n",
       "0  2024      5                  I would give them zero stars!   \n",
       "1  2024      9                     Very Poor service/responce   \n",
       "2  2024     10       Business Class of Singpore Airlines 2024   \n",
       "3  2024     10  10/10 for how they handled our delayed flight   \n",
       "4  2024     10                                Premium Economy   \n",
       "\n",
       "                                         Review Text  Rating  \n",
       "0  I’d give zero stars if I could. I always see o...       1  \n",
       "1  Zero stars. Very disappointed with Singapore a...       1  \n",
       "2  Amazing, best service ever. Food is amazing, e...       5  \n",
       "3  We had a 4.5 hour delay on our flight from Lon...       5  \n",
       "4  The leg room was great but the food was terrib...       3  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tripadvisor.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skytrax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Clean Skytrax scraped dataframe\n",
    "def clean_skytrax_df(df):\n",
    "    cleaned_df = df.copy()\n",
    "    \n",
    "    # Clean rating and convert to 1 to 5 scale\n",
    "    cleaned_df['Rating'] = pd.to_numeric(cleaned_df['Rating'], errors='coerce')\n",
    "    cleaned_df['Rating'] = cleaned_df['Rating'].apply(lambda x: round(x / 2))\n",
    "    cleaned_df['Rating'] = cleaned_df['Rating'].astype(int)\n",
    "        \n",
    "    # Clean text fields and remove \"Trip Verified\" prefix\n",
    "    cleaned_df['Review Text'] = cleaned_df['Review Text'].apply(lambda x: str(x).replace('✅Trip Verified| ', '').strip())\n",
    "    cleaned_df['Title'] = cleaned_df['Title'].apply(lambda x: str(x).strip().strip('\"'))\n",
    "    \n",
    "    ##  Convert Year and Month to lowercase\n",
    "    cleaned_df = cleaned_df.rename(columns={'Year': 'year', 'Month': 'month'})\n",
    "\n",
    "    # Remove any empty reviews\n",
    "    cleaned_df = cleaned_df.dropna(subset=['Review Text', 'Rating'])\n",
    "    \n",
    "    # Remove any duplicate reviews\n",
    "    cleaned_df.drop_duplicates(subset=['Review Text']).reset_index(drop=True)\n",
    "    \n",
    "    ## Keep reviews only from years 2021 to 2024\n",
    "    cleaned_df = cleaned_df[(cleaned_df['year'] >= 2021) & (cleaned_df['year'] <= 2024)]\n",
    "    \n",
    "    \n",
    "    return cleaned_df\n",
    "\n",
    "clean_skytrax = clean_skytrax_df(skytrax_scraped_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1446 entries, 0 to 1445\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   year         1446 non-null   int64 \n",
      " 1   month        1446 non-null   int64 \n",
      " 2   Title        1446 non-null   object\n",
      " 3   Review Text  1446 non-null   object\n",
      " 4   Rating       1446 non-null   int64 \n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 56.6+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 335 entries, 0 to 334\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   year         335 non-null    int64 \n",
      " 1   month        335 non-null    int64 \n",
      " 2   Title        335 non-null    object\n",
      " 3   Review Text  335 non-null    object\n",
      " 4   Rating       335 non-null    int64 \n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 15.7+ KB\n"
     ]
    }
   ],
   "source": [
    "clean_tripadvisor.info()\n",
    "clean_skytrax.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1781 entries, 0 to 1780\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   year         1781 non-null   int64 \n",
      " 1   month        1781 non-null   int64 \n",
      " 2   Title        1781 non-null   object\n",
      " 3   Review Text  1781 non-null   object\n",
      " 4   Rating       1781 non-null   int64 \n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 69.7+ KB\n"
     ]
    }
   ],
   "source": [
    "## Combine both dataframes into one\n",
    "combined_df = pd.concat([clean_tripadvisor, clean_skytrax], ignore_index=True)\n",
    "\n",
    "combined_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new column `full_review`\n",
    "Since there are some rows with empty `text` and `title`, we will concatenate both columns (`text` and `title`) to form a new column `full_review`.\n",
    "1. Replace `NaN` values in `text` and `title` with an empty string.\n",
    "\n",
    "2. Combine `text` and `title` into `full_review`.\n",
    "\n",
    "3. Strip any leading/trailing whitespaces in `full_review`.\n",
    "\n",
    "4. Drop `text` and `title` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  month  Rating                                        full_review\n",
      "0  2024      5       1  I’d give zero stars if I could. I always see o...\n",
      "1  2024      9       1  Zero stars. Very disappointed with Singapore a...\n",
      "2  2024     10       5  Amazing, best service ever. Food is amazing, e...\n",
      "3  2024     10       5  We had a 4.5 hour delay on our flight from Lon...\n",
      "4  2024     10       3  The leg room was great but the food was terrib...\n",
      "\n",
      "The old shape is: (1781, 4)\n"
     ]
    }
   ],
   "source": [
    "# 1) Combine 'text' and 'title' into 'full_review'\n",
    "combined_df['full_review'] = combined_df['Review Text'] + \" \" + combined_df['Title']\n",
    "\n",
    "# 2) Strip any leading/trailing whitespace\n",
    "combined_df['full_review'] = combined_df['full_review'].str.strip()\n",
    "\n",
    "# 3) Drop `text` and `title` columns\n",
    "combined_df = combined_df.drop(columns = ['Review Text', 'Title'])\n",
    "\n",
    "# Check if the 'full_review' column was added and if 'text' and 'title' columns has been dropped\n",
    "print(combined_df.head())\n",
    "print(\"\\nThe old shape is:\", combined_df.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Outliers\n",
    "\n",
    "### `full_review`\n",
    "\n",
    "The `full_review` column of `combined_df`, which is of string (`str`) type, may contain values with unusually long lengths, indicating the presence of outliers. We will identify the outliers using [Z-score method].\n",
    "\n",
    "1. Create a new column `text_length` in the DataFrame `combined_df` by calculating the length of each review. (Set the value as 0 if the correponding `text` column has NaN values.)\n",
    "\n",
    "2. Check the statistics of `text_length` using `describe()` method.\n",
    "\n",
    "3. Calculate the mean and standard deviation of the `text_length` column.\n",
    "\n",
    "4. Set the Z-score threshold for identifying outliers to 3.\n",
    "\n",
    "5. Identify outliers of the `text_length` column and set the corresponding `text` to np.nan.\n",
    "\n",
    "6. Drop the `text_length` column from the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1781.000000\n",
      "mean      405.410444\n",
      "std       344.534000\n",
      "min       114.000000\n",
      "25%       295.000000\n",
      "50%       310.000000\n",
      "75%       337.000000\n",
      "max      3285.000000\n",
      "Name: text_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def remove_outliers(df, text_column='', threshold=3):\n",
    "    \"\"\"\n",
    "    Removes outliers based on the length of the text in the given column. \n",
    "    Outliers are defined as texts whose lengths are more than the specified \n",
    "    number of standard deviations away from the mean.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing the text data.\n",
    "    - text_column: Name of the column containing text reviews (default: 'Review Text').\n",
    "    - threshold: Number of standard deviations to define an outlier (default: 3).\n",
    "\n",
    "    Returns:\n",
    "    - df: DataFrame with outliers (texts with extreme lengths) removed.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a new column for text length\n",
    "    df['text_length'] = df[text_column].apply(lambda x: len(x) if pd.notna(x) else 0)\n",
    "    \n",
    "    # Calculate the statistics for text length\n",
    "    TL = df[\"text_length\"]\n",
    "    stats_TL = TL.describe()\n",
    "    print(stats_TL)\n",
    "\n",
    "    # Calculate z-scores for text lengths\n",
    "    z_score = zscore(TL)\n",
    "    \n",
    "    # Remove rows where the z-score exceeds the threshold\n",
    "    df.loc[abs(z_score) > threshold, text_column] = np.nan\n",
    "    \n",
    "    # Drop the temporary 'text_length' column after cleaning\n",
    "    df = df.drop(\"text_length\", axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "combined_df = remove_outliers(combined_df, text_column='full_review', threshold=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1781 entries, 0 to 1780\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   year         1781 non-null   int64 \n",
      " 1   month        1781 non-null   int64 \n",
      " 2   Rating       1781 non-null   int64 \n",
      " 3   full_review  1730 non-null   object\n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 55.8+ KB\n"
     ]
    }
   ],
   "source": [
    "combined_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop rows where full_review is NaN\n",
    "combined_df = combined_df.dropna(subset=['full_review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year            int64\n",
      "month           int64\n",
      "Rating          int64\n",
      "full_review    object\n",
      "dtype: object\n",
      "Remaining duplicate rows: 0\n",
      "Unique ratings: [1 5 3 4 2 0]\n"
     ]
    }
   ],
   "source": [
    "#check data types of each column, make sure they are correct\n",
    "print(combined_df.dtypes)\n",
    "\n",
    "# Make sure no more duplicates are present\n",
    "print(\"Remaining duplicate rows:\", combined_df.duplicated().sum())\n",
    "combined_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Check for outliers in ratings\n",
    "print(\"Unique ratings:\", combined_df['Rating'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year\n",
       "2022    677\n",
       "2023    628\n",
       "2024    416\n",
       "2021      9\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df['year'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove empty strings\n",
    "1. Drop rows where `full_review` are empty strings and reset the index.\n",
    "\n",
    "2. Check if there are no more null values in `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new shape is: (1730, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "year           0\n",
       "month          0\n",
       "Rating         0\n",
       "full_review    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Drop rows where `full_review` are empty strings and reset the index\n",
    "combined_df = combined_df[combined_df['full_review'] != \"\"].reset_index(drop=True)\n",
    "print(\"The new shape is:\",combined_df.shape)\n",
    "\n",
    "# 2) Check if there are no more null values in `data`\n",
    "combined_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new column `language`\n",
    "In the case where there are rows where `full_review` are in different languages (e.g., French, Russian, etc.) other than English. We decided to use 2 different language detector libraries (`langdetect`, `langid`) on the `full_review` column and combined the predictions of all 2 libraries and selecting the most frequent predicted language.\n",
    "\n",
    "**Reason**: `langdetect` might perform well on longer texts while `langid` is more reliable on short texts, using multiple detectors reduces the likelihood of misclassification and mitigates individual detector errors, leading to more accurate overall predictions. Also, even if one detector fails or throws an error, the other can still provide predictions, therefore improving the robustness of the language detection.\n",
    "\n",
    "1. Set a seed for `langdetect` to ensure reproducibility.\n",
    "\n",
    "2. Preprocess the text in `full_review`:\n",
    "    - a\\) Function to remove non-alphabetic characters and normalise whitespaces in  `full_review`.\n",
    "    - b\\) Function to determine if the text is non-language (e.g., numbers, symbols only).\n",
    "\n",
    "3. Two functions for language detection:\n",
    "    - a\\) Using `langdetect`.\n",
    "    - b\\) Using `langid`.\n",
    "\n",
    "4. Function for calculating majority vote for each language.\n",
    "\n",
    "5. Function for parallel processing for efficiency.\n",
    "\n",
    "6. Caching function for repeated inputs\n",
    "\n",
    "7. Function for choosing language based on combined majority voting.\n",
    "\n",
    "8. Applying the combined function on `full_review` column.\n",
    "\n",
    "9. Display the resulting `data` DataFrame.\n",
    "\n",
    "### <span style=\"color:red\">The code below will take approximately 1 minute to run!</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Language Detection:   0%|          | 0/1730 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Language Detection: 100%|██████████| 1730/1730 [00:32<00:00, 53.44it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>Rating</th>\n",
       "      <th>full_review</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>I’d give zero stars if I could. I always see o...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>Zero stars. Very disappointed with Singapore a...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>Amazing, best service ever. Food is amazing, e...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>We had a 4.5 hour delay on our flight from Lon...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>The leg room was great but the food was terrib...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>Due to the pandemic, it has been two years sin...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>SQ25, JFK-FRA, in Business. Check in Counter, ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>FRA to JFK, still a good and safe airline but ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1728</th>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>I paid $7200 for a first / business class tick...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1729</th>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Verified|  I've never had a more frustrati...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1730 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      year  month  Rating                                        full_review  \\\n",
       "0     2024      5       1  I’d give zero stars if I could. I always see o...   \n",
       "1     2024      9       1  Zero stars. Very disappointed with Singapore a...   \n",
       "2     2024     10       5  Amazing, best service ever. Food is amazing, e...   \n",
       "3     2024     10       5  We had a 4.5 hour delay on our flight from Lon...   \n",
       "4     2024     10       3  The leg room was great but the food was terrib...   \n",
       "...    ...    ...     ...                                                ...   \n",
       "1725  2021     12       5  Due to the pandemic, it has been two years sin...   \n",
       "1726  2021     12       5  SQ25, JFK-FRA, in Business. Check in Counter, ...   \n",
       "1727  2021     11       4  FRA to JFK, still a good and safe airline but ...   \n",
       "1728  2021     11       0  I paid $7200 for a first / business class tick...   \n",
       "1729  2021      5       0  Not Verified|  I've never had a more frustrati...   \n",
       "\n",
       "     language  \n",
       "0          en  \n",
       "1          en  \n",
       "2          en  \n",
       "3          en  \n",
       "4          en  \n",
       "...       ...  \n",
       "1725       en  \n",
       "1726       en  \n",
       "1727       en  \n",
       "1728       en  \n",
       "1729       en  \n",
       "\n",
       "[1730 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Set a seed for langdetect to ensure reproducibility\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "# 2a) Simplified preprocessing: only remove non-alphabetic characters\n",
    "def preprocess_text_simple(text):\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove non-alphabetic characters\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Normalize whitespace\n",
    "    return text.strip()\n",
    "\n",
    "# 2b) Check if the text is non-language (e.g., numbers, symbols only)\n",
    "def is_non_language_text(text):\n",
    "    if re.match(r'^[^a-zA-Z]*$', text):  # Check if text has no alphabetic characters\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# 3a) Function to get langdetect prediction\n",
    "def get_langdetect_prediction(text):\n",
    "    try:\n",
    "        # Directly use text without preprocessing for efficiency\n",
    "        if len(text) < 10 or is_non_language_text(text):\n",
    "            return \"unknown\"\n",
    "        lang = langdetect_detect(text)\n",
    "        return lang\n",
    "    except LangDetectException:\n",
    "        return \"unknown\"\n",
    "\n",
    "# 3b) Function to get langid prediction\n",
    "def get_langid_prediction(text):\n",
    "    try:\n",
    "        lang, _ = langid_classify(text)\n",
    "        if len(text) < 10 or is_non_language_text(text):\n",
    "            return \"unknown\"\n",
    "        return lang\n",
    "    except Exception:\n",
    "        return \"unknown\"\n",
    "\n",
    "# 4) Function to calculate majority vote for each language\n",
    "def calculate_majority_vote(predictions):\n",
    "    vote_counts = {}\n",
    "    for lang in predictions:\n",
    "        if lang in vote_counts:\n",
    "            vote_counts[lang] += 1\n",
    "        else:\n",
    "            vote_counts[lang] = 1\n",
    "    return vote_counts\n",
    "\n",
    "# 5) Parallel processing for efficiency with limited workers\n",
    "def parallel_detection(text):\n",
    "    with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        results = list(executor.map(lambda func: func(text), \n",
    "                                    [get_langdetect_prediction, get_langid_prediction]))\n",
    "    return results\n",
    "\n",
    "# 6) Caching function for repeated inputs\n",
    "@lru_cache(maxsize=500)\n",
    "def get_cached_language(text):\n",
    "    return combined_language_detection(text)\n",
    "\n",
    "# 7) Combined majority voting language detection function\n",
    "def combined_language_detection(text):\n",
    "    # Check if the text is non-language (e.g., numbers, symbols only)\n",
    "    if is_non_language_text(text):\n",
    "        return \"unknown\"\n",
    "    \n",
    "    # Run the detectors in parallel for efficiency\n",
    "    predictions = parallel_detection(text)\n",
    "    \n",
    "    # Calculate majority vote for each language based on predictions\n",
    "    vote_counts = calculate_majority_vote(predictions)\n",
    "    \n",
    "    # Determine the language with the highest majority vote\n",
    "    final_language = max(vote_counts, key=vote_counts.get)\n",
    "    \n",
    "    # If \"unknown\" is the most common or if all detectors fail, return \"unknown\"\n",
    "    if final_language == \"unknown\" or vote_counts[final_language] <= 1:\n",
    "        return \"unknown\"\n",
    "    \n",
    "    return final_language\n",
    "\n",
    "# 8) Apply the cached function to each text in the DataFrame with a progress bar\n",
    "combined_df['language'] = [get_cached_language(text) for text in tqdm(combined_df['full_review'], desc=\"Language Detection\")]\n",
    "\n",
    "# 9) Display the DataFrame with detected languages\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "language\n",
       "en    1729\n",
       "nl       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See distribution of languages\n",
    "combined_df[\"language\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1729, 5)\n"
     ]
    }
   ],
   "source": [
    "# Drop rows where language is NOT in english and reset the index\n",
    "combined_df = combined_df[combined_df['language'] == 'en'].reset_index(drop=True)\n",
    "print(combined_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will drop the `language` column since all values of `language` are `en` and all `full_review` are in the English language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1729 entries, 0 to 1728\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   year         1729 non-null   int64 \n",
      " 1   month        1729 non-null   int64 \n",
      " 2   Rating       1729 non-null   int64 \n",
      " 3   full_review  1729 non-null   object\n",
      " 4   language     1729 non-null   object\n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 67.7+ KB\n",
      "The new shape is: (1729, 4)\n"
     ]
    }
   ],
   "source": [
    "combined_df.info()\n",
    "combined_df.drop(columns=[\"language\"], inplace=True)\n",
    "print(\"The new shape is:\", combined_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>Rating</th>\n",
       "      <th>full_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>I’d give zero stars if I could. I always see o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>Zero stars. Very disappointed with Singapore a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>Amazing, best service ever. Food is amazing, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>We had a 4.5 hour delay on our flight from Lon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>The leg room was great but the food was terrib...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  Rating                                        full_review\n",
       "0  2024      5       1  I’d give zero stars if I could. I always see o...\n",
       "1  2024      9       1  Zero stars. Very disappointed with Singapore a...\n",
       "2  2024     10       5  Amazing, best service ever. Food is amazing, e...\n",
       "3  2024     10       5  We had a 4.5 hour delay on our flight from Lon...\n",
       "4  2024     10       3  The leg room was great but the food was terrib..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing for NLP\n",
    "\n",
    "Here we will define a function `process_full_review` that takes a textual value as input and applies the following processing steps in sequence:\n",
    "\n",
    "1. Convert the input text to lowercase using the `lower()` function.\n",
    "\n",
    "2. Tokenize the lowercase text using the `word_tokenize` function from the NLTK library.\n",
    "\n",
    "3. Create a list (`alphabetic_tokens`) containing only alphanetic tokens using a list comprehension with a regular expression match.\n",
    "\n",
    "4. Remove stopwords\n",
    "-   Obtain a set of English stopwords using the `stopwords.words('english')` method.\n",
    "-   Define a list of `allowed_words` that should not be removed.\n",
    "-   Remove the stopwords (excluding those that should not be removed).\n",
    "\n",
    "5. Apply lemmatization to each token in the list (`lemmatized_words`) using the `lemmatize` method.\n",
    "\n",
    "6. Join the lemmatized tokens into a single processed text using the `join` method and return the processed text.\n",
    "\n",
    "Create a new column `processed_full_review` in `data` by applying the `process_full_review` function to the `full_review` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/ritikabajpai/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ritikabajpai/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ritikabajpai/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/ritikabajpai/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure require NLTK data is downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "# Define function to process text\n",
    "def process_full_review(text):\n",
    "    processed_text = \"\"\n",
    "\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Tokenize the text into words\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Keep only alphabetic tokens\n",
    "    alphabetic_tokens = [i for i in tokens if re.match('^[a-zA-Z]+$', i)]\n",
    "\n",
    "    if len(alphabetic_tokens) == 0:\n",
    "        # Return empty processed text if there are no alphabetic tokens\n",
    "        return processed_text\n",
    "\n",
    "    # List of stopwords\n",
    "    stop_words = stopwords.words('english')\n",
    "\n",
    "    # List of allowed words (to preserve certain negative words and conjuctions)\n",
    "    allowed_words = [\"no\", \"not\", \"don't\", \"dont\", \"don\", \"but\", \n",
    "                     \"however\", \"never\", \"wasn't\", \"wasnt\", \"shouldn't\",\n",
    "                     \"shouldnt\", \"mustn't\", \"musnt\"]\n",
    "    '''\n",
    "    these words may carry important information, such as negative connotations. in examples such as\n",
    "    \"don't ever get this dish\" -> if don't was removed, it may be interpreted as \"get dish\", which is of the opposite sentiment\n",
    "    of what the original review is supposed to be.\n",
    "    Conjunctions like \"but\" and \"however\" shows a contrast to the sentence said before, meaning that the sentiment can be\n",
    "    negatively affected or at the very least, impacted. Similarly for \"mustn't\" or \"shouldn't\", they typically carry a negative sentiment.\n",
    "    '''\n",
    "\n",
    "    # Filter out stopwords, keeping allowed words\n",
    "    filtered_tokens = [i for i in alphabetic_tokens if i not in stop_words or i in allowed_words]\n",
    "\n",
    "    # Initialise the WordNet Lemmatizer\n",
    "    stemmer = PorterStemmer()\n",
    "\n",
    "    # Stem the filtered tokens\n",
    "    stemmed_words = [stemmer.stem(word) for word in filtered_tokens]\n",
    "\n",
    "    # Join the stemmed words back into a single string\n",
    "    processed_text = ' '.join(stemmed_words)\n",
    "\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Reviews: 100%|██████████| 1729/1729 [00:04<00:00, 402.79it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>Rating</th>\n",
       "      <th>full_review</th>\n",
       "      <th>processed_full_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>I’d give zero stars if I could. I always see o...</td>\n",
       "      <td>give zero star could alway see onlin singapor ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>Zero stars. Very disappointed with Singapore a...</td>\n",
       "      <td>zero star disappoint singapor air not much due...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>Amazing, best service ever. Food is amazing, e...</td>\n",
       "      <td>amaz best servic ever food amaz especi starter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>We had a 4.5 hour delay on our flight from Lon...</td>\n",
       "      <td>hour delay flight london singapor thought woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>The leg room was great but the food was terrib...</td>\n",
       "      <td>leg room great but food terribl travel singapo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>Due to the pandemic, it has been two years sin...</td>\n",
       "      <td>due pandem two year sinc board flight opportun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>SQ25, JFK-FRA, in Business. Check in Counter, ...</td>\n",
       "      <td>busi check counter not know put final destin l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>FRA to JFK, still a good and safe airline but ...</td>\n",
       "      <td>fra jfk still good safe airlin but massiv cut ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>I paid $7200 for a first / business class tick...</td>\n",
       "      <td>paid first busi class ticket websit buggi hand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1728</th>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Verified|  I've never had a more frustrati...</td>\n",
       "      <td>not never frustrat experi tri book flight webs...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1729 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      year  month  Rating                                        full_review  \\\n",
       "0     2024      5       1  I’d give zero stars if I could. I always see o...   \n",
       "1     2024      9       1  Zero stars. Very disappointed with Singapore a...   \n",
       "2     2024     10       5  Amazing, best service ever. Food is amazing, e...   \n",
       "3     2024     10       5  We had a 4.5 hour delay on our flight from Lon...   \n",
       "4     2024     10       3  The leg room was great but the food was terrib...   \n",
       "...    ...    ...     ...                                                ...   \n",
       "1724  2021     12       5  Due to the pandemic, it has been two years sin...   \n",
       "1725  2021     12       5  SQ25, JFK-FRA, in Business. Check in Counter, ...   \n",
       "1726  2021     11       4  FRA to JFK, still a good and safe airline but ...   \n",
       "1727  2021     11       0  I paid $7200 for a first / business class tick...   \n",
       "1728  2021      5       0  Not Verified|  I've never had a more frustrati...   \n",
       "\n",
       "                                  processed_full_review  \n",
       "0     give zero star could alway see onlin singapor ...  \n",
       "1     zero star disappoint singapor air not much due...  \n",
       "2     amaz best servic ever food amaz especi starter...  \n",
       "3     hour delay flight london singapor thought woul...  \n",
       "4     leg room great but food terribl travel singapo...  \n",
       "...                                                 ...  \n",
       "1724  due pandem two year sinc board flight opportun...  \n",
       "1725  busi check counter not know put final destin l...  \n",
       "1726  fra jfk still good safe airlin but massiv cut ...  \n",
       "1727  paid first busi class ticket websit buggi hand...  \n",
       "1728  not never frustrat experi tri book flight webs...  \n",
       "\n",
       "[1729 rows x 5 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enable tqdm for pandas (progress bar)\n",
    "tqdm.pandas(desc=\"Processing Reviews\")\n",
    "\n",
    "# Apply process_full_review function with tqdm progress bar and expand the results into a\n",
    "combined_df['processed_full_review'] = combined_df['full_review'].progress_apply(process_full_review)\n",
    "\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping ratings to sentiment labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "Negative    964\n",
      "Positive    581\n",
      "Neutral     184\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Function to map ratings to sentiment\n",
    "def rating_to_sentiment(rating):\n",
    "    if rating <= 2:\n",
    "        return 'Negative'\n",
    "    elif rating == 3:\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Positive'\n",
    "\n",
    "# Apply the function to the 'rating' column\n",
    "combined_df['sentiment'] = combined_df['Rating'].apply(rating_to_sentiment)\n",
    "\n",
    "# Check the sentiment distribution\n",
    "print(combined_df['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "Now, we select the final features to use for our sentiment analysis of airline reviews. \n",
    "- `processed_full_review`,`processed_review_length`, `sentiment`,`year`,`month`\n",
    "\n",
    "- Columns excluded: [`published_platform`,`type`,`helpful_votes`,`language`,`review_length`,`day`,`day_of_week`,`year_month`]\n",
    "\n",
    "- Create a new DataFrame (`data_final`) by selecting the specifc columns mentioned above from the original DataFrame `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_data_final = combined_df[['year','month','processed_full_review','sentiment']]\n",
    "scraped_data_final.head()\n",
    "scraped_data_final.to_csv('scraped_data_final.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashing Vectorization\n",
    "We applied several text preprocessing techniques to prepare the dataset:\n",
    "- TF-IDF with N-grams: Captures word combinations (bigrams/trigrams) to represent more complex patterns in text.\n",
    "\n",
    "- Hashing Vectorizer: A memory-efficient method to represent text as a fixed-size sparse vector.\n",
    "\n",
    "- Latent Semantic Analysis (LSA): Used singular value decomposition (SVD) to reduce the dimensionality of the TF-IDF matrix while capturing important features\n",
    "\n",
    "- We combined these text features (from TF-IDF, Hashing, and LSA) with other numeric features like year and month to create the final feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abl chang</th>\n",
       "      <th>absolut amaz</th>\n",
       "      <th>absolut best</th>\n",
       "      <th>absolut disgust</th>\n",
       "      <th>absolut dread</th>\n",
       "      <th>absolut nightmar</th>\n",
       "      <th>absolut terribl</th>\n",
       "      <th>absolut useless</th>\n",
       "      <th>absolut worst</th>\n",
       "      <th>act like</th>\n",
       "      <th>...</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019929</td>\n",
       "      <td>-0.047736</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.036550</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>-0.109166</td>\n",
       "      <td>-0.012493</td>\n",
       "      <td>0.018406</td>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014637</td>\n",
       "      <td>-0.022750</td>\n",
       "      <td>0.005521</td>\n",
       "      <td>0.009753</td>\n",
       "      <td>0.031811</td>\n",
       "      <td>-0.002279</td>\n",
       "      <td>0.003172</td>\n",
       "      <td>-0.023173</td>\n",
       "      <td>2024</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027549</td>\n",
       "      <td>0.014843</td>\n",
       "      <td>0.038262</td>\n",
       "      <td>0.036190</td>\n",
       "      <td>-0.057100</td>\n",
       "      <td>0.010452</td>\n",
       "      <td>-0.033660</td>\n",
       "      <td>0.005421</td>\n",
       "      <td>2024</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001603</td>\n",
       "      <td>-0.008525</td>\n",
       "      <td>0.058282</td>\n",
       "      <td>0.000761</td>\n",
       "      <td>0.003910</td>\n",
       "      <td>0.061209</td>\n",
       "      <td>-0.014216</td>\n",
       "      <td>-0.011463</td>\n",
       "      <td>2024</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063225</td>\n",
       "      <td>0.080954</td>\n",
       "      <td>0.049114</td>\n",
       "      <td>0.058847</td>\n",
       "      <td>-0.037877</td>\n",
       "      <td>-0.048982</td>\n",
       "      <td>0.018832</td>\n",
       "      <td>-0.034113</td>\n",
       "      <td>2024</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abl chang  absolut amaz  absolut best  absolut disgust  absolut dread  \\\n",
       "0        0.0           0.0           0.0              0.0            0.0   \n",
       "1        0.0           0.0           0.0              0.0            0.0   \n",
       "2        0.0           0.0           0.0              0.0            0.0   \n",
       "3        0.0           0.0           0.0              0.0            0.0   \n",
       "4        0.0           0.0           0.0              0.0            0.0   \n",
       "\n",
       "   absolut nightmar  absolut terribl  absolut useless  absolut worst  \\\n",
       "0               0.0              0.0              0.0            0.0   \n",
       "1               0.0              0.0              0.0            0.0   \n",
       "2               0.0              0.0              0.0            0.0   \n",
       "3               0.0              0.0              0.0            0.0   \n",
       "4               0.0              0.0              0.0            0.0   \n",
       "\n",
       "   act like  ...        92        93        94        95        96        97  \\\n",
       "0       0.0  ...  0.019929 -0.047736  0.000062  0.036550  0.000106 -0.109166   \n",
       "1       0.0  ... -0.014637 -0.022750  0.005521  0.009753  0.031811 -0.002279   \n",
       "2       0.0  ...  0.027549  0.014843  0.038262  0.036190 -0.057100  0.010452   \n",
       "3       0.0  ...  0.001603 -0.008525  0.058282  0.000761  0.003910  0.061209   \n",
       "4       0.0  ...  0.063225  0.080954  0.049114  0.058847 -0.037877 -0.048982   \n",
       "\n",
       "         98        99  year  month  \n",
       "0 -0.012493  0.018406  2024      5  \n",
       "1  0.003172 -0.023173  2024      9  \n",
       "2 -0.033660  0.005421  2024     10  \n",
       "3 -0.014216 -0.011463  2024     10  \n",
       "4  0.018832 -0.034113  2024     10  \n",
       "\n",
       "[5 rows x 5102 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Assuming your data is in a dataframe called 'df'\n",
    "# The text column is 'processed_full_review', and the target column is 'sentiment'\n",
    "\n",
    "# Step 1: TF-IDF with Bigrams/Trigrams\n",
    "tfidf_ngram_vectorizer = TfidfVectorizer(ngram_range=(2, 3), max_features=5000)\n",
    "X_tfidf_ngram = tfidf_ngram_vectorizer.fit_transform(scraped_data_final['processed_full_review'])\n",
    "\n",
    "# Convert TF-IDF matrix to DataFrame for readability\n",
    "tfidf_ngram_df = pd.DataFrame(X_tfidf_ngram.toarray(), columns=tfidf_ngram_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Step 2: Hashing Vectorizer\n",
    "hash_vectorizer = HashingVectorizer(n_features=5000, alternate_sign=False)\n",
    "X_hash = hash_vectorizer.fit_transform(scraped_data_final['processed_full_review'])\n",
    "\n",
    "# Step 3: LSA (Latent Semantic Analysis) via SVD\n",
    "# Applying SVD on the TF-IDF matrix for dimensionality reduction\n",
    "svd = TruncatedSVD(n_components=100)\n",
    "X_lsa = svd.fit_transform(X_tfidf_ngram)\n",
    "\n",
    "# Combine features if needed\n",
    "X_combined = pd.concat([tfidf_ngram_df, pd.DataFrame(X_lsa)], axis=1)\n",
    "\n",
    "# Step 4: Select Other Columns (Year, Month, etc.)\n",
    "df_selected = scraped_data_final[['year', 'month']]  # Modify based on the features you want to select\n",
    "X_combined = pd.concat([X_combined, df_selected], axis=1)\n",
    "\n",
    "# Output the final dataframe for inspection\n",
    "X_combined.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 65.90%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.62      0.97      0.75       178\n",
      "     Neutral       0.00      0.00      0.00        38\n",
      "    Positive       0.82      0.43      0.57       130\n",
      "\n",
      "    accuracy                           0.66       346\n",
      "   macro avg       0.48      0.47      0.44       346\n",
      "weighted avg       0.63      0.66      0.60       346\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritikabajpai/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/ritikabajpai/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/ritikabajpai/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Assuming 'X_combined' is the feature matrix and 'scraped_data_final['sentiment']' is the target\n",
    "X_combined.columns = X_combined.columns.map(str)\n",
    "y = scraped_data_final['sentiment']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF with cross-validation\n",
    "\n",
    "Cross-validation is a technique used to evaluate the performance of a model by splitting the data into multiple subsets, training the model on some subsets, and validating it on others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy scores: [0.66425993 0.68231047 0.71480144 0.6884058  0.69565217]\n",
      "Mean cross-validation accuracy: 0.69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.62      0.97      0.75       178\n",
      "     Neutral       0.00      0.00      0.00        38\n",
      "    Positive       0.82      0.43      0.57       130\n",
      "\n",
      "    accuracy                           0.66       346\n",
      "   macro avg       0.48      0.47      0.44       346\n",
      "weighted avg       0.63      0.66      0.60       346\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritikabajpai/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/ritikabajpai/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/ritikabajpai/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Ensure X_combined columns are strings\n",
    "X_combined.columns = X_combined.columns.map(str)\n",
    "y = scraped_data_final['sentiment']\n",
    "\n",
    "# Split data into separate train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 1: Cross-Validation on the training set only\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Cross-validation on the training set\n",
    "cv_scores = cross_val_score(rf_classifier, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Print Cross-validation results\n",
    "print(f\"Cross-validation accuracy scores: {cv_scores}\")\n",
    "print(f\"Mean cross-validation accuracy: {cv_scores.mean():.2f}\")\n",
    "\n",
    "# Step 2: Train on the full training set after cross-validation\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Evaluate on the separate test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Step 4: Classification report on test set\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF with Grid Search for Hyperparameter Tuning\n",
    "\n",
    "Instead of using default hyperparameters, we perform a Grid Search to find the best combination of hyperparameters (such as n_estimators, max_depth, and min_samples_split). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 30, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "Best cross-validation accuracy: 0.68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.62      0.99      0.76       178\n",
      "     Neutral       0.00      0.00      0.00        38\n",
      "    Positive       0.92      0.43      0.59       130\n",
      "\n",
      "    accuracy                           0.67       346\n",
      "   macro avg       0.51      0.48      0.45       346\n",
      "weighted avg       0.66      0.67      0.61       346\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritikabajpai/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/ritikabajpai/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/ritikabajpai/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Ensure X_combined columns are strings\n",
    "X_combined.columns = X_combined.columns.map(str)\n",
    "y = scraped_data_final['sentiment']\n",
    "\n",
    "# Split data into separate train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the parameter grid for Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Set up Grid Search\n",
    "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the model with Grid Search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best cross-validation accuracy: {best_score:.2f}\")\n",
    "\n",
    "# Use the best model for predictions\n",
    "best_rf_classifier = grid_search.best_estimator_\n",
    "y_pred = best_rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF with Out-of-Bag (OOB) Evaluation\n",
    "\n",
    "Random Forest has an internal method for evaluating performance called Out-of-Bag (OOB) score. It evaluates the model on samples not used during the training of individual trees, providing an internal cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB Score: 0.68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.62      0.97      0.75       178\n",
      "     Neutral       0.00      0.00      0.00        38\n",
      "    Positive       0.82      0.43      0.57       130\n",
      "\n",
      "    accuracy                           0.66       346\n",
      "   macro avg       0.48      0.47      0.44       346\n",
      "weighted avg       0.63      0.66      0.60       346\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritikabajpai/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/ritikabajpai/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/ritikabajpai/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Initialize Random Forest with OOB enabled\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, oob_score=True, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Print the OOB score\n",
    "print(f\"OOB Score: {rf_classifier.oob_score_:.2f}\")\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Stacking\n",
    "\n",
    "Stacking is a technique where you combine the predictions of multiple models, not just Random Forests, but any set of models, to make a final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.73      0.90      0.81       178\n",
      "     Neutral       0.00      0.00      0.00        38\n",
      "    Positive       0.76      0.72      0.74       130\n",
      "\n",
      "    accuracy                           0.73       346\n",
      "   macro avg       0.49      0.54      0.51       346\n",
      "weighted avg       0.66      0.73      0.69       346\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define the base models\n",
    "base_estimators = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('svm', SVC(kernel='linear', probability=True, random_state=42))\n",
    "]\n",
    "\n",
    "# Define the final estimator (meta-learner)\n",
    "stacking_clf = StackingClassifier(estimators=base_estimators, final_estimator=LogisticRegression())\n",
    "\n",
    "# Train the stacking classifier\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = stacking_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7196531791907514\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.69      0.94      0.79       178\n",
      "     Neutral       0.00      0.00      0.00        38\n",
      "    Positive       0.80      0.62      0.70       130\n",
      "\n",
      "    accuracy                           0.72       346\n",
      "   macro avg       0.50      0.52      0.50       346\n",
      "weighted avg       0.65      0.72      0.67       346\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritikabajpai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ritikabajpai/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/ritikabajpai/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/ritikabajpai/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=42).fit(X_train, y_train)\n",
    "clf_predictions = clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, clf_predictions))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, clf_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
