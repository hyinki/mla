{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhancing Singapore Airlines' Service Through Automated Sentiment Analysis of Customer Reviews\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Motivation**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Singapore Airlines Customer Reviews Dataset Information\n",
    "\n",
    "The [Singapore Airlines Customer Reviews Dataset](https://www.kaggle.com/datasets/kanchana1990/singapore-airlines-reviews) aggregates 10,000 anonymized customer reviews, providing a broad perspective on the passenger experience with Singapore Airlines. \n",
    "\n",
    "The dimensions are shown below:\n",
    "- **`published_date`**: Date and time of review publication.\n",
    "- **`published_platform`**: Platform where the review was posted.\n",
    "- **`rating`**: Customer satisfaction rating, from 1 (lowest) to 5 (highest).\n",
    "- **`type`**: Specifies the content as a review.\n",
    "- **`text`**: Detailed customer feedback.\n",
    "- **`title`**: Summary of the review.\n",
    "- **`helpful_votes`**: Number of users finding the review helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries\n",
    "\n",
    "Please uncomment the code box below to pip install relevant dependencies for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Statistical functions\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# For concurrency (running functions in parallel)\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# For caching (to speed up repeated function calls)\n",
    "from functools import lru_cache\n",
    "\n",
    "# For progress tracking\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Plotting and Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Language Detection packages\n",
    "# `langdetect` for detecting language\n",
    "from langdetect import detect as langdetect_detect, DetectorFactory\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "# `langid` for an alternative language detection method\n",
    "from langid import classify as langid_classify\n",
    "\n",
    "# Text Preprocessing and NLP\n",
    "# Stopwords (common words to ignore) from NLTK\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Tokenizing sentences/words\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Tokenizing sentences/words\n",
    "from nltk.tokenize import word_tokenize\n",
    "# Lemmatization (converting words to their base form)\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "# Regular expressions for text pattern matching\n",
    "import re\n",
    "\n",
    "# Word Cloud generation\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# For generating n-grams\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation (Loading CSV)\n",
    "\n",
    "Load the `singapore_airline_reviews.csv` file into a pandas DataFrame `data`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial NB with Count Vectorizer\n",
    "\n",
    "Count vectoriser converts a collection of text documents into a matrix of token counts. It simply counts the number of occurrences of each word in the document without considering the importance of frequency of words across the entire corpus.\n",
    "\n",
    "Count vectoriser counts the raw frequency where each word is weighted equally while tf-idf is weighted by term frequency and rarity across documents.\n",
    "\n",
    "Count vectoriser is simple and fast as it's just raw counts, while tf-idf requires more computation as it is slightly more complex due to the use of inverse document frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"final_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>processed_full_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>ok use airlin go singapor london heathrow issu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>Negative</td>\n",
       "      <td>don give money book paid receiv email confirm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>Positive</td>\n",
       "      <td>best airlin world best airlin world seat food ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>Negative</td>\n",
       "      <td>premium economi seat singapor airlin not worth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>Negative</td>\n",
       "      <td>imposs get promis refund book flight full mont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11513</th>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>Negative</td>\n",
       "      <td>websit buggi paid first busi class ticket webs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11514</th>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>Negative</td>\n",
       "      <td>reduc level qualiti servic fear futur airlin t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11515</th>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>Negative</td>\n",
       "      <td>chang would cost usd book ticket singapor airl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11516</th>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>Negative</td>\n",
       "      <td>disappoint flight check secur check frankfurt ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11517</th>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "      <td>Negative</td>\n",
       "      <td>frustrat experi tri book flight not never frus...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11518 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       year  month sentiment  \\\n",
       "0      2024      3   Neutral   \n",
       "1      2024      3  Negative   \n",
       "2      2024      3  Positive   \n",
       "3      2024      3  Negative   \n",
       "4      2024      3  Negative   \n",
       "...     ...    ...       ...   \n",
       "11513  2021     11  Negative   \n",
       "11514  2021     10  Negative   \n",
       "11515  2021     10  Negative   \n",
       "11516  2021      8  Negative   \n",
       "11517  2021      5  Negative   \n",
       "\n",
       "                                   processed_full_review  \n",
       "0      ok use airlin go singapor london heathrow issu...  \n",
       "1      don give money book paid receiv email confirm ...  \n",
       "2      best airlin world best airlin world seat food ...  \n",
       "3      premium economi seat singapor airlin not worth...  \n",
       "4      imposs get promis refund book flight full mont...  \n",
       "...                                                  ...  \n",
       "11513  websit buggi paid first busi class ticket webs...  \n",
       "11514  reduc level qualiti servic fear futur airlin t...  \n",
       "11515  chang would cost usd book ticket singapor airl...  \n",
       "11516  disappoint flight check secur check frankfurt ...  \n",
       "11517  frustrat experi tri book flight not never frus...  \n",
       "\n",
       "[11518 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8240740740740741\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.78      0.69      0.73       692\n",
      "     Neutral       0.38      0.64      0.48       346\n",
      "    Positive       0.95      0.89      0.92      2418\n",
      "\n",
      "    accuracy                           0.82      3456\n",
      "   macro avg       0.70      0.74      0.71      3456\n",
      "weighted avg       0.86      0.82      0.84      3456\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=1000)\n",
    "X = vectorizer.fit_transform(data['processed_full_review'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, data['sentiment'],test_size=0.3, random_state=42)\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train,y_train)\n",
    "\n",
    "nb_predictions = nb_model.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test,nb_predictions))\n",
    "print(classification_report(y_test, nb_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF with Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.8518518518518519\n",
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.81      0.78      0.79       692\n",
      "     Neutral       0.88      0.08      0.15       346\n",
      "    Positive       0.86      0.98      0.92      2418\n",
      "\n",
      "    accuracy                           0.85      3456\n",
      "   macro avg       0.85      0.61      0.62      3456\n",
      "weighted avg       0.85      0.85      0.82      3456\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, rf_predictions))\n",
    "print(\"Random Forest Classification Report:\\n\", classification_report(y_test, rf_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log Regression with Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8449074074074074\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.76      0.76      0.76       692\n",
      "     Neutral       0.43      0.36      0.39       346\n",
      "    Positive       0.92      0.94      0.93      2418\n",
      "\n",
      "    accuracy                           0.84      3456\n",
      "   macro avg       0.70      0.69      0.69      3456\n",
      "weighted avg       0.84      0.84      0.84      3456\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=42, max_iter=100).fit(X_train, y_train)\n",
    "clf_predictions = clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, clf_predictions))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, clf_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using count vectoriser, log regression does not converge since count vectoriser produces raw counts for each word, which can result in large values in the feature matrix, especially if a word appears very frequently in a document while TF-IDF normalises these counts by down-weighting common words and dividing by the document length, leading to smaller values in the feature matrix.\n",
    "\n",
    "Log regression is sensitive to the scale of features. Since Count Vectoriser can produce features of widely varying scales (some words may appear 1000 times, others only once), this can affect convergence. TF-IDF normalises the data, results in features that are more evenly scaled, leading to easier optimisation and quicker convergence.\n",
    "\n",
    "Fixed by increasing max_iter from 100 to 200 OR scaling data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.84375\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.76      0.76      0.76       692\n",
      "     Neutral       0.43      0.36      0.39       346\n",
      "    Positive       0.92      0.94      0.93      2418\n",
      "\n",
      "    accuracy                           0.84      3456\n",
      "   macro avg       0.70      0.68      0.69      3456\n",
      "weighted avg       0.84      0.84      0.84      3456\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=42, max_iter=200).fit(X_train, y_train)\n",
    "clf_predictions = clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, clf_predictions))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, clf_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8035300925925926\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.70      0.70      0.70       692\n",
      "     Neutral       0.34      0.39      0.36       346\n",
      "    Positive       0.91      0.89      0.90      2418\n",
      "\n",
      "    accuracy                           0.80      3456\n",
      "   macro avg       0.65      0.66      0.65      3456\n",
      "weighted avg       0.81      0.80      0.81      3456\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler(with_mean=False)  # with_mean=False because sparse matrices don't support centering\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression(random_state=42).fit(X_train_scaled, y_train)\n",
    "clf_predictions = clf.predict(X_test_scaled)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, clf_predictions))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, clf_predictions))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
