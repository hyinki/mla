{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhancing Singapore Airlines' Service Through Automated Sentiment Analysis of Customer Reviews\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Motivation**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Singapore Airlines Customer Reviews Dataset Information\n",
    "\n",
    "The [Singapore Airlines Customer Reviews Dataset](https://www.kaggle.com/datasets/kanchana1990/singapore-airlines-reviews) aggregates 10,000 anonymized customer reviews, providing a broad perspective on the passenger experience with Singapore Airlines. \n",
    "\n",
    "The dimensions are shown below:\n",
    "- **`published_date`**: Date and time of review publication.\n",
    "- **`published_platform`**: Platform where the review was posted.\n",
    "- **`rating`**: Customer satisfaction rating, from 1 (lowest) to 5 (highest).\n",
    "- **`type`**: Specifies the content as a review.\n",
    "- **`text`**: Detailed customer feedback.\n",
    "- **`title`**: Summary of the review.\n",
    "- **`helpful_votes`**: Number of users finding the review helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries\n",
    "\n",
    "Please uncomment the code box below to pip install relevant dependencies for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Statistical functions\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# For concurrency (running functions in parallel)\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# For caching (to speed up repeated function calls)\n",
    "from functools import lru_cache\n",
    "\n",
    "# For progress tracking\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Plotting and Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Language Detection packages\n",
    "# `langdetect` for detecting language\n",
    "from langdetect import detect as langdetect_detect, DetectorFactory\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "# `langid` for an alternative language detection method\n",
    "from langid import classify as langid_classify\n",
    "\n",
    "# Text Preprocessing and NLP\n",
    "# Stopwords (common words to ignore) from NLTK\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Tokenizing sentences/words\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Tokenizing sentences/words\n",
    "from nltk.tokenize import word_tokenize\n",
    "# Lemmatization (converting words to their base form)\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "# Regular expressions for text pattern matching\n",
    "import re\n",
    "\n",
    "# Word Cloud generation\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# For generating n-grams\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>processed_full_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>ok use airlin go singapor london heathrow issu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>Negative</td>\n",
       "      <td>don give money book paid receiv email confirm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>Positive</td>\n",
       "      <td>best airlin world best airlin world seat food ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>Negative</td>\n",
       "      <td>premium economi seat singapor airlin not worth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>Negative</td>\n",
       "      <td>imposs get promis refund book flight full mont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11513</th>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>Negative</td>\n",
       "      <td>websit buggi paid first busi class ticket webs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11514</th>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>Negative</td>\n",
       "      <td>reduc level qualiti servic fear futur airlin t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11515</th>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>Negative</td>\n",
       "      <td>chang would cost usd book ticket singapor airl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11516</th>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>Negative</td>\n",
       "      <td>disappoint flight check secur check frankfurt ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11517</th>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "      <td>Negative</td>\n",
       "      <td>frustrat experi tri book flight not never frus...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11518 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       year  month sentiment  \\\n",
       "0      2024      3   Neutral   \n",
       "1      2024      3  Negative   \n",
       "2      2024      3  Positive   \n",
       "3      2024      3  Negative   \n",
       "4      2024      3  Negative   \n",
       "...     ...    ...       ...   \n",
       "11513  2021     11  Negative   \n",
       "11514  2021     10  Negative   \n",
       "11515  2021     10  Negative   \n",
       "11516  2021      8  Negative   \n",
       "11517  2021      5  Negative   \n",
       "\n",
       "                                   processed_full_review  \n",
       "0      ok use airlin go singapor london heathrow issu...  \n",
       "1      don give money book paid receiv email confirm ...  \n",
       "2      best airlin world best airlin world seat food ...  \n",
       "3      premium economi seat singapor airlin not worth...  \n",
       "4      imposs get promis refund book flight full mont...  \n",
       "...                                                  ...  \n",
       "11513  websit buggi paid first busi class ticket webs...  \n",
       "11514  reduc level qualiti servic fear futur airlin t...  \n",
       "11515  chang would cost usd book ticket singapor airl...  \n",
       "11516  disappoint flight check secur check frankfurt ...  \n",
       "11517  frustrat experi tri book flight not never frus...  \n",
       "\n",
       "[11518 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('final_df.csv')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "Now, we select the final features to use for our sentiment analysis of airline reviews. \n",
    "- `processed_full_review`,`processed_review_length`, `sentiment`,`year`,`month`\n",
    "\n",
    "- Columns excluded: [`published_platform`,`type`,`helpful_votes`,`language`,`review_length`,`day`,`day_of_week`,`year_month`]\n",
    "\n",
    "- Create a new DataFrame (`data_final`) by selecting the specifc columns mentioned above from the original DataFrame `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>processed_full_review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ok use airlin go singapor london heathrow issu...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>don give money book paid receiv email confirm ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>best airlin world best airlin world seat food ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>premium economi seat singapor airlin not worth...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>imposs get promis refund book flight full mont...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               processed_full_review sentiment\n",
       "0  ok use airlin go singapor london heathrow issu...   Neutral\n",
       "1  don give money book paid receiv email confirm ...  Negative\n",
       "2  best airlin world best airlin world seat food ...  Positive\n",
       "3  premium economi seat singapor airlin not worth...  Negative\n",
       "4  imposs get promis refund book flight full mont...  Negative"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final = data[['processed_full_review','sentiment']]\n",
    "data_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial NB with TF-IDF (`max_features=1000`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB Accuracy: 0.8318865740740741\n",
      "Multinomial NB Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative      0.836     0.694     0.758       692\n",
      "     Neutral      0.571     0.081     0.142       346\n",
      "    Positive      0.836     0.979     0.902      2418\n",
      "\n",
      "    accuracy                          0.832      3456\n",
      "   macro avg      0.748     0.584     0.601      3456\n",
      "weighted avg      0.809     0.832     0.797      3456\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(data['processed_full_review'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_matrix, data['sentiment'],test_size=0.3, random_state=42)\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train,y_train)\n",
    "\n",
    "nb_predictions = nb_model.predict(X_test)\n",
    "\n",
    "print(\"Multinomial NB Accuracy:\", accuracy_score(y_test,nb_predictions))\n",
    "print(\"Multinomial NB Classification Report:\\n\", classification_report(y_test, nb_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complement NB with TF-IDF (`max_features=1000`)\n",
    "\n",
    "CNB is designed to handle imbalanced classes better than MNB, which improves the classification accuracy for minority classes and often yields more balanced performance.\n",
    "\n",
    "CNB includes a form of implicit regularisation by estimating the probability of a class as a complement of the other classes, which helps smooth out the likelihood of each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complement NB Accuracy: 0.8275462962962963\n",
      "Complement NB Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative      0.634     0.867     0.733       692\n",
      "     Neutral      0.438     0.223     0.295       346\n",
      "    Positive      0.935     0.903     0.919      2418\n",
      "\n",
      "    accuracy                          0.828      3456\n",
      "   macro avg      0.669     0.664     0.649      3456\n",
      "weighted avg      0.825     0.828     0.819      3456\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(data['processed_full_review'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_matrix, data['sentiment'],test_size=0.3, random_state=42)\n",
    "\n",
    "nb_model = ComplementNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "nb_predictions = nb_model.predict(X_test)\n",
    "\n",
    "print(\"Complement NB Accuracy:\", accuracy_score(y_test,nb_predictions))\n",
    "print(\"Complement NB Classification Report:\\n\", classification_report(y_test, nb_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complement NB with TF-IDF (`max_features=1000`) with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Alpha: {'alpha': 5.0}\n",
      "Complement NB Accuracy: 0.8339120370370371\n",
      "Complement NB Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative      0.658     0.850     0.741       692\n",
      "     Neutral      0.465     0.228     0.306       346\n",
      "    Positive      0.926     0.916     0.921      2418\n",
      "\n",
      "    accuracy                          0.834      3456\n",
      "   macro avg      0.683     0.665     0.656      3456\n",
      "weighted avg      0.826     0.834     0.824      3456\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(data['processed_full_review'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_matrix, data['sentiment'], test_size=0.3, random_state=42)\n",
    "\n",
    "param_grid = {'alpha': [0.1, 0.5, 1.0, 2.0, 5.0]}  \n",
    "grid_search = GridSearchCV(ComplementNB(), param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_nb_model = grid_search.best_estimator_\n",
    "\n",
    "nb_predictions = best_nb_model.predict(X_test)\n",
    "\n",
    "print(\"Best Alpha:\", grid_search.best_params_)\n",
    "print(\"Complement NB Accuracy:\", accuracy_score(y_test, nb_predictions))\n",
    "print(\"Complement NB Classification Report:\\n\", classification_report(y_test, nb_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF with TF-IDF (`max_features=1000`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.8451967592592593\n",
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative      0.808     0.747     0.776       692\n",
      "     Neutral      0.929     0.075     0.139       346\n",
      "    Positive      0.853     0.983     0.914      2418\n",
      "\n",
      "    accuracy                          0.845      3456\n",
      "   macro avg      0.863     0.602     0.610      3456\n",
      "weighted avg      0.851     0.845     0.809      3456\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, rf_predictions))\n",
    "print(\"Random Forest Classification Report:\\n\", classification_report(y_test, rf_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log Regression with TF-IDF (`max_features=1000`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Regression Accuracy: 0.8587962962962963\n",
      "Log Regression Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative      0.785     0.795     0.790       692\n",
      "     Neutral      0.489     0.257     0.337       346\n",
      "    Positive      0.905     0.963     0.933      2418\n",
      "\n",
      "    accuracy                          0.859      3456\n",
      "   macro avg      0.726     0.672     0.687      3456\n",
      "weighted avg      0.839     0.859     0.845      3456\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=42, multi_class='multinomial', solver='lbfgs').fit(X_train, y_train)\n",
    "clf_predictions = clf.predict(X_test)\n",
    "print(\"Log Regression Accuracy:\", accuracy_score(y_test, clf_predictions))\n",
    "print(\"Log Regression Classification Report:\\n\", classification_report(y_test, clf_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM (linear) with TF-IDF with Stratified K-fold\n",
    "\n",
    "Linear kernel computes the dot product between 2 vectors, works best for lienarly separated data, more effective when features are numerous, as in text classification, where each word or term often represents a feature in high-dimensional space.\n",
    "\n",
    "Less computationally less intensive and faster to train.\n",
    "\n",
    "Class Imbalance Handling: We set `class_weight='balanced'` to automatically adjust the class weights inversely proportional to the class frequencies in the training data, helping the model pay more attention to minority classes.\n",
    "\n",
    "Stratified K-fold: Maintain class distribution across the folds, which is important for imbalanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.81277123 0.8233106  0.82506203 0.81637717 0.81265509]\n",
      "Mean Cross-Validation Accuracy: 0.818035225578773\n",
      "SVM(lienar) Accuracy: 0.8081597222222222\n",
      "SVM(linear) Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative      0.743     0.757     0.750       692\n",
      "     Neutral      0.335     0.581     0.425       346\n",
      "    Positive      0.961     0.855     0.905      2418\n",
      "\n",
      "    accuracy                          0.808      3456\n",
      "   macro avg      0.680     0.731     0.693      3456\n",
      "weighted avg      0.855     0.808     0.826      3456\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "svm_model = SVC(kernel='linear', C=1, class_weight='balanced', random_state=42)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cross_val_scores = cross_val_score(svm_model, X_train, y_train, cv=skf, scoring='accuracy')\n",
    "\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_predictions = svm_model.predict(X_test)\n",
    "\n",
    "print(\"Cross-Validation Accuracy Scores:\", cross_val_scores)\n",
    "print(\"Mean Cross-Validation Accuracy:\", cross_val_scores.mean())\n",
    "\n",
    "print(\"SVM(linear) Accuracy:\", accuracy_score(y_test, svm_predictions))\n",
    "print(\"SVM(linear) Classification Report:\\n\", classification_report(y_test, svm_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM (radial basis function (rbf)) with TF-IDF\n",
    "\n",
    "RBF kernel, a.k.a. Gaussian kernel, is a non-linear kernel that maps data to a higher-dimensional space. Allows for non-linear separation, where classes cannot be separated by a single straight line, can capture complex patterns by creating flexible decision boundaries.\n",
    "\n",
    "More computationally expensive and requires careful tuning of parameters to avoid overfitting.\n",
    "\n",
    "Linear kernel more suitable in this context for text airline sentiment classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.866708   0.86546807 0.86724566 0.87282878 0.86166253]\n",
      "Mean Cross-Validation Accuracy: 0.8667826084281097\n",
      "SVM(rbf) Accuracy: 0.8642939814814815\n",
      "SVM(rbf) Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative      0.761     0.838     0.798       692\n",
      "     Neutral      0.502     0.471     0.486       346\n",
      "    Positive      0.947     0.928     0.938      2418\n",
      "\n",
      "    accuracy                          0.864      3456\n",
      "   macro avg      0.737     0.746     0.740      3456\n",
      "weighted avg      0.865     0.864     0.864      3456\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "svm_model = SVC(kernel='rbf' , C=1, class_weight='balanced', random_state=42)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cross_val_scores = cross_val_score(svm_model, X_train, y_train, cv=skf, scoring='accuracy')\n",
    "\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_predictions = svm_model.predict(X_test)\n",
    "\n",
    "print(\"Cross-Validation Accuracy Scores:\", cross_val_scores)\n",
    "print(\"Mean Cross-Validation Accuracy:\", cross_val_scores.mean())\n",
    "\n",
    "print(\"SVM(rbf) Accuracy:\", accuracy_score(y_test, svm_predictions))\n",
    "print(\"SVM(rbf) Classification Report:\\n\", classification_report(y_test, svm_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM (linear) with TF-IDF with GridSearchCV\n",
    "\n",
    "Performed GridSearchCV for hyperparameter tuning of the Regularization Parameter `C`.\n",
    "\n",
    "The `C` parameter controls the trade-off between maximising the margin and minimising classification errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C parameter: {'C': 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'C': [0.1, 1, 10, 100]}\n",
    "grid_search = GridSearchCV(SVC(kernel='linear'), param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best C parameter:\", grid_search.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
