{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Statistical functions\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# For concurrency (running functions in parallel)\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# For caching (to speed up repeated function calls)\n",
    "from functools import lru_cache\n",
    "\n",
    "# For progress tracking\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Plotting and Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Language Detection packages\n",
    "# `langdetect` for detecting language\n",
    "from langdetect import detect as langdetect_detect, DetectorFactory\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "# `langid` for an alternative language detection method\n",
    "from langid import classify as langid_classify\n",
    "\n",
    "# Text Preprocessing and NLP\n",
    "# Stopwords (common words to ignore) from NLTK\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Tokenizing sentences/words\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Tokenizing sentences/words\n",
    "from nltk.tokenize import word_tokenize\n",
    "# Lemmatization (converting words to their base form)\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "# Regular expressions for text pattern matching\n",
    "import re\n",
    "\n",
    "# Word Cloud generation\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# For generating n-grams\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "\n",
    "# Libraries for Word2Vec and Logistic Regression\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score, make_scorer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"final_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastText + Complement NB\n",
    "\n",
    "FastText is an extension of Word2Vec developed by Facebookâ€™s AI Research (FAIR). While Word2Vec treats each word as a unique token, FastText breaks words into character n-grams (subword information). This means that it can generate vectors for words that were not seen during training, as long as their subwords were seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Negative values in data passed to ComplementNB (input X)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Initialize and train the Complement Naive Bayes model\u001b[39;00m\n\u001b[0;32m     30\u001b[0m nb_model \u001b[38;5;241m=\u001b[39m ComplementNB(alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5.0\u001b[39m)\n\u001b[1;32m---> 31\u001b[0m \u001b[43mnb_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[0;32m     34\u001b[0m nb_predictions \u001b[38;5;241m=\u001b[39m nb_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\naive_bayes.py:759\u001b[0m, in \u001b[0;36m_BaseDiscreteNB.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    757\u001b[0m n_classes \u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    758\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_counters(n_classes, n_features)\n\u001b[1;32m--> 759\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    760\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_alpha()\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_feature_log_prob(alpha)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\naive_bayes.py:1027\u001b[0m, in \u001b[0;36mComplementNB._count\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_count\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y):\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Count feature occurrences.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1027\u001b[0m     \u001b[43mcheck_non_negative\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mComplementNB (input X)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1028\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_count_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m safe_sparse_dot(Y\u001b[38;5;241m.\u001b[39mT, X)\n\u001b[0;32m   1029\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_count_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1689\u001b[0m, in \u001b[0;36mcheck_non_negative\u001b[1;34m(X, whom)\u001b[0m\n\u001b[0;32m   1686\u001b[0m     X_min \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mmin(X)\n\u001b[0;32m   1688\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X_min \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1689\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNegative values in data passed to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m whom)\n",
      "\u001b[1;31mValueError\u001b[0m: Negative values in data passed to ComplementNB (input X)"
     ]
    }
   ],
   "source": [
    "from gensim.models import FastText\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Tokenize the processed reviews for FastText training\n",
    "tokenized_reviews = [review.split() for review in data['processed_full_review']]\n",
    "\n",
    "# Train the FastText model\n",
    "fasttext_model = FastText(sentences=tokenized_reviews, vector_size=100, window=5, min_count=1, sg=1, workers=4, seed=42)\n",
    "\n",
    "# Function to compute the average FastText vectors for each review\n",
    "def get_average_fasttext(review, model, vector_size):\n",
    "    words = review.split()\n",
    "    word_vecs = [model.wv[word] for word in words if word in model.wv]\n",
    "    if word_vecs:\n",
    "        return np.mean(word_vecs, axis=0)\n",
    "    else:\n",
    "        return np.zeros(vector_size)\n",
    "\n",
    "# Create the feature matrix by averaging word vectors for each review\n",
    "vector_size = fasttext_model.vector_size\n",
    "X = np.array([get_average_fasttext(review, fasttext_model, vector_size) for review in data['processed_full_review']])\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, data['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Complement Naive Bayes model\n",
    "nb_model = ComplementNB(alpha=5.0)\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "nb_predictions = nb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Complement NB Accuracy:\", accuracy_score(y_test, nb_predictions))\n",
    "print(\"Complement NB Classification Report:\\n\", classification_report(y_test, nb_predictions, digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastText + RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Accuracy: 0.8415798611111112\n",
      "Fold Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.7628    0.7910    0.7767       488\n",
      "     Neutral     0.5000    0.0987    0.1649       233\n",
      "    Positive     0.8733    0.9665    0.9175      1583\n",
      "\n",
      "    accuracy                         0.8416      2304\n",
      "   macro avg     0.7120    0.6187    0.6197      2304\n",
      "weighted avg     0.8121    0.8416    0.8116      2304\n",
      "\n",
      "Fold Accuracy: 0.8511284722222222\n",
      "Fold Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.7844    0.8053    0.7947       488\n",
      "     Neutral     0.5692    0.1588    0.2483       233\n",
      "    Positive     0.8809    0.9672    0.9220      1583\n",
      "\n",
      "    accuracy                         0.8511      2304\n",
      "   macro avg     0.7449    0.6438    0.6550      2304\n",
      "weighted avg     0.8289    0.8511    0.8269      2304\n",
      "\n",
      "Fold Accuracy: 0.8333333333333334\n",
      "Fold Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.7596    0.7705    0.7650       488\n",
      "     Neutral     0.4909    0.1159    0.1875       233\n",
      "    Positive     0.8649    0.9583    0.9092      1583\n",
      "\n",
      "    accuracy                         0.8333      2304\n",
      "   macro avg     0.7051    0.6149    0.6206      2304\n",
      "weighted avg     0.8048    0.8333    0.8057      2304\n",
      "\n",
      "Fold Accuracy: 0.8358662613981763\n",
      "Fold Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.7847    0.7766    0.7806       488\n",
      "     Neutral     0.4286    0.1288    0.1980       233\n",
      "    Positive     0.8663    0.9583    0.9100      1582\n",
      "\n",
      "    accuracy                         0.8359      2303\n",
      "   macro avg     0.6932    0.6212    0.6295      2303\n",
      "weighted avg     0.8047    0.8359    0.8105      2303\n",
      "\n",
      "Fold Accuracy: 0.8441163699522363\n",
      "Fold Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.7854    0.8160    0.8004       489\n",
      "     Neutral     0.5172    0.1293    0.2069       232\n",
      "    Positive     0.8722    0.9576    0.9129      1582\n",
      "\n",
      "    accuracy                         0.8441      2303\n",
      "   macro avg     0.7250    0.6343    0.6401      2303\n",
      "weighted avg     0.8180    0.8441    0.8179      2303\n",
      "\n",
      "\n",
      "Average Accuracy across folds: 0.841204859603416\n",
      "Average Precision across folds: 0.8137153964654406\n",
      "Average Recall across folds: 0.841204859603416\n",
      "Average F1 Score across folds: 0.8145252144733348\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import FastText\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Tokenize the processed reviews for FastText training\n",
    "tokenized_reviews = [review.split() for review in data['processed_full_review']]\n",
    "\n",
    "# Train the FastText model\n",
    "fasttext_model = FastText(sentences=tokenized_reviews, vector_size=100, window=5, min_count=1, sg=1, workers=4, seed=42)\n",
    "\n",
    "# Function to compute the average FastText vectors for each review\n",
    "def get_average_fasttext(review, model, vector_size):\n",
    "    words = review.split()\n",
    "    word_vecs = [model.wv[word] for word in words if word in model.wv]\n",
    "    if word_vecs:\n",
    "        return np.mean(word_vecs, axis=0)\n",
    "    else:\n",
    "        return np.zeros(vector_size)\n",
    "\n",
    "# Create the feature matrix by averaging word vectors for each review\n",
    "vector_size = fasttext_model.vector_size\n",
    "X = np.array([get_average_fasttext(review, fasttext_model, vector_size) for review in data['processed_full_review']])\n",
    "y = data['sentiment']\n",
    "\n",
    "# Stratified 5-fold cross-validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Initialize and train the Random Forest model\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    rf_predictions = rf_model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, rf_predictions)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    \n",
    "    report = classification_report(y_test, rf_predictions, digits=4, output_dict=True)\n",
    "    precision_scores.append(report[\"weighted avg\"][\"precision\"])\n",
    "    recall_scores.append(report[\"weighted avg\"][\"recall\"])\n",
    "    f1_scores.append(report[\"weighted avg\"][\"f1-score\"])\n",
    "\n",
    "    print(f\"Fold Accuracy: {accuracy}\")\n",
    "    print(f\"Fold Classification Report:\\n\", classification_report(y_test, rf_predictions, digits=4))\n",
    "\n",
    "# Print average scores across all folds\n",
    "print(\"\\nAverage Accuracy across folds:\", np.mean(accuracy_scores))\n",
    "print(\"Average Precision across folds:\", np.mean(precision_scores))\n",
    "print(\"Average Recall across folds:\", np.mean(recall_scores))\n",
    "print(\"Average F1 Score across folds:\", np.mean(f1_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastText + Log Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Accuracy: 0.8493923611111112\n",
      "Fold Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.7627    0.7971    0.7796       488\n",
      "     Neutral     0.5263    0.2146    0.3049       233\n",
      "    Positive     0.8935    0.9589    0.9250      1583\n",
      "\n",
      "    accuracy                         0.8494      2304\n",
      "   macro avg     0.7275    0.6569    0.6698      2304\n",
      "weighted avg     0.8286    0.8494    0.8315      2304\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Accuracy: 0.8550347222222222\n",
      "Fold Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.7853    0.8094    0.7972       488\n",
      "     Neutral     0.5312    0.2189    0.3100       233\n",
      "    Positive     0.8938    0.9627    0.9270      1583\n",
      "\n",
      "    accuracy                         0.8550      2304\n",
      "   macro avg     0.7368    0.6637    0.6781      2304\n",
      "weighted avg     0.8342    0.8550    0.8371      2304\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Accuracy: 0.8415798611111112\n",
      "Fold Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.7548    0.8012    0.7773       488\n",
      "     Neutral     0.4700    0.2017    0.2823       233\n",
      "    Positive     0.8903    0.9482    0.9183      1583\n",
      "\n",
      "    accuracy                         0.8416      2304\n",
      "   macro avg     0.7050    0.6504    0.6593      2304\n",
      "weighted avg     0.8191    0.8416    0.8241      2304\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Accuracy: 0.8441163699522363\n",
      "Fold Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.7923    0.8053    0.7988       488\n",
      "     Neutral     0.4433    0.1845    0.2606       233\n",
      "    Positive     0.8819    0.9532    0.9162      1582\n",
      "\n",
      "    accuracy                         0.8441      2303\n",
      "   macro avg     0.7058    0.6477    0.6585      2303\n",
      "weighted avg     0.8185    0.8441    0.8250      2303\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Accuracy: 0.8532349109856708\n",
      "Fold Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.7596    0.8466    0.8008       489\n",
      "     Neutral     0.5161    0.2069    0.2954       232\n",
      "    Positive     0.9027    0.9501    0.9258      1582\n",
      "\n",
      "    accuracy                         0.8532      2303\n",
      "   macro avg     0.7262    0.6679    0.6740      2303\n",
      "weighted avg     0.8334    0.8532    0.8357      2303\n",
      "\n",
      "\n",
      "Average Accuracy across folds: 0.8486716450764703\n",
      "Average Precision across folds: 0.8267647473776394\n",
      "Average Recall across folds: 0.8486716450764703\n",
      "Average F1 Score across folds: 0.8306925339486154\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import FastText\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Tokenize the processed reviews for FastText training\n",
    "tokenized_reviews = [review.split() for review in data['processed_full_review']]\n",
    "\n",
    "# Train the FastText model\n",
    "fasttext_model = FastText(sentences=tokenized_reviews, vector_size=100, window=5, min_count=1, sg=1, workers=4, seed=42)\n",
    "\n",
    "# Function to compute the average FastText vectors for each review\n",
    "def get_average_fasttext(review, model, vector_size):\n",
    "    words = review.split()\n",
    "    word_vecs = [model.wv[word] for word in words if word in model.wv]\n",
    "    if word_vecs:\n",
    "        return np.mean(word_vecs, axis=0)\n",
    "    else:\n",
    "        return np.zeros(vector_size)\n",
    "\n",
    "# Create the feature matrix by averaging word vectors for each review\n",
    "vector_size = fasttext_model.vector_size\n",
    "X = np.array([get_average_fasttext(review, fasttext_model, vector_size) for review in data['processed_full_review']])\n",
    "y = data['sentiment']\n",
    "\n",
    "# Stratified 5-fold cross-validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Initialize and train the Logistic Regression model\n",
    "    clf = LogisticRegression(random_state=42, multi_class='multinomial', solver='lbfgs', max_iter=200)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    clf_predictions = clf.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, clf_predictions)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    \n",
    "    report = classification_report(y_test, clf_predictions, digits=4, output_dict=True)\n",
    "    precision_scores.append(report[\"weighted avg\"][\"precision\"])\n",
    "    recall_scores.append(report[\"weighted avg\"][\"recall\"])\n",
    "    f1_scores.append(report[\"weighted avg\"][\"f1-score\"])\n",
    "\n",
    "    print(f\"Fold Accuracy: {accuracy}\")\n",
    "    print(f\"Fold Classification Report:\\n\", classification_report(y_test, clf_predictions, digits=4))\n",
    "\n",
    "# Print average scores across all folds\n",
    "print(\"\\nAverage Accuracy across folds:\", np.mean(accuracy_scores))\n",
    "print(\"Average Precision across folds:\", np.mean(precision_scores))\n",
    "print(\"Average Recall across folds:\", np.mean(recall_scores))\n",
    "print(\"Average F1 Score across folds:\", np.mean(f1_scores))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
