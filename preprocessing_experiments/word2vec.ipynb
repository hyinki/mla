{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhancing Singapore Airlines' Service Through Automated Sentiment Analysis of Customer Reviews\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Singapore Airlines Customer Reviews Dataset Information\n",
    "\n",
    "The [Singapore Airlines Customer Reviews Dataset](https://www.kaggle.com/datasets/kanchana1990/singapore-airlines-reviews) aggregates 10,000 anonymized customer reviews, providing a broad perspective on the passenger experience with Singapore Airlines. \n",
    "\n",
    "The dimensions are shown below:\n",
    "- **`published_date`**: Date and time of review publication.\n",
    "- **`published_platform`**: Platform where the review was posted.\n",
    "- **`rating`**: Customer satisfaction rating, from 1 (lowest) to 5 (highest).\n",
    "- **`type`**: Specifies the content as a review.\n",
    "- **`text`**: Detailed customer feedback.\n",
    "- **`title`**: Summary of the review.\n",
    "- **`helpful_votes`**: Number of users finding the review helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries\n",
    "\n",
    "Please uncomment the code box below to pip install relevant dependencies for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Statistical functions\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# For concurrency (running functions in parallel)\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# For caching (to speed up repeated function calls)\n",
    "from functools import lru_cache\n",
    "\n",
    "# For progress tracking\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Plotting and Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Language Detection packages\n",
    "# `langdetect` for detecting language\n",
    "from langdetect import detect as langdetect_detect, DetectorFactory\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "# `langid` for an alternative language detection method\n",
    "from langid import classify as langid_classify\n",
    "\n",
    "# Text Preprocessing and NLP\n",
    "# Stopwords (common words to ignore) from NLTK\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Tokenizing sentences/words\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Tokenizing sentences/words\n",
    "from nltk.tokenize import word_tokenize\n",
    "# Lemmatization (converting words to their base form)\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "# Regular expressions for text pattern matching\n",
    "import re\n",
    "\n",
    "# Word Cloud generation\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# For generating n-grams\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "\n",
    "# Libraries for Word2Vec and Logistic Regression\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../final_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec + ComplementNB\n",
    "\n",
    "You can see that Word2Vec doesn't work with Complement NB because NB cannot handle negative values in the input data. Word2Vec embeddings produces negative values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Negative values in data passed to ComplementNB (input X)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Initialize and train the Complement Naive Bayes model\u001b[39;00m\n\u001b[0;32m     30\u001b[0m nb_model \u001b[38;5;241m=\u001b[39m ComplementNB(alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5.0\u001b[39m)\n\u001b[1;32m---> 31\u001b[0m \u001b[43mnb_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[0;32m     34\u001b[0m nb_predictions \u001b[38;5;241m=\u001b[39m nb_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\naive_bayes.py:759\u001b[0m, in \u001b[0;36m_BaseDiscreteNB.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    757\u001b[0m n_classes \u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    758\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_counters(n_classes, n_features)\n\u001b[1;32m--> 759\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    760\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_alpha()\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_feature_log_prob(alpha)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\naive_bayes.py:1027\u001b[0m, in \u001b[0;36mComplementNB._count\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_count\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y):\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Count feature occurrences.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1027\u001b[0m     \u001b[43mcheck_non_negative\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mComplementNB (input X)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1028\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_count_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m safe_sparse_dot(Y\u001b[38;5;241m.\u001b[39mT, X)\n\u001b[0;32m   1029\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_count_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1689\u001b[0m, in \u001b[0;36mcheck_non_negative\u001b[1;34m(X, whom)\u001b[0m\n\u001b[0;32m   1686\u001b[0m     X_min \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mmin(X)\n\u001b[0;32m   1688\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X_min \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1689\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNegative values in data passed to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m whom)\n",
      "\u001b[1;31mValueError\u001b[0m: Negative values in data passed to ComplementNB (input X)"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Tokenize the processed reviews for Word2Vec training\n",
    "tokenized_reviews = [review.split() for review in data['processed_full_review']]\n",
    "\n",
    "# Train the Word2Vec model\n",
    "w2v_model = Word2Vec(sentences=tokenized_reviews, vector_size=100, window=5, min_count=1, sg=1, workers=4, seed=42)\n",
    "\n",
    "# Function to compute the average word vectors for each review\n",
    "def get_average_word2vec(review, model, vector_size):\n",
    "    words = review.split()\n",
    "    word_vecs = [model.wv[word] for word in words if word in model.wv]\n",
    "    if word_vecs:\n",
    "        return np.mean(word_vecs, axis=0)\n",
    "    else:\n",
    "        return np.zeros(vector_size)\n",
    "\n",
    "# Create the feature matrix by averaging word vectors for each review\n",
    "vector_size = w2v_model.vector_size\n",
    "X = np.array([get_average_word2vec(review, w2v_model, vector_size) for review in data['processed_full_review']])\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, data['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Complement Naive Bayes model\n",
    "nb_model = ComplementNB(alpha=5.0)\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "nb_predictions = nb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Complement NB Accuracy:\", accuracy_score(y_test, nb_predictions))\n",
    "print(\"Complement NB Classification Report:\\n\", classification_report(y_test, nb_predictions, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec + RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Accuracy: 0.8454861111111112\n",
      "Fold Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.7697    0.7807    0.7752       488\n",
      "     Neutral     0.6333    0.1631    0.2594       233\n",
      "    Positive     0.8742    0.9659    0.9178      1583\n",
      "\n",
      "    accuracy                         0.8455      2304\n",
      "   macro avg     0.7591    0.6366    0.6508      2304\n",
      "weighted avg     0.8277    0.8455    0.8210      2304\n",
      "\n",
      "Fold Accuracy: 0.8519965277777778\n",
      "Fold Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.7851    0.7787    0.7819       488\n",
      "     Neutral     0.5591    0.2232    0.3190       233\n",
      "    Positive     0.8865    0.9672    0.9251      1583\n",
      "\n",
      "    accuracy                         0.8520      2304\n",
      "   macro avg     0.7436    0.6563    0.6753      2304\n",
      "weighted avg     0.8319    0.8520    0.8335      2304\n",
      "\n",
      "Fold Accuracy: 0.8315972222222222\n",
      "Fold Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.7520    0.7643    0.7581       488\n",
      "     Neutral     0.4133    0.1330    0.2013       233\n",
      "    Positive     0.8725    0.9551    0.9119      1583\n",
      "\n",
      "    accuracy                         0.8316      2304\n",
      "   macro avg     0.6793    0.6175    0.6238      2304\n",
      "weighted avg     0.8005    0.8316    0.8075      2304\n",
      "\n",
      "Fold Accuracy: 0.8406426400347373\n",
      "Fold Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.7936    0.7643    0.7787       488\n",
      "     Neutral     0.5902    0.1545    0.2449       233\n",
      "    Positive     0.8617    0.9652    0.9106      1582\n",
      "\n",
      "    accuracy                         0.8406      2303\n",
      "   macro avg     0.7485    0.6280    0.6447      2303\n",
      "weighted avg     0.8198    0.8406    0.8153      2303\n",
      "\n",
      "Fold Accuracy: 0.8432479374728615\n",
      "Fold Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.7697    0.8200    0.7941       489\n",
      "     Neutral     0.5714    0.1552    0.2441       232\n",
      "    Positive     0.8755    0.9513    0.9118      1582\n",
      "\n",
      "    accuracy                         0.8432      2303\n",
      "   macro avg     0.7389    0.6422    0.6500      2303\n",
      "weighted avg     0.8224    0.8432    0.8196      2303\n",
      "\n",
      "\n",
      "Average Accuracy across folds: 0.8425940877237421\n",
      "Average Precision across folds: 0.8204812313756176\n",
      "Average Recall across folds: 0.8425940877237421\n",
      "Average F1 Score across folds: 0.819355230258555\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import FastText\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Tokenize the processed reviews for Word2Vec training\n",
    "tokenized_reviews = [review.split() for review in data['processed_full_review']]\n",
    "\n",
    "# Train the Word2Vec model\n",
    "w2v_model = Word2Vec(sentences=tokenized_reviews, vector_size=100, window=5, min_count=1, sg=1, workers=4, seed=42)\n",
    "\n",
    "# Function to compute the average word vectors for each review\n",
    "def get_average_word2vec(review, model, vector_size):\n",
    "    words = review.split()\n",
    "    word_vecs = [model.wv[word] for word in words if word in model.wv]\n",
    "    if word_vecs:\n",
    "        return np.mean(word_vecs, axis=0)\n",
    "    else:\n",
    "        return np.zeros(vector_size)\n",
    "\n",
    "# Create the feature matrix by averaging word vectors for each review\n",
    "vector_size = w2v_model.vector_size\n",
    "X = np.array([get_average_word2vec(review, w2v_model, vector_size) for review in data['processed_full_review']])\n",
    "y = data['sentiment']\n",
    "\n",
    "# Stratified 5-fold cross-validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Initialize and train the Random Forest model\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    rf_predictions = rf_model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, rf_predictions)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    \n",
    "    report = classification_report(y_test, rf_predictions, digits=4, output_dict=True)\n",
    "    precision_scores.append(report[\"weighted avg\"][\"precision\"])\n",
    "    recall_scores.append(report[\"weighted avg\"][\"recall\"])\n",
    "    f1_scores.append(report[\"weighted avg\"][\"f1-score\"])\n",
    "\n",
    "    print(f\"Fold Accuracy: {accuracy}\")\n",
    "    print(f\"Fold Classification Report:\\n\", classification_report(y_test, rf_predictions, digits=4))\n",
    "\n",
    "# Print average scores across all folds\n",
    "print(\"\\nAverage Accuracy across folds:\", np.mean(accuracy_scores))\n",
    "print(\"Average Precision across folds:\", np.mean(precision_scores))\n",
    "print(\"Average Recall across folds:\", np.mean(recall_scores))\n",
    "print(\"Average F1 Score across folds:\", np.mean(f1_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec + log regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Accuracy: 0.8537326388888888\n",
      "Fold Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.7758    0.8012    0.7883       488\n",
      "     Neutral     0.5225    0.2489    0.3372       233\n",
      "    Positive     0.8988    0.9589    0.9279      1583\n",
      "\n",
      "    accuracy                         0.8537      2304\n",
      "   macro avg     0.7324    0.6697    0.6845      2304\n",
      "weighted avg     0.8347    0.8537    0.8386      2304\n",
      "\n",
      "Fold Accuracy: 0.8563368055555556\n",
      "Fold Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.7837    0.8094    0.7964       488\n",
      "     Neutral     0.5000    0.2232    0.3086       233\n",
      "    Positive     0.8998    0.9640    0.9308      1583\n",
      "\n",
      "    accuracy                         0.8563      2304\n",
      "   macro avg     0.7278    0.6655    0.6786      2304\n",
      "weighted avg     0.8348    0.8563    0.8394      2304\n",
      "\n",
      "Fold Accuracy: 0.8459201388888888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.7523    0.8217    0.7855       488\n",
      "     Neutral     0.5000    0.2189    0.3045       233\n",
      "    Positive     0.8969    0.9457    0.9207      1583\n",
      "\n",
      "    accuracy                         0.8459      2304\n",
      "   macro avg     0.7164    0.6621    0.6702      2304\n",
      "weighted avg     0.8262    0.8459    0.8297      2304\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Accuracy: 0.8471558836300478\n",
      "Fold Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.7907    0.7971    0.7939       488\n",
      "     Neutral     0.5000    0.2017    0.2875       233\n",
      "    Positive     0.8824    0.9576    0.9185      1582\n",
      "\n",
      "    accuracy                         0.8472      2303\n",
      "   macro avg     0.7243    0.6522    0.6666      2303\n",
      "weighted avg     0.8242    0.8472    0.8282      2303\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Accuracy: 0.8588797221016066\n",
      "Fold Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.7813    0.8548    0.8164       489\n",
      "     Neutral     0.5392    0.2371    0.3293       232\n",
      "    Positive     0.9034    0.9513    0.9267      1582\n",
      "\n",
      "    accuracy                         0.8589      2303\n",
      "   macro avg     0.7413    0.6811    0.6908      2303\n",
      "weighted avg     0.8408    0.8589    0.8431      2303\n",
      "\n",
      "\n",
      "Average Accuracy across folds: 0.8524050378129975\n",
      "Average Precision across folds: 0.8321199062382114\n",
      "Average Recall across folds: 0.8524050378129975\n",
      "Average F1 Score across folds: 0.8358060729131429\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Tokenize the processed reviews for Word2Vec training\n",
    "tokenized_reviews = [review.split() for review in data['processed_full_review']]\n",
    "\n",
    "# Train the Word2Vec model\n",
    "w2v_model = Word2Vec(sentences=tokenized_reviews, vector_size=100, window=5, min_count=1, sg=1, workers=4, seed=42)\n",
    "\n",
    "# Function to compute the average word vectors for each review\n",
    "def get_average_word2vec(review, model, vector_size):\n",
    "    words = review.split()\n",
    "    word_vecs = [model.wv[word] for word in words if word in model.wv]\n",
    "    if word_vecs:\n",
    "        return np.mean(word_vecs, axis=0)\n",
    "    else:\n",
    "        return np.zeros(vector_size)\n",
    "\n",
    "# Create the feature matrix by averaging word vectors for each review\n",
    "vector_size = w2v_model.vector_size\n",
    "X = np.array([get_average_word2vec(review, w2v_model, vector_size) for review in data['processed_full_review']])\n",
    "y = data['sentiment']\n",
    "\n",
    "# Stratified 5-fold cross-validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Initialize and train the Logistic Regression model\n",
    "    clf = LogisticRegression(random_state=42, multi_class='multinomial', solver='lbfgs', max_iter=100)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    clf_predictions = clf.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, clf_predictions)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    \n",
    "    report = classification_report(y_test, clf_predictions, digits=4, output_dict=True)\n",
    "    precision_scores.append(report[\"weighted avg\"][\"precision\"])\n",
    "    recall_scores.append(report[\"weighted avg\"][\"recall\"])\n",
    "    f1_scores.append(report[\"weighted avg\"][\"f1-score\"])\n",
    "\n",
    "    print(f\"Fold Accuracy: {accuracy}\")\n",
    "    print(f\"Fold Classification Report:\\n\", classification_report(y_test, clf_predictions, digits=4))\n",
    "\n",
    "# Print average scores across all folds\n",
    "print(\"\\nAverage Accuracy across folds:\", np.mean(accuracy_scores))\n",
    "print(\"Average Precision across folds:\", np.mean(precision_scores))\n",
    "print(\"Average Recall across folds:\", np.mean(recall_scores))\n",
    "print(\"Average F1 Score across folds:\", np.mean(f1_scores))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
