{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhancing Singapore Airlines' Service Through Automated Sentiment Analysis of Customer Reviews\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Motivation**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Singapore Airlines Customer Reviews Dataset Information\n",
    "\n",
    "The [Singapore Airlines Customer Reviews Dataset](https://www.kaggle.com/datasets/kanchana1990/singapore-airlines-reviews) aggregates 10,000 anonymized customer reviews, providing a broad perspective on the passenger experience with Singapore Airlines. \n",
    "\n",
    "The dimensions are shown below:\n",
    "- **`published_date`**: Date and time of review publication.\n",
    "- **`published_platform`**: Platform where the review was posted.\n",
    "- **`rating`**: Customer satisfaction rating, from 1 (lowest) to 5 (highest).\n",
    "- **`type`**: Specifies the content as a review.\n",
    "- **`text`**: Detailed customer feedback.\n",
    "- **`title`**: Summary of the review.\n",
    "- **`helpful_votes`**: Number of users finding the review helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries\n",
    "\n",
    "Please uncomment the code box below to pip install relevant dependencies for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Statistical functions\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# For concurrency (running functions in parallel)\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# For caching (to speed up repeated function calls)\n",
    "from functools import lru_cache\n",
    "\n",
    "# For progress tracking\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Plotting and Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Language Detection packages\n",
    "# `langdetect` for detecting language\n",
    "from langdetect import detect as langdetect_detect, DetectorFactory\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "# `langid` for an alternative language detection method\n",
    "from langid import classify as langid_classify\n",
    "\n",
    "# Text Preprocessing and NLP\n",
    "# Stopwords (common words to ignore) from NLTK\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Tokenizing sentences/words\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Tokenizing sentences/words\n",
    "from nltk.tokenize import word_tokenize\n",
    "# Lemmatization (converting words to their base form)\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "# Regular expressions for text pattern matching\n",
    "import re\n",
    "\n",
    "# Word Cloud generation\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# For generating n-grams\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "\n",
    "# Libraries for Word2Vec and Logistic Regression\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score, make_scorer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec + log regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /home/dariusng2103/projects/mla_project/tf217/lib/python3.12/site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in /home/dariusng2103/projects/mla_project/tf217/lib/python3.12/site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /home/dariusng2103/projects/mla_project/tf217/lib/python3.12/site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/dariusng2103/projects/mla_project/tf217/lib/python3.12/site-packages (from gensim) (7.0.5)\n",
      "Requirement already satisfied: wrapt in /home/dariusng2103/projects/mla_project/tf217/lib/python3.12/site-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"final_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 83.45%\n",
      "Model F1 Score: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dariusng2103/projects/mla_project/tf217/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:1000: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dariusng2103/projects/mla_project/tf217/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 139, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/dariusng2103/projects/mla_project/tf217/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 371, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/dariusng2103/projects/mla_project/tf217/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 89, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dariusng2103/projects/mla_project/tf217/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 204, in _get_response_values\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label: It should be one of ['Negative' 'Neutral' 'Positive']\n",
      "\n",
      "  warnings.warn(\n",
      "/home/dariusng2103/projects/mla_project/tf217/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:1000: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dariusng2103/projects/mla_project/tf217/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 139, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/dariusng2103/projects/mla_project/tf217/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 371, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/dariusng2103/projects/mla_project/tf217/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 89, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dariusng2103/projects/mla_project/tf217/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 204, in _get_response_values\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label: It should be one of ['Negative' 'Neutral' 'Positive']\n",
      "\n",
      "  warnings.warn(\n",
      "/home/dariusng2103/projects/mla_project/tf217/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:1000: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dariusng2103/projects/mla_project/tf217/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 139, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/dariusng2103/projects/mla_project/tf217/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 371, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/dariusng2103/projects/mla_project/tf217/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 89, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dariusng2103/projects/mla_project/tf217/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 204, in _get_response_values\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label: It should be one of ['Negative' 'Neutral' 'Positive']\n",
      "\n",
      "  warnings.warn(\n",
      "/home/dariusng2103/projects/mla_project/tf217/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:1000: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dariusng2103/projects/mla_project/tf217/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 139, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/dariusng2103/projects/mla_project/tf217/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 371, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/dariusng2103/projects/mla_project/tf217/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 89, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dariusng2103/projects/mla_project/tf217/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 204, in _get_response_values\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label: It should be one of ['Negative' 'Neutral' 'Positive']\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation F1 Scores: [nan nan nan nan nan]\n",
      "Average Cross-Validation F1 Score: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dariusng2103/projects/mla_project/tf217/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:1000: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dariusng2103/projects/mla_project/tf217/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 139, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/dariusng2103/projects/mla_project/tf217/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 371, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/dariusng2103/projects/mla_project/tf217/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 89, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dariusng2103/projects/mla_project/tf217/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 204, in _get_response_values\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label: It should be one of ['Negative' 'Neutral' 'Positive']\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define X (features) and y (target) based on multiclass sentiment\n",
    "X = data['processed_full_review']  # Review text\n",
    "y = data['sentiment']\n",
    "\n",
    "# Tokenize the sentences\n",
    "tokenized_sentences = [word_tokenize(sentence.lower()) for sentence in X]\n",
    "\n",
    "# Train the Word2Vec model\n",
    "word2vec_model = Word2Vec(sentences=tokenized_sentences, vector_size=100, window=5, min_count=2)\n",
    "\n",
    "# Function to convert each sentence into an average word2vec vector\n",
    "def sentence_to_avg_vector(sentence, model):\n",
    "    words = [word for word in sentence if word in model.wv]  # Keep only words present in the Word2Vec vocabulary\n",
    "    if len(words) > 0:\n",
    "        return np.mean([model.wv[word] for word in words], axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)  # Return a zero vector if no words from the sentence are in the vocabulary\n",
    "\n",
    "# Convert all tokenized sentences to their corresponding average word2vec vectors\n",
    "X_word2vec = np.array([sentence_to_avg_vector(sentence, word2vec_model) for sentence in tokenized_sentences])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_word2vec, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a logistic regression model\n",
    "model = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy and F1 score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Model F1 Score: {f1:.2f}\")\n",
    "\n",
    "# Cross-validation with F1 score\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_f1_scores = cross_val_score(model, X_word2vec, y, cv=kf, scoring=make_scorer(f1_score, average='weighted'))\n",
    "\n",
    "# Output cross-validation F1 score results\n",
    "print(f\"Cross-Validation F1 Scores: {cv_f1_scores}\")\n",
    "print(f\"Average Cross-Validation F1 Score: {np.mean(cv_f1_scores):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec + random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 82.23%\n",
      "Model F1 Score: 0.80\n",
      "Cross-Validation F1 Scores: [0.80198335 0.79488966 0.79785105 0.79883879 0.78189603]\n",
      "Average Cross-Validation F1 Score: 0.80\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "import numpy as np\n",
    "\n",
    "# Define X (features) and y (target) based on multiclass sentiment\n",
    "X = data['processed_full_review']  # Review text\n",
    "y = data['sentiment']\n",
    "\n",
    "# Tokenize the sentences\n",
    "tokenized_sentences = [word_tokenize(sentence.lower()) for sentence in X]\n",
    "\n",
    "# Train the Word2Vec model\n",
    "word2vec_model = Word2Vec(sentences=tokenized_sentences, vector_size=100, window=5, min_count=2)\n",
    "\n",
    "# Function to convert each sentence into an average word2vec vector\n",
    "def sentence_to_avg_vector(sentence, model):\n",
    "    words = [word for word in sentence if word in model.wv]  # Keep only words present in the Word2Vec vocabulary\n",
    "    if len(words) > 0:\n",
    "        return np.mean([model.wv[word] for word in words], axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)  # Return a zero vector if no words from the sentence are in the vocabulary\n",
    "\n",
    "# Convert all tokenized sentences to their corresponding average word2vec vectors\n",
    "X_word2vec = np.array([sentence_to_avg_vector(sentence, word2vec_model) for sentence in tokenized_sentences])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_word2vec, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Model F1 Score: {f1:.2f}\")\n",
    "\n",
    "# Cross-validation with F1 score\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_f1_scores = cross_val_score(model, X_word2vec, y, cv=kf, scoring=make_scorer(f1_score, average='weighted'))\n",
    "\n",
    "# Output cross-validation F1 score results\n",
    "print(f\"Cross-Validation F1 Scores: {cv_f1_scores}\")\n",
    "print(f\"Average Cross-Validation F1 Score: {np.mean(cv_f1_scores):.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf217",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
